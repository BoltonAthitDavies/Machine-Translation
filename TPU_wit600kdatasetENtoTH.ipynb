{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPU_wit600k_p'man+p'pongV4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "abde3afb14734d09ad55969c1f3d1559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1d23bca4039c4647af24985c33448adb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_90c491d0e9d64cdb85178a4621527fa0",
              "IPY_MODEL_23ed090048234a68b25fff2f21f20177",
              "IPY_MODEL_ffb0f5bccaa142f4836ef24a184fb5da"
            ]
          }
        },
        "1d23bca4039c4647af24985c33448adb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90c491d0e9d64cdb85178a4621527fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b029e82544fe4d2cb52c694416e9a5e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2577063f727349e08cbd9c77c8afefb8"
          }
        },
        "23ed090048234a68b25fff2f21f20177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cc11ffeee2504f558eb157dda42209f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_409185a17e3b4a688d4bf13f35ff5c00"
          }
        },
        "ffb0f5bccaa142f4836ef24a184fb5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b8465db0b5040f89c0e9e5ac481418c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1520/1520 [10:15&lt;00:00,  1.35it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc2cce5039394848946894d1d6623c79"
          }
        },
        "b029e82544fe4d2cb52c694416e9a5e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2577063f727349e08cbd9c77c8afefb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc11ffeee2504f558eb157dda42209f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "409185a17e3b4a688d4bf13f35ff5c00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b8465db0b5040f89c0e9e5ac481418c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc2cce5039394848946894d1d6623c79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1c4VRvOzPkFKsbavjgxaX59SKG6CZzxpQ"
      ],
      "metadata": {
        "id": "NhEyvROsFv9Q",
        "outputId": "e78be996-3ef7-42b4-ed6c-b514a7ccdcbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1c4VRvOzPkFKsbavjgxaX59SKG6CZzxpQ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "sYv87Ie6bNxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYHoPbm9P8fR",
        "outputId": "226cd20a-b183-4033-d540-2421d1db2b73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar 10 05:50:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!gdown --id 1Viv8ilV6vCDIUPlHw3Wf5z4dnQh8mSRe # 15m data"
      ],
      "metadata": {
        "id": "u0OieXen7GPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!gdown --id 1wKpWqYL45HBe9t5Edk3n1KvEHl_BnVO_ # p'namwan dataset"
      ],
      "metadata": {
        "id": "v9RaLDOGwq6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kexbwe_CuWGb",
        "outputId": "74a0f3b9-81cb-44ae-d315-269eca390f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp /content/drive/MyDrive/en-th.zip ."
      ],
      "metadata": {
        "id": "YAjkKm_-kbBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip en-th.zip"
      ],
      "metadata": {
        "id": "aE-jfjrQv-Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip scb-mt-en-th-2020.zip"
      ],
      "metadata": {
        "id": "NNTobO2Zk52j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install git+git://github.com/rkcosmos/deepcut.git #deepcut"
      ],
      "metadata": {
        "id": "XgPNtIwqmQMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import deepcut\n",
        "#def deepCut(df):\n",
        "   \n",
        "   #AG = []\n",
        "   #i = 0\n",
        "   \n",
        "   #for i in range(0,222733):\n",
        "      #j = deepcut.tokenize(df['th_text'][i])\n",
        "      #AG.append(j)\n",
        "      #i += 1\n",
        "   #return AG"
      ],
      "metadata": {
        "id": "KLetYyzDmJtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TM1 = deepCut(task_master_1)\n",
        "#TM1"
      ],
      "metadata": {
        "id": "K0WVpmuQpSAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TM1"
      ],
      "metadata": {
        "id": "ptk0bfh_XWoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TM1[0]"
      ],
      "metadata": {
        "id": "2YX9r5IF8l4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a = pd.DataFrame([TM1])\n",
        "#b = a.transpose()\n",
        "#b[0]"
      ],
      "metadata": {
        "id": "DvR_IgzQHdY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b[0][0]"
      ],
      "metadata": {
        "id": "9zMGzMppSswG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#c = pd.read_csv(\"/content/22k_remove.csv\")"
      ],
      "metadata": {
        "id": "frnjHpp6SHuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#c"
      ],
      "metadata": {
        "id": "0-QRjKNETXff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#d = c.drop(['Unnamed: 0'], axis=1)"
      ],
      "metadata": {
        "id": "xJl3GluVTGu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#d"
      ],
      "metadata": {
        "id": "5f8Z6FO5ThwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e['0'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8X8gQG6Na2V4",
        "outputId": "15008fc5-d580-43be-d2f5-a2282c0c22ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"'ได้', 'เลย', 'ค่ะ', ' ', 'แถว', 'ไหน', 'ดี', 'คะ', '?''\""
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e['0'][1].replace(',', '').replace(\"'\", '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_gZrcBkGcxto",
        "outputId": "0b000c4f-0bff-4849-91c4-664260c69c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ได้ เลย ค่ะ   แถว ไหน ดี คะ ?'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e['0'][0].replace(',', '')#.replace(\"'\", '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jbprO0agn1Vk",
        "outputId": "17f5280d-3b0d-42f6-9a47-302373add53c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"'สวัสดี' 'ค่ะ' ' ' 'ช่วย' 'จอง' 'ร้าน' 'อาหาร' 'เกาหลี' 'ให้' 'หน่อย' 'ได้' 'มั้ย' 'คะ' '?''\""
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e['0'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qQoQiUxVoxkb",
        "outputId": "8fd10bb6-fa01-4363-981c-9a5653df967d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"'สวัสดี', 'ค่ะ', ' ', 'ช่วย', 'จอง', 'ร้าน', 'อาหาร', 'เกาหลี', 'ให้', 'หน่อย', 'ได้', 'มั้ย', 'คะ', '?''\""
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "e['0'] = e['0'].apply(lambda x:re.sub(r\"(')\",'',x))\n",
        "e['0'] = e['0'].apply(lambda x:re.sub(r\"(,)\",'',x))\n",
        "e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "yZyYvHrNoQ_W",
        "outputId": "c45f2cbf-f69f-4144-e0f5-bb1257037d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8c53c8a0-1b9e-49c5-a71e-97a03a554b7d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>สวัสดี ค่ะ   ช่วย จอง ร้าน อาหาร เกาหลี ให้ หน...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ได้ เลย ค่ะ   แถว ไหน ดี คะ ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>แถว   ๆ   นิวยอร์ค ทาง ใต้ ก็ ได้ ค่ะ   แถว อี...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>โอเค ค่ะ   ดี เลย   มี ร้านเธอร์เดย์ คิท เช่น ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>เยี่ยม ค่ะ   อยาก ได้ โต๊ะ แปด คน ตอน ทุ่มนึง ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222728</th>\n",
              "      <td>ขอบ หนา ทั้ง   3   ถาด เลย มั้ย คะ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222729</th>\n",
              "      <td>สรุป เป็น พิซซ่าไซส์ ใหญ่ สาม ถาด นะ คะ   ทุก ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222730</th>\n",
              "      <td>ราคา ทั้งหมด   56 . 44   เหรียญ ค่ะ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222731</th>\n",
              "      <td>ค่ะ   เป็น ออเดอร์ สำหรับ ไป รับ ที่ ร้าน นะ คะ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222732</th>\n",
              "      <td>โอเค ค่ะ   ส่ง ออเดอร์ สำหรับ รับ ที่ ร้าน เรี...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>222733 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c53c8a0-1b9e-49c5-a71e-97a03a554b7d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c53c8a0-1b9e-49c5-a71e-97a03a554b7d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c53c8a0-1b9e-49c5-a71e-97a03a554b7d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                        0\n",
              "0       สวัสดี ค่ะ   ช่วย จอง ร้าน อาหาร เกาหลี ให้ หน...\n",
              "1                           ได้ เลย ค่ะ   แถว ไหน ดี คะ ?\n",
              "2       แถว   ๆ   นิวยอร์ค ทาง ใต้ ก็ ได้ ค่ะ   แถว อี...\n",
              "3       โอเค ค่ะ   ดี เลย   มี ร้านเธอร์เดย์ คิท เช่น ...\n",
              "4       เยี่ยม ค่ะ   อยาก ได้ โต๊ะ แปด คน ตอน ทุ่มนึง ...\n",
              "...                                                   ...\n",
              "222728                 ขอบ หนา ทั้ง   3   ถาด เลย มั้ย คะ\n",
              "222729  สรุป เป็น พิซซ่าไซส์ ใหญ่ สาม ถาด นะ คะ   ทุก ...\n",
              "222730                ราคา ทั้งหมด   56 . 44   เหรียญ ค่ะ\n",
              "222731    ค่ะ   เป็น ออเดอร์ สำหรับ ไป รับ ที่ ร้าน นะ คะ\n",
              "222732  โอเค ค่ะ   ส่ง ออเดอร์ สำหรับ รับ ที่ ร้าน เรี...\n",
              "\n",
              "[222733 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e['0']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfbtepDZrBCM",
        "outputId": "ac21cc9b-6b80-4fc9-a128-3a1bd1a50d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         สวัสดี ค่ะ   ช่วย จอง ร้าน อาหาร เกาหลี ให้ หน...\n",
              "1                             ได้ เลย ค่ะ   แถว ไหน ดี คะ ?\n",
              "2         แถว   ๆ   นิวยอร์ค ทาง ใต้ ก็ ได้ ค่ะ   แถว อี...\n",
              "3         โอเค ค่ะ   ดี เลย   มี ร้านเธอร์เดย์ คิท เช่น ...\n",
              "4         เยี่ยม ค่ะ   อยาก ได้ โต๊ะ แปด คน ตอน ทุ่มนึง ...\n",
              "                                ...                        \n",
              "222728                   ขอบ หนา ทั้ง   3   ถาด เลย มั้ย คะ\n",
              "222729    สรุป เป็น พิซซ่าไซส์ ใหญ่ สาม ถาด นะ คะ   ทุก ...\n",
              "222730                  ราคา ทั้งหมด   56 . 44   เหรียญ ค่ะ\n",
              "222731      ค่ะ   เป็น ออเดอร์ สำหรับ ไป รับ ที่ ร้าน นะ คะ\n",
              "222732    โอเค ค่ะ   ส่ง ออเดอร์ สำหรับ รับ ที่ ร้าน เรี...\n",
              "Name: 0, Length: 222733, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#transactions = e.iloc[:222732, :1].astype(str).values.tolist()\n",
        "#transactions"
      ],
      "metadata": {
        "id": "YY9OJZWarn8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.DataFrame([\"STD, City    State\",\n",
        "#\"33, Kolkata    West Bengal\",\n",
        "#\"44, Chennai    Tamil Nadu\",\n",
        "#\"40, Hyderabad    Telengana\",\n",
        "#\"80, Bangalore    Karnataka\"], columns=['row'])\n",
        "\n",
        "#out = pd.DataFrame(df.row.str.split(' ',2).tolist(),columns=['STD','City','State'])\n",
        "#out.drop(index=0,inplace=True)"
      ],
      "metadata": {
        "id": "IdTlE7ddyTG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e = pd.read_csv(\"/content/LST_Ver2 (1).csv\")\n",
        "e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2xtR23CyVWBv",
        "outputId": "dfc1aed2-987e-44b7-f215-d7f6321709d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1ead7637-b807-4694-96be-b3edcae04726\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>en_text</th>\n",
              "      <th>th_text</th>\n",
              "      <th>th_Sep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you but i don't have enough time .</td>\n",
              "      <td>ขอบคุณแต่ฉันไม่มีเวลาพอ</td>\n",
              "      <td>ขอบคุณ แต่ ฉัน ไม่ มี เวลา พอ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>oh, you know, when i get up i usually do my st...</td>\n",
              "      <td>โอ้,คุณรู้,เมื่อฉันตื่นฉันจะออกไปเดินเล่นยืดเส...</td>\n",
              "      <td>โอ้ , คุณ รู้ , เมื่อ ฉัน ตื่น ฉัน จะ ออกไป เด...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>the duty of a policeman is to safeguard people .</td>\n",
              "      <td>หน้าที่ของตำรวจคือการปกป้องประชาชน</td>\n",
              "      <td>หน้าที่ ของ ตำรวจ คือ การ ปกป้อง ประชาชน</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>it's female vanity .</td>\n",
              "      <td>มันเป็นความโอหังของเพศหญิง</td>\n",
              "      <td>มัน เป็นความ โอหัง ของ เพศ หญิง</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>please keep a sharp lookout .</td>\n",
              "      <td>โปรดคอยดูอย่าเผลอ</td>\n",
              "      <td>โปรด คอย ดู อย่า เผลอ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681427</th>\n",
              "      <td>681427</td>\n",
              "      <td>when wijai talked to me on the phone , his voi...</td>\n",
              "      <td>ตอนวิจัยพูดโทรศัพท์กับดิฉันเสียงเขาแตกพร่าเพรา...</td>\n",
              "      <td>ตอน วิจัย พูด โทรศัพท์ กับ ดิฉัน เสียง เขา แตก...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681428</th>\n",
              "      <td>681428</td>\n",
              "      <td>the bus terminal is on the west side of the ci...</td>\n",
              "      <td>สถานีรถโดยสารทางตะวันตกของเมือง</td>\n",
              "      <td>สถานี รถ โดยสาร ทาง ตะวันตก ของ เมือง</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681429</th>\n",
              "      <td>681429</td>\n",
              "      <td>encapsulate .</td>\n",
              "      <td>ลักษณะภายนอก</td>\n",
              "      <td>ลักษณะ ภาย นอก</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681430</th>\n",
              "      <td>681430</td>\n",
              "      <td>death frightens me , specifically my own death .</td>\n",
              "      <td>ความตายทำให้ผมกลัวโดยเฉพาะอย่างยิ่งการตายของผมเอง</td>\n",
              "      <td>ความ ตาย ทำ ให้ ผม กลัว โดย เฉพาะอย่างยิ่ง การ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681431</th>\n",
              "      <td>681431</td>\n",
              "      <td>i weigh sixty kilograms .</td>\n",
              "      <td>ฉันหนักหกสิบกิโลกรัม</td>\n",
              "      <td>ฉัน หนัก หก สิบ กิโลกรัม</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>681432 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ead7637-b807-4694-96be-b3edcae04726')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ead7637-b807-4694-96be-b3edcae04726 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ead7637-b807-4694-96be-b3edcae04726');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Unnamed: 0                                            en_text  \\\n",
              "0                0           thank you but i don't have enough time .   \n",
              "1                1  oh, you know, when i get up i usually do my st...   \n",
              "2                2   the duty of a policeman is to safeguard people .   \n",
              "3                3                               it's female vanity .   \n",
              "4                4                      please keep a sharp lookout .   \n",
              "...            ...                                                ...   \n",
              "681427      681427  when wijai talked to me on the phone , his voi...   \n",
              "681428      681428  the bus terminal is on the west side of the ci...   \n",
              "681429      681429                                      encapsulate .   \n",
              "681430      681430   death frightens me , specifically my own death .   \n",
              "681431      681431                          i weigh sixty kilograms .   \n",
              "\n",
              "                                                  th_text  \\\n",
              "0                                 ขอบคุณแต่ฉันไม่มีเวลาพอ   \n",
              "1       โอ้,คุณรู้,เมื่อฉันตื่นฉันจะออกไปเดินเล่นยืดเส...   \n",
              "2                      หน้าที่ของตำรวจคือการปกป้องประชาชน   \n",
              "3                              มันเป็นความโอหังของเพศหญิง   \n",
              "4                                       โปรดคอยดูอย่าเผลอ   \n",
              "...                                                   ...   \n",
              "681427  ตอนวิจัยพูดโทรศัพท์กับดิฉันเสียงเขาแตกพร่าเพรา...   \n",
              "681428                    สถานีรถโดยสารทางตะวันตกของเมือง   \n",
              "681429                                       ลักษณะภายนอก   \n",
              "681430  ความตายทำให้ผมกลัวโดยเฉพาะอย่างยิ่งการตายของผมเอง   \n",
              "681431                               ฉันหนักหกสิบกิโลกรัม   \n",
              "\n",
              "                                                   th_Sep  \n",
              "0                           ขอบคุณ แต่ ฉัน ไม่ มี เวลา พอ  \n",
              "1       โอ้ , คุณ รู้ , เมื่อ ฉัน ตื่น ฉัน จะ ออกไป เด...  \n",
              "2                หน้าที่ ของ ตำรวจ คือ การ ปกป้อง ประชาชน  \n",
              "3                        มัน เป็นความ โอหัง ของ เพศ หญิง   \n",
              "4                                   โปรด คอย ดู อย่า เผลอ  \n",
              "...                                                   ...  \n",
              "681427  ตอน วิจัย พูด โทรศัพท์ กับ ดิฉัน เสียง เขา แตก...  \n",
              "681428              สถานี รถ โดยสาร ทาง ตะวันตก ของ เมือง  \n",
              "681429                                     ลักษณะ ภาย นอก  \n",
              "681430  ความ ตาย ทำ ให้ ผม กลัว โดย เฉพาะอย่างยิ่ง การ...  \n",
              "681431                          ฉัน หนัก หก สิบ กิโลกรัม   \n",
              "\n",
              "[681432 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e = e.drop(['th_text'], axis=1)\n",
        "e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "BCr_99SUZI7S",
        "outputId": "38f736f9-5915-4c21-f6df-8b947a1a8ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-eb67bb2b-4797-4b00-848e-39ede22de692\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>en_text</th>\n",
              "      <th>th_Sep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you but i don't have enough time .</td>\n",
              "      <td>ขอบคุณ แต่ ฉัน ไม่ มี เวลา พอ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>oh, you know, when i get up i usually do my st...</td>\n",
              "      <td>โอ้ , คุณ รู้ , เมื่อ ฉัน ตื่น ฉัน จะ ออกไป เด...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>the duty of a policeman is to safeguard people .</td>\n",
              "      <td>หน้าที่ ของ ตำรวจ คือ การ ปกป้อง ประชาชน</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>it's female vanity .</td>\n",
              "      <td>มัน เป็นความ โอหัง ของ เพศ หญิง</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>please keep a sharp lookout .</td>\n",
              "      <td>โปรด คอย ดู อย่า เผลอ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681427</th>\n",
              "      <td>681427</td>\n",
              "      <td>when wijai talked to me on the phone , his voi...</td>\n",
              "      <td>ตอน วิจัย พูด โทรศัพท์ กับ ดิฉัน เสียง เขา แตก...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681428</th>\n",
              "      <td>681428</td>\n",
              "      <td>the bus terminal is on the west side of the ci...</td>\n",
              "      <td>สถานี รถ โดยสาร ทาง ตะวันตก ของ เมือง</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681429</th>\n",
              "      <td>681429</td>\n",
              "      <td>encapsulate .</td>\n",
              "      <td>ลักษณะ ภาย นอก</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681430</th>\n",
              "      <td>681430</td>\n",
              "      <td>death frightens me , specifically my own death .</td>\n",
              "      <td>ความ ตาย ทำ ให้ ผม กลัว โดย เฉพาะอย่างยิ่ง การ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681431</th>\n",
              "      <td>681431</td>\n",
              "      <td>i weigh sixty kilograms .</td>\n",
              "      <td>ฉัน หนัก หก สิบ กิโลกรัม</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>681432 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb67bb2b-4797-4b00-848e-39ede22de692')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb67bb2b-4797-4b00-848e-39ede22de692 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb67bb2b-4797-4b00-848e-39ede22de692');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Unnamed: 0                                            en_text  \\\n",
              "0                0           thank you but i don't have enough time .   \n",
              "1                1  oh, you know, when i get up i usually do my st...   \n",
              "2                2   the duty of a policeman is to safeguard people .   \n",
              "3                3                               it's female vanity .   \n",
              "4                4                      please keep a sharp lookout .   \n",
              "...            ...                                                ...   \n",
              "681427      681427  when wijai talked to me on the phone , his voi...   \n",
              "681428      681428  the bus terminal is on the west side of the ci...   \n",
              "681429      681429                                      encapsulate .   \n",
              "681430      681430   death frightens me , specifically my own death .   \n",
              "681431      681431                          i weigh sixty kilograms .   \n",
              "\n",
              "                                                   th_Sep  \n",
              "0                           ขอบคุณ แต่ ฉัน ไม่ มี เวลา พอ  \n",
              "1       โอ้ , คุณ รู้ , เมื่อ ฉัน ตื่น ฉัน จะ ออกไป เด...  \n",
              "2                หน้าที่ ของ ตำรวจ คือ การ ปกป้อง ประชาชน  \n",
              "3                        มัน เป็นความ โอหัง ของ เพศ หญิง   \n",
              "4                                   โปรด คอย ดู อย่า เผลอ  \n",
              "...                                                   ...  \n",
              "681427  ตอน วิจัย พูด โทรศัพท์ กับ ดิฉัน เสียง เขา แตก...  \n",
              "681428              สถานี รถ โดยสาร ทาง ตะวันตก ของ เมือง  \n",
              "681429                                     ลักษณะ ภาย นอก  \n",
              "681430  ความ ตาย ทำ ให้ ผม กลัว โดย เฉพาะอย่างยิ่ง การ...  \n",
              "681431                          ฉัน หนัก หก สิบ กิโลกรัม   \n",
              "\n",
              "[681432 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hopethai(df):\n",
        "  \n",
        "  athit = []\n",
        "  i = 0\n",
        "  \n",
        "  for i in range(0, 681431):\n",
        "     j = df['th_Sep'][i].replace(',', '').replace(\"'\", '')\n",
        "     athit.append(j)\n",
        "     i += 1\n",
        "  return athit\n",
        "#print(hope(e)[0:6])"
      ],
      "metadata": {
        "id": "HbsfPA0ZZCT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hopefulthai = hopethai(e)\n",
        "hopefulthai[0:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgM57v_1zk4",
        "outputId": "9b59e433-5f3f-4098-cccf-e317bd83dec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ขอบคุณ แต่ ฉัน ไม่ มี เวลา พอ',\n",
              " 'โอ้  คุณ รู้  เมื่อ ฉัน ตื่น ฉัน จะ ออกไป เดินเล่น ยืด เส้น ยืด สาย กับ สุนัข ของ ฉัน เสมอ ',\n",
              " 'หน้าที่ ของ ตำรวจ คือ การ ปกป้อง ประชาชน',\n",
              " 'มัน เป็นความ โอหัง ของ เพศ หญิง ',\n",
              " 'โปรด คอย ดู อย่า เผลอ',\n",
              " 'ขอร้อง ให้ some body ทำ บางอย่าง',\n",
              " 'ใช้ ความ รุนแรง',\n",
              " 'ฉัน เกรง ว่า ฉัน ไม่ สามารถ มา ได้ ใน วัน นั้น',\n",
              " 'ในที่สุด ฉัน ก็มี โอกาส ได้ พบ เชอร์ เล่ย ์ เมื่อวาน นี้ เธอ และ ฉัน ทำได้ ดี ตั้งแต่ เริ่มต้น เธอ เป็น คน ตลก จริง ๆ',\n",
              " 'ไม่เป็นไร ขอบคุณ',\n",
              " 'การ ให้ ความ ยุติธรรม',\n",
              " 'การ จำ ผิด',\n",
              " 'ช่วง ต่าง สี่ หรือ ห้า โน้ต ของ เสียง ดนตรี',\n",
              " 'กระดาษ อิง ค ์ เจต H P ชั้น ยอด',\n",
              " 'เหตุการณ์ ที่ ไม่ คาดคิด มา ก่อน',\n",
              " 'กำจัด',\n",
              " 'การ กิน สินบน โดย ผู้ พิพากษา นั้น อาจ ถือ ได้ ว่า เป็นการ ทำลาย ความ ยุติธรรม',\n",
              " 'คำ ที่ มี 6 ตัว อักษร',\n",
              " 'ฉัน ปวด ฟัน และ อื่นๆ',\n",
              " 'ครึ่ง โหล']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(hopefulthai)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7rBQUpLUJB4",
        "outputId": "011fc0ac-6e51-4354-d731-3c0d301b6865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "681431"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hopeeng(df):\n",
        "  \n",
        "  athit = []\n",
        "  i = 0\n",
        "  \n",
        "  for i in range(0, 681431):\n",
        "     j = df['en_text'][i].replace(',', '').replace(\"'\", '')\n",
        "     athit.append(j)\n",
        "     i += 1\n",
        "  return athit\n",
        "#print(hope(e)[0:6])"
      ],
      "metadata": {
        "id": "dUg0Xv9_TVoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hopefuleng = hopeeng(e)\n",
        "hopefuleng[0:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCC_tuWYTXW3",
        "outputId": "9fe3c7d8-3352-4473-e716-761b67c001f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['thank you but i dont have enough time .',\n",
              " 'oh you know when i get up i usually do my stretching and walk my dog .',\n",
              " 'the duty of a policeman is to safeguard people .',\n",
              " 'its female vanity .',\n",
              " 'please keep a sharp lookout .',\n",
              " 'ask somebody to do something .',\n",
              " 'get physical .',\n",
              " 'i m afraid i can t come that day .',\n",
              " 'finally i had a chance to meet shirley yesterday she and i hit it off well from the start she is real fun .',\n",
              " 'thanks anyway .',\n",
              " 'administration of justice .',\n",
              " 'a slip of memory .',\n",
              " 'perfect interval .',\n",
              " 'hp premium inkjet paper .',\n",
              " 'an unforeseen occurrence .',\n",
              " 'do away with .',\n",
              " 'corruption among judges can be regarded as a rape of justice .',\n",
              " 'a word of six letters .',\n",
              " 'i got a toothache etc .',\n",
              " 'half a dozen .']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(hopefuleng)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ajn-ogO8T6QQ",
        "outputId": "37e67322-253f-4d6c-e864-2865ed9be839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "681431"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#b.to_csv(\"22k.csv\")"
      ],
      "metadata": {
        "id": "wwYBL5inIvAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a = np.array(TM1)\n",
        "#a"
      ],
      "metadata": {
        "id": "MuW9UbOz3D45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#i = 0\n",
        "#a_list = TM1\n",
        "#textfile = open(\"TM1_file.txt\", \"w\")\n",
        "#for element in a_list[i]:\n",
        "    #textfile.write(element)\n",
        "    #i += 1\n",
        "#textfile.close()\n"
      ],
      "metadata": {
        "id": "k2TK1cCI5sM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "#np.savetxt(\"HOPE.csv\", \n",
        "           #a,\n",
        "           #delimiter =\"]\", \n",
        "           #fmt ='% s', encoding='utf8')"
      ],
      "metadata": {
        "id": "DEZ7DMX4wkAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GF = pd.read_csv(\"/content/HOPE.csv\", on_bad_lines = 'skip')\n",
        "#GF"
      ],
      "metadata": {
        "id": "nULP6ufI07-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b"
      ],
      "metadata": {
        "id": "zhFdzMl9JIT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#c = pd.read_csv(\"/content/22k_remove.csv\")\n",
        "#c"
      ],
      "metadata": {
        "id": "nmBYN_-7Qdyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def listToString(s): \n",
        "    \n",
        "    # initialize an empty string\n",
        "    #str1 = \" \" \n",
        "    \n",
        "    # return string  \n",
        "    #return (str1.join(s))\n",
        "        \n",
        "        \n",
        "# Driver code    \n",
        "#s = ['Geeks', 'for', 'Geeks']\n",
        "#print(listToString(s)) "
      ],
      "metadata": {
        "id": "OSy7MQ_GJ3Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#myList = TM1[0:3]\n",
        "#result = ' '.join([item for sub_list in myList for item in sub_list])"
      ],
      "metadata": {
        "id": "3JyCptlOXKNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#result"
      ],
      "metadata": {
        "id": "uHxxlyoMYIrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#assorted_government = pd.read_csv(\"/content/scb-mt-en-th-2020/assorted_government.csv\")\n",
        "#assorted_government"
      ],
      "metadata": {
        "id": "WclQa23Nmppl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#msr_paraphrase = pd.read_csv(\"/content/scb-mt-en-th-2020/msr_paraphrase.csv\")\n",
        "#msr_paraphrase"
      ],
      "metadata": {
        "id": "JAZi8aKPh-wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_master_1 = pd.read_csv(\"/content/task_master_1.csv\")\n",
        "task_master_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "dUGz2jCWbDZR",
        "outputId": "7284a219-19c4-4dc1-f9a8-85a66e94c58c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f370988f-e820-4284-ab9a-93b48423df9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en_text</th>\n",
              "      <th>th_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, I'm looking to book a table for Korean fod.</td>\n",
              "      <td>สวัสดีค่ะ ช่วยจองร้านอาหารเกาหลีให้หน่อยได้มั้...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok, what area are you thinking about?</td>\n",
              "      <td>ได้เลยค่ะ แถวไหนดีคะ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Somewhere in Southern NYC, maybe the East Vill...</td>\n",
              "      <td>แถว ๆ นิวยอร์คทางใต้ก็ได้ค่ะ แถวอีสต์วิลเลจอะไ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ok, great. There's Thursday Kitchen, it has gr...</td>\n",
              "      <td>โอเคค่ะ ดีเลย มีร้านเธอร์เดย์คิทเช่นอยู่ รีวิว...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>That's great. So I need a table for tonight at...</td>\n",
              "      <td>เยี่ยมค่ะ อยากได้โต๊ะแปดคนตอนทุ่มนึงค่ะ นั่งตร...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222728</th>\n",
              "      <td>did you want thick crust for all 3 pizzas?</td>\n",
              "      <td>ขอบหนาทั้ง 3 ถาดเลยมั้ยคะ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222729</th>\n",
              "      <td>you said you want to order 3 large pizzas, all...</td>\n",
              "      <td>สรุปเป็นพิซซ่าไซส์ใหญ่สามถาดนะคะ ทุกถาดพิเศษชี...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222730</th>\n",
              "      <td>the total for your order is $56.44.</td>\n",
              "      <td>ราคาทั้งหมด 56.44 เหรียญค่ะ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222731</th>\n",
              "      <td>Yes, can you make that for pickup, please?</td>\n",
              "      <td>ค่ะ เป็นออเดอร์สำหรับไปรับที่ร้านนะคะ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222732</th>\n",
              "      <td>great, i've submitted your order for pick up. ...</td>\n",
              "      <td>โอเคค่ะ ส่งออเดอร์สำหรับรับที่ร้านเรียบร้อยแล้...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>222733 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f370988f-e820-4284-ab9a-93b48423df9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f370988f-e820-4284-ab9a-93b48423df9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f370988f-e820-4284-ab9a-93b48423df9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  en_text  \\\n",
              "0         Hi, I'm looking to book a table for Korean fod.   \n",
              "1                   Ok, what area are you thinking about?   \n",
              "2       Somewhere in Southern NYC, maybe the East Vill...   \n",
              "3       Ok, great. There's Thursday Kitchen, it has gr...   \n",
              "4       That's great. So I need a table for tonight at...   \n",
              "...                                                   ...   \n",
              "222728         did you want thick crust for all 3 pizzas?   \n",
              "222729  you said you want to order 3 large pizzas, all...   \n",
              "222730                the total for your order is $56.44.   \n",
              "222731         Yes, can you make that for pickup, please?   \n",
              "222732  great, i've submitted your order for pick up. ...   \n",
              "\n",
              "                                                  th_text  \n",
              "0       สวัสดีค่ะ ช่วยจองร้านอาหารเกาหลีให้หน่อยได้มั้...  \n",
              "1                                   ได้เลยค่ะ แถวไหนดีคะ?  \n",
              "2       แถว ๆ นิวยอร์คทางใต้ก็ได้ค่ะ แถวอีสต์วิลเลจอะไ...  \n",
              "3       โอเคค่ะ ดีเลย มีร้านเธอร์เดย์คิทเช่นอยู่ รีวิว...  \n",
              "4       เยี่ยมค่ะ อยากได้โต๊ะแปดคนตอนทุ่มนึงค่ะ นั่งตร...  \n",
              "...                                                   ...  \n",
              "222728                          ขอบหนาทั้ง 3 ถาดเลยมั้ยคะ  \n",
              "222729  สรุปเป็นพิซซ่าไซส์ใหญ่สามถาดนะคะ ทุกถาดพิเศษชี...  \n",
              "222730                        ราคาทั้งหมด 56.44 เหรียญค่ะ  \n",
              "222731              ค่ะ เป็นออเดอร์สำหรับไปรับที่ร้านนะคะ  \n",
              "222732  โอเคค่ะ ส่งออเดอร์สำหรับรับที่ร้านเรียบร้อยแล้...  \n",
              "\n",
              "[222733 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hopeeng(df):\n",
        "  \n",
        "  athit = []\n",
        "  i = 0\n",
        "  \n",
        "  for i in range(0, 222732):\n",
        "     j = df['en_text'][i].replace(',', '').replace(\".\", '').replace(\"?\", '').replace('\"', \"\").replace(\"'\", \"\")\n",
        "     athit.append(j)\n",
        "     i += 1\n",
        "  return athit\n",
        "#print(hope(task_master_1)[0:6])"
      ],
      "metadata": {
        "id": "CmZw87VG3RgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hopefuleng = hopeeng(task_master_1)\n",
        "hopefuleng[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FZuswn54H0f",
        "outputId": "bcc3887e-6d53-480b-c75a-404554d73e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi Im looking to book a table for Korean fod',\n",
              " 'Ok what area are you thinking about',\n",
              " 'Somewhere in Southern NYC maybe the East Village',\n",
              " 'Ok great Theres Thursday Kitchen it has great reviews',\n",
              " 'Thats great So I need a table for tonight at 7 pm for 8 people We dont want to sit at the bar but anywhere else is fine',\n",
              " 'They dont have any availability for 7 pm',\n",
              " 'What times are available',\n",
              " '5 or 8',\n",
              " 'Ok do you have a second choice',\n",
              " 'Let me check',\n",
              " 'Lets try Boka are they free for 8 people at 7',\n",
              " 'Great lets book that',\n",
              " 'Ok great are there any other requests',\n",
              " 'No thats it just book',\n",
              " 'Great should I use your account you have open with them',\n",
              " 'Great You will get a confirmation to your phone soon',\n",
              " 'Hi I would like to see if the Movie What Men Want is playing here',\n",
              " 'Yes its showing here would you like to purchase a ticket',\n",
              " 'Yes for me and a friend so two tickets please',\n",
              " 'What time is that moving playing today']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(task_master_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DegqlJ98Bvc8",
        "outputId": "8be99c4a-3c1c-4f2d-85d7-b93f24df34ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "222733"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sum = pd.concat([msr_paraphrase[\"th_text\"], task_master_1[\"th_text\"],assorted_government[\"th_text\"]], axis=0)\n",
        "#sum"
      ],
      "metadata": {
        "id": "lMFWnGZVwPF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fifteenM = pd.read_csv(\"/content/drive/MyDrive/15M/15M_tatoe.csv\")\n",
        "#fifteenM"
      ],
      "metadata": {
        "id": "HwazJzc0-PuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fifteenM['source_en'].array"
      ],
      "metadata": {
        "id": "uoQu_5DV_Exs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!gdown --id 1l-LJgsqOWYzA8E1v4wjGPGfTiXWNO94v"
      ],
      "metadata": {
        "id": "Ce3A46oBj0Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATbzWIL4D28W"
      },
      "outputs": [],
      "source": [
        "#!unzip drive/MyDrive/Fairseq_Tutorial/en-th.zip -d drive/MyDrive/Fairseq_Tutorial/Copy/data/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hopefuleng[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnXcECeS5SKf",
        "outputId": "344afd15-e7fc-4bcb-e76f-205745fb3185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi Im looking to book a table for Korean fod',\n",
              " 'Ok what area are you thinking about',\n",
              " 'Somewhere in Southern NYC maybe the East Village',\n",
              " 'Ok great Theres Thursday Kitchen it has great reviews',\n",
              " 'Thats great So I need a table for tonight at 7 pm for 8 people We dont want to sit at the bar but anywhere else is fine']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hopefulthai[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx844rs_5Wdv",
        "outputId": "abd57f27-2478-4013-e20f-dd580dae7ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['สวัสดี ค่ะ   ช่วย จอง ร้าน อาหาร เกาหลี ให้ หน่อย ได้ มั้ย คะ ?',\n",
              " 'ได้ เลย ค่ะ   แถว ไหน ดี คะ ?',\n",
              " 'แถว   ๆ   นิวยอร์ค ทาง ใต้ ก็ ได้ ค่ะ   แถว อีสต์วิลเลจ อะไร งี้',\n",
              " 'โอเค ค่ะ   ดี เลย   มี ร้านเธอร์เดย์ คิท เช่น อยู่   รี วิว ดี ด้วย นะ คะ',\n",
              " 'เยี่ยม ค่ะ   อยาก ได้ โต๊ะ แปด คน ตอน ทุ่มนึง ค่ะ   นั่ง ตรง ไหน ก็ ได้ แต่ ไม่ เอา ตรง บาร์ นะ คะ']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation"
      ],
      "metadata": {
        "id": "h-IR8t5ANOth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#path = \"drive/MyDrive/Fairseq_Tutorial/Copy/data/\"\n",
        "path = \"/content/\"\n",
        "#en = open(path+\"en_translated\").read().translate(str.maketrans(\"\",\"\",punctuation.replace(\"'\",\"\"))).split(\"\\n\")\n",
        "#th = open(path+\"th_translated_neu\").read().translate(str.maketrans(\"\",\"\",punctuation.replace(\"'\",\"\"))).split(\"\\n\")"
      ],
      "metadata": {
        "id": "BY60Y3WyInfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#th"
      ],
      "metadata": {
        "id": "a9Fj5seJu_K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(en[:5])"
      ],
      "metadata": {
        "id": "-VOsPcCsL54h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(th[:5])"
      ],
      "metadata": {
        "id": "Ts_XkQ2dL-SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sel_hopefuleng, sel_hopefulthai = [],[]\n",
        "for z,t in zip(hopefuleng,hopefulthai):\n",
        "  if z.count(' ') >= 10:\n",
        "    sel_hopefuleng.append(z)\n",
        "    sel_hopefulthai.append(t.strip())"
      ],
      "metadata": {
        "id": "zgzFY1GDL_Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sel_hopefuleng)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jUibnOYt3u7",
        "outputId": "76ea4720-5937-4e94-f253-3154484f0ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71333"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sel_hopefuleng[100000:100001]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaSR3yZety2r",
        "outputId": "0c991960-cb5a-49c3-a376-00226bf96513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(hopefulthai)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbIAahTxuFRj",
        "outputId": "4f17d9c9-f7db-43ea-cd93-53cef2eee8e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "222732"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(hopefuleng)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRKXPs00uHqS",
        "outputId": "215ecd42-487c-4dee-d5dc-96f718813cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "681431"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hopefulthai[222009:222011]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yknD_okGNAht",
        "outputId": "45279fbd-9164-4384-d1f9-403e1c6c8d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ร้าน แรก ชื่อ บอมเบย์บาร์ แอนด์ กริลล์   ร้าน อาหาร อินเดีย มี สไตล์   และ มี บรรยากาศ ที่ อบอุ่น   มี ฟูลบาร์   และ อาหาร จาน พิเศษ มากมาย ค่ะ',\n",
              " 'ร้าน ที่ สอง คือ   อินเดีย   โอเว่น   ร้าน อาหาร อินเดีย บรรยากาศ สบาย ๆ   ด้วย การ ตกแต่ง ที่ แปลก ใหม่   เสิร์ฟ อาหาร แบบ ดั้งเดิม   และ มี บุฟเฟ่ต์ อาหาร กลาง วัน ค่ะ']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_en_100k = sel_en[:100000]\n",
        "# test_en_100k = sel_en[100000:110000]\n",
        "# val_en_100k = sel_en[110000:111000]\n",
        "# train_th_100k = sel_th[:100000]\n",
        "# test_th_100k = sel_th[100000:110000]\n",
        "# val_th_100k = sel_th[110000:111000]\n",
        "\n",
        "# train_en_50k = sel_en[:50000]\n",
        "# test_en_50k = sel_en[50000:55000]\n",
        "# val_en_50k = sel_en[55000:55500]\n",
        "# train_th_50k = sel_th[:50000]\n",
        "# test_th_50k = sel_th[50000:55000]\n",
        "# val_th_50k = sel_th[55000:55500]\n",
        "\n",
        "train_en_220k = hopefuleng[:221000]\n",
        "test_en_220k = hopefuleng[221000:222000]\n",
        "val_en_220k = hopefuleng[222000:]\n",
        "train_th_220k = hopefulthai[:221000]\n",
        "test_th_220k = hopefulthai[221000:222000]\n",
        "val_th_220k = hopefulthai[222000:]"
      ],
      "metadata": {
        "id": "EkaZdlpRPtH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open(path+\"train_en_100k\",'w').write(\"\\n\".join(train_en_100k))\n",
        "# open(path+\"test_en_100k\",'w').write(\"\\n\".join(test_en_100k))\n",
        "# open(path+\"val_en_100k\",'w').write(\"\\n\".join(val_en_100k))\n",
        "# open(path+\"train_th_100k\",'w').write(\"\\n\".join(train_th_100k))\n",
        "# open(path+\"test_th_100k\",'w').write(\"\\n\".join(test_th_100k))\n",
        "# open(path+\"val_th_100k\",'w').write(\"\\n\".join(val_th_100k))\n",
        "\n",
        "# open(path+\"train_en_50k\",'w').write(\"\\n\".join(train_en_50k))\n",
        "# open(path+\"test_en_50k\",'w').write(\"\\n\".join(test_en_50k))\n",
        "# open(path+\"val_en_50k\",'w').write(\"\\n\".join(val_en_50k))\n",
        "# open(path+\"train_th_50k\",'w').write(\"\\n\".join(train_th_50k))\n",
        "# open(path+\"test_th_50k\",'w').write(\"\\n\".join(test_th_50k))\n",
        "# open(path+\"val_th_50k\",'w').write(\"\\n\".join(val_th_50k))\n",
        "\n",
        "open(path+\"train_en_220k\",'w').write(\"\\n\".join(train_en_220k))\n",
        "open(path+\"test_en_220k\",'w').write(\"\\n\".join(test_en_220k))\n",
        "open(path+\"val_en_220k\",'w').write(\"\\n\".join(val_en_220k))\n",
        "open(path+\"train_th_220k\",'w').write(\"\\n\".join(train_th_220k))\n",
        "open(path+\"test_th_220k\",'w').write(\"\\n\".join(test_th_220k))\n",
        "open(path+\"val_th_220k\",'w').write(\"\\n\".join(val_th_220k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVmnuaZTNDmm",
        "outputId": "3cba63ad-f84b-4ed6-ecab-2031c4ef0eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17580177"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sIkOw23ltzV",
        "outputId": "9cf0d403-849b-4856-c008-201a959819d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install subword-nmt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX0wVCOQwvcN",
        "outputId": "645d1230-a589-4046-a9f2-ab056a4d6716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting subword-nmt\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from subword-nmt) (4.63.0)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: mock, subword-nmt\n",
            "Successfully installed mock-4.0.3 subword-nmt-0.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!mkdir drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe"
      ],
      "metadata": {
        "id": "gejcIYA9ww98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETGobF-09WPh",
        "outputId": "bd982501-3293-4b89-e80b-0bbdbdf79b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir bpe"
      ],
      "metadata": {
        "id": "-ijkwVj-lUeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!subword-nmt learn-bpe -s 200000 \\\n",
        "< train_en_220k > bpe/src.bpe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9DUlKwalaVZ",
        "outputId": "46e1c9f1-bd7b-4815-a1e9-7620be81bd8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 18% 36562/200000 [00:47<01:21, 2012.09it/s]no pair has frequency >= 2. Stopping\n",
            " 18% 36731/200000 [00:48<03:33, 765.02it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!subword-nmt learn-bpe -s 200000 \\\n",
        "< train_th_220k > bpe/trg.bpe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2cyhv5wlh1w",
        "outputId": "90cc6c69-be79-44dc-9560-6cf16c38f52c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 11% 21501/200000 [00:18<01:22, 2166.56it/s]no pair has frequency >= 2. Stopping\n",
            " 11% 21747/200000 [00:18<02:35, 1147.82it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!subword-nmt apply-bpe -c bpe/src.bpe \\\n",
        "< train_en_220k > bpe/train.bpe.src\n",
        "\n",
        "!subword-nmt apply-bpe -c bpe/src.bpe \\\n",
        "< test_en_220k > bpe/test.bpe.src\n",
        "\n",
        "!subword-nmt apply-bpe -c bpe/src.bpe \\\n",
        "< val_en_220k > bpe/val.bpe.src"
      ],
      "metadata": {
        "id": "jicMYdfMlqpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!subword-nmt apply-bpe -c bpe/trg.bpe \\\n",
        "< train_th_220k > bpe/train.bpe.trg\n",
        "\n",
        "!subword-nmt apply-bpe -c bpe/trg.bpe \\\n",
        "< test_th_220k > bpe/test.bpe.trg\n",
        "\n",
        "!subword-nmt apply-bpe -c bpe/trg.bpe \\\n",
        "< val_th_220k > bpe/val.bpe.trg"
      ],
      "metadata": {
        "id": "5CXn0-gllquw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l bpe/*bpe*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYB85Sgrlqx-",
        "outputId": "a7a87c7a-e067-4c5c-bab0-e3b6052dfafa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   36732 bpe/src.bpe\n",
            "     999 bpe/test.bpe.src\n",
            "     999 bpe/test.bpe.trg\n",
            "  220999 bpe/train.bpe.src\n",
            "  220999 bpe/train.bpe.trg\n",
            "   21748 bpe/trg.bpe\n",
            "  459430 bpe/val.bpe.src\n",
            "  459430 bpe/val.bpe.trg\n",
            " 1421336 total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_gj0XdEJlq0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!subword-nmt learn-bpe -s 15000 \\\n",
        "#< drive/MyDrive/Fairseq_Tutorial/Copy/data/train_en_10k > drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/src.bpe"
      ],
      "metadata": {
        "id": "jHm0Rp0VPWyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!subword-nmt learn-bpe -s 15000 \\\n",
        "#< drive/MyDrive/Fairseq_Tutorial/Copy/data/train_th_10k > drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/trg.bpe"
      ],
      "metadata": {
        "id": "ItMf2xY1WyhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!subword-nmt apply-bpe -c drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/src.bpe \\\n",
        "#< drive/MyDrive/Fairseq_Tutorial/Copy/data/train_en_10k > drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/train.bpe.src\n",
        "\n",
        "#!subword-nmt apply-bpe -c drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/src.bpe \\\n",
        "#< drive/MyDrive/Fairseq_Tutorial/Copy/data/test_en_10k > drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/test.bpe.src\n",
        "\n",
        "#!subword-nmt apply-bpe -c drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/src.bpe \\\n",
        "#< drive/MyDrive/Fairseq_Tutorial/Copy/data/val_en_10k > drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/val.bpe.src"
      ],
      "metadata": {
        "id": "rAs_dJhDXQI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!subword-nmt apply-bpe -c drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/trg.bpe \\\n",
        "#< drive/MyDrive/Fairseq_Tutorial/Copy/data/train_th_10k > drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/train.bpe.trg\n",
        "\n",
        "#!subword-nmt apply-bpe -c drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/trg.bpe \\\n",
        "#< drive/MyDrive/Fairseq_Tutorial/Copy/data/test_th_10k > drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/test.bpe.trg\n",
        "\n",
        "#!subword-nmt apply-bpe -c drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/trg.bpe \\\n",
        "#< drive/MyDrive/Fairseq_Tutorial/Copy/data/val_th_10k > drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/val.bpe.trg"
      ],
      "metadata": {
        "id": "Pb0VfcmWY2Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!ls drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/"
      ],
      "metadata": {
        "id": "6knOdcMpZHgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!wc -l drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/*bpe*"
      ],
      "metadata": {
        "id": "spCL2Q0dZ5mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tDYBhfDPK8a",
        "outputId": "1cfbf17f-7326-4433-8e1e-35bd10596e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##rm -r fairseq"
      ],
      "metadata": {
        "id": "eECJOQWEPCTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pytorch/fairseq.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f13yHk60aHr_",
        "outputId": "501db84f-751f-4969-b42a-40c3382ee362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 31005, done.\u001b[K\n",
            "remote: Counting objects: 100% (636/636), done.\u001b[K\n",
            "remote: Compressing objects: 100% (373/373), done.\u001b[K\n",
            "remote: Total 31005 (delta 297), reused 506 (delta 253), pack-reused 30369\u001b[K\n",
            "Receiving objects: 100% (31005/31005), 21.27 MiB | 36.24 MiB/s, done.\n",
            "Resolving deltas: 100% (22996/22996), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fairseq"
      ],
      "metadata": {
        "id": "6FtOhajSepFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/fairseq/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIsg4Xi1hpk4",
        "outputId": "45f6db5f-e09a-4a6b-a739-a6d7dc62b5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fairseq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git checkout v0.9.0\n",
        "!git checkout"
      ],
      "metadata": {
        "id": "2PPQ2jz2bYFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43494e90-0350-4b9e-a4b6-95a16a3245f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your branch is up to date with 'origin/main'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##%cd /content/\n",
        "##!rm -rf fairseq"
      ],
      "metadata": {
        "id": "IQ9kKVV302kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##!wget -c https://github.com/pytorch/fairseq/archive/refs/tags/v0.9.0.zip"
      ],
      "metadata": {
        "id": "bET24S4i0z_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##!unzip v0.9.0.zip"
      ],
      "metadata": {
        "id": "g51wnO580-Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##!mv fairseq-0.9.0 fairseq"
      ],
      "metadata": {
        "id": "bLo8_Ogp1GXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##%cd /content/fairseq/"
      ],
      "metadata": {
        "id": "mUfIg1XS1OmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --editable ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juv6yWiXhrUZ",
        "outputId": "d571d3c2-40f5-4406-c485-8a74a70dda91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (1.21.5)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (1.10.0+cu111)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (1.15.0)\n",
            "Collecting bitarray\n",
            "  Downloading bitarray-2.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (221 kB)\n",
            "\u001b[K     |████████████████████████████████| 221 kB 30.5 MB/s \n",
            "\u001b[?25hCollecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 86.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (0.29.28)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (0.10.0+cu111)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (4.63.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 94.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+0f078de) (5.4.0)\n",
            "Collecting PyYAML>=5.1.*\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 88.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+0f078de) (3.10.0.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+0f078de) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+0f078de) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+0f078de) (3.7.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=34112ec82031c4f079842446ac8b7adc19355f9241e12cdaba2c2cb203736bf8\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, portalocker, omegaconf, colorama, antlr4-python3-runtime, sacrebleu, hydra-core, bitarray, fairseq\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.8 bitarray-2.4.0 colorama-0.4.4 fairseq hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.4.0 sacrebleu-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-aOV5tBbdng",
        "outputId": "c54628a4-ac79-48a9-b422-79036fcc7aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade ./fairseq/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "BsuFv3sM2M3D",
        "outputId": "7f53a0f7-22a2-47b8-ea64-20105511f011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./fairseq\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (1.21.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (2019.12.20)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (0.29.28)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (0.10.0+cu111)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (2.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (4.63.0)\n",
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (2.4.0)\n",
            "Requirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (2.0.6)\n",
            "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (1.0.7)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+0f078de) (4.8)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+0f078de) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+0f078de) (3.10.0.2)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+0f078de) (6.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+0f078de) (2.4.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+0f078de) (0.4.4)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+0f078de) (0.8.9)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+0f078de) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+0f078de) (3.7.0)\n",
            "Building wheels for collected packages: fairseq\n",
            "  Building wheel for fairseq (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-1.0.0a0+0f078de-cp37-cp37m-linux_x86_64.whl size=16134892 sha256=ac30f7ad541c4ef399a5708c9ccccbb4a9ac2c16993010758fcd5c2f241606c9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6zmwa_rp/wheels/7c/35/80/edbd520a1a7e615df007002aeea9f6bf5f3c8f9243e072f6ce\n",
            "Successfully built fairseq\n",
            "Installing collected packages: fairseq\n",
            "Successfully installed fairseq-1.0.0a0+0f078de\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "fairseq"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd /content/fairseq/"
      ],
      "metadata": {
        "id": "jPSnOPj7m-y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/fairseq/fairseq_cli/preprocess.py \\\n",
        "--trainpref ./bpe/train.bpe -s src -t trg \\\n",
        "--testpref ./bpe/test.bpe \\\n",
        "--validpref ./bpe/val.bpe \\\n",
        "--destdir ./data_enth_bin/ \\\n",
        "--workers 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL9crnZHbm5h",
        "outputId": "8987297f-94e9-4373-aed8-69327f549135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-10 07:22:06 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2022-03-10 07:22:06 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='./data_enth_bin/', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='src', srcdict=None, suppress_crashes=False, target_lang='trg', task='translation', tensorboard_logdir=None, testpref='./bpe/test.bpe', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='./bpe/train.bpe', use_plasma_view=False, user_dir=None, validpref='./bpe/val.bpe', wandb_project=None, workers=8)\n",
            "2022-03-10 07:22:09 | INFO | fairseq_cli.preprocess | [src] Dictionary: 33456 types\n",
            "2022-03-10 07:22:13 | INFO | fairseq_cli.preprocess | [src] ./bpe/train.bpe.src: 221000 sents, 1923880 tokens, 0.0% replaced (by <unk>)\n",
            "2022-03-10 07:22:13 | INFO | fairseq_cli.preprocess | [src] Dictionary: 33456 types\n",
            "2022-03-10 07:22:21 | INFO | fairseq_cli.preprocess | [src] ./bpe/val.bpe.src: 459431 sents, 4033248 tokens, 0.0918% replaced (by <unk>)\n",
            "2022-03-10 07:22:21 | INFO | fairseq_cli.preprocess | [src] Dictionary: 33456 types\n",
            "2022-03-10 07:22:21 | INFO | fairseq_cli.preprocess | [src] ./bpe/test.bpe.src: 1000 sents, 8785 tokens, 0.114% replaced (by <unk>)\n",
            "2022-03-10 07:22:21 | INFO | fairseq_cli.preprocess | [trg] Dictionary: 17208 types\n",
            "2022-03-10 07:22:28 | INFO | fairseq_cli.preprocess | [trg] ./bpe/train.bpe.trg: 221000 sents, 1932968 tokens, 0.0% replaced (by <unk>)\n",
            "2022-03-10 07:22:28 | INFO | fairseq_cli.preprocess | [trg] Dictionary: 17208 types\n",
            "2022-03-10 07:22:41 | INFO | fairseq_cli.preprocess | [trg] ./bpe/val.bpe.trg: 459431 sents, 4031234 tokens, 0.0672% replaced (by <unk>)\n",
            "2022-03-10 07:22:41 | INFO | fairseq_cli.preprocess | [trg] Dictionary: 17208 types\n",
            "2022-03-10 07:22:41 | INFO | fairseq_cli.preprocess | [trg] ./bpe/test.bpe.trg: 1000 sents, 8679 tokens, 0.0807% replaced (by <unk>)\n",
            "2022-03-10 07:22:41 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ./data_enth_bin/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/fairseq/fairseq_cli/train.py ./data_enth_bin --arch transformer_wmt_en_de \\\n",
        "--optimizer adam --clip-norm 0.0 \\\n",
        "--lr-scheduler inverse_sqrt --warmup-init-lr 1e-07 \\\n",
        "--lr 0.0007 --max-epoch 20 \\\n",
        "--criterion label_smoothed_cross_entropy \\\n",
        "--label-smoothing 0.1 --max-tokens 14000 --update-freq 3 \\\n",
        "--save-interval 5 --save-interval-updates 10000 \\\n",
        "--keep-interval-updates 5 --keep-last-epochs 2 --max-update 150000 \\\n",
        "--dropout 0.1 "
      ],
      "metadata": {
        "id": "t8kqVkbReIvr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d06932-68f0-4c5c-da21-4d93b9f1cfc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-10 15:16:26 | INFO | numexpr.utils | Note: NumExpr detected 40 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2022-03-10 15:16:26 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2022-03-10 15:16:27 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2022-03-10 15:16:28 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 0, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 14000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 14000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 20, 'max_update': 150000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [3], 'lr': [0.0007], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 10000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_wmt_en_de', activation_dropout=0.0, activation_fn='relu', adam_betas=(0.9, 0.999), adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_wmt_en_de', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='./data_enth_bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0007], lr_scheduler='inverse_sqrt', max_epoch=20, max_tokens=14000, max_tokens_valid=14000, max_update=150000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=5, save_interval_updates=10000, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[3], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': './data_enth_bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0007]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2022-03-10 15:16:29 | INFO | fairseq.tasks.translation | [src] dictionary: 33456 types\n",
            "2022-03-10 15:16:29 | INFO | fairseq.tasks.translation | [trg] dictionary: 17208 types\n",
            "2022-03-10 15:16:30 | INFO | fairseq_cli.train | TransformerModel(\n",
            "  (encoder): TransformerEncoderBase(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(33456, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): TransformerDecoderBase(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(17208, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (output_projection): Linear(in_features=512, out_features=17208, bias=False)\n",
            "  )\n",
            ")\n",
            "2022-03-10 15:16:30 | INFO | fairseq_cli.train | task: TranslationTask\n",
            "2022-03-10 15:16:30 | INFO | fairseq_cli.train | model: TransformerModel\n",
            "2022-03-10 15:16:30 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2022-03-10 15:16:30 | INFO | fairseq_cli.train | num. shared model params: 78,888,960 (num. trained: 78,888,960)\n",
            "2022-03-10 15:16:30 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2022-03-10 15:16:30 | INFO | fairseq.data.data_utils | loaded 459,431 examples from: ./data_enth_bin/valid.src-trg.src\n",
            "2022-03-10 15:16:30 | INFO | fairseq.data.data_utils | loaded 459,431 examples from: ./data_enth_bin/valid.src-trg.trg\n",
            "2022-03-10 15:16:30 | INFO | fairseq.tasks.translation | ./data_enth_bin valid src-trg 459431 examples\n",
            "2022-03-10 15:16:30 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2022-03-10 15:16:30 | INFO | fairseq_cli.train | max tokens per device = 14000 and max sentences per device = None\n",
            "2022-03-10 15:16:30 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2022-03-10 15:16:31 | INFO | fairseq.trainer | Loaded checkpoint checkpoints/checkpoint_last.pt (epoch 16 @ 885 updates)\n",
            "2022-03-10 15:16:31 | INFO | fairseq.trainer | loading train data for epoch 16\n",
            "2022-03-10 15:16:31 | INFO | fairseq.data.data_utils | loaded 221,000 examples from: ./data_enth_bin/train.src-trg.src\n",
            "2022-03-10 15:16:31 | INFO | fairseq.data.data_utils | loaded 221,000 examples from: ./data_enth_bin/train.src-trg.trg\n",
            "2022-03-10 15:16:31 | INFO | fairseq.tasks.translation | ./data_enth_bin train src-trg 221000 examples\n",
            "2022-03-10 15:16:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 59\n",
            "epoch 016:   0% 0/59 [00:00<?, ?it/s]2022-03-10 15:16:31 | INFO | fairseq.trainer | begin training epoch 16\n",
            "2022-03-10 15:16:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "epoch 016:  98% 58/59 [16:42<00:16, 16.91s/it, loss=6.388, nll_loss=5.201, ppl=36.77, wps=1825.4, ups=0.06, wpb=31167.9, bsz=3357.9, num_updates=900, lr=0.000157578, gnorm=2.304, train_wall=262, wall=265]2022-03-10 15:33:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 016 | valid on 'valid' subset:   0% 0/349 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   0% 1/349 [00:04<25:13,  4.35s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   1% 2/349 [00:05<15:30,  2.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   1% 3/349 [00:06<11:10,  1.94s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   1% 4/349 [00:08<09:26,  1.64s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   1% 5/349 [00:09<09:18,  1.62s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   2% 6/349 [00:11<09:11,  1.61s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   2% 7/349 [00:12<09:07,  1.60s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   2% 8/349 [00:14<09:36,  1.69s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   3% 9/349 [00:16<09:54,  1.75s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   3% 10/349 [00:18<09:52,  1.75s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   3% 11/349 [00:20<09:45,  1.73s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   3% 12/349 [00:21<09:28,  1.69s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   4% 13/349 [00:23<09:21,  1.67s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   4% 14/349 [00:24<09:13,  1.65s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   4% 15/349 [00:26<08:56,  1.61s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   5% 16/349 [00:27<08:36,  1.55s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   5% 17/349 [00:29<08:07,  1.47s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   5% 18/349 [00:30<07:44,  1.40s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   5% 19/349 [00:31<07:48,  1.42s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   6% 20/349 [00:33<07:48,  1.42s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   6% 21/349 [00:34<07:47,  1.43s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   6% 22/349 [00:36<08:06,  1.49s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   7% 23/349 [00:37<08:15,  1.52s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   7% 24/349 [00:39<08:20,  1.54s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   7% 25/349 [00:41<08:22,  1.55s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   7% 26/349 [00:42<08:50,  1.64s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   8% 27/349 [00:44<09:09,  1.71s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   8% 28/349 [00:46<09:22,  1.75s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   8% 29/349 [00:48<09:30,  1.78s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   9% 30/349 [00:50<09:22,  1.76s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   9% 31/349 [00:51<09:14,  1.74s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   9% 32/349 [00:53<09:10,  1.74s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:   9% 33/349 [00:55<08:59,  1.71s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  10% 34/349 [00:56<08:50,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  10% 35/349 [00:58<08:37,  1.65s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  10% 36/349 [00:59<08:21,  1.60s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  11% 37/349 [01:01<08:01,  1.54s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  11% 38/349 [01:02<07:35,  1.47s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  11% 39/349 [01:04<08:01,  1.55s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  11% 40/349 [01:05<07:55,  1.54s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  12% 41/349 [01:07<07:52,  1.53s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  12% 42/349 [01:08<07:46,  1.52s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  12% 43/349 [01:10<07:41,  1.51s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  13% 44/349 [01:12<07:53,  1.55s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  13% 45/349 [01:13<07:59,  1.58s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  13% 46/349 [01:15<08:04,  1.60s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  13% 47/349 [01:16<08:07,  1.61s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  14% 48/349 [01:18<08:09,  1.63s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  14% 49/349 [01:20<08:09,  1.63s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  14% 50/349 [01:22<08:25,  1.69s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  15% 51/349 [01:23<08:35,  1.73s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  15% 52/349 [01:25<08:40,  1.75s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  15% 53/349 [01:27<08:45,  1.77s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  15% 54/349 [01:29<08:49,  1.80s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  16% 55/349 [01:31<08:43,  1.78s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  16% 56/349 [01:32<08:37,  1.77s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  16% 57/349 [01:34<08:33,  1.76s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  17% 58/349 [01:36<08:30,  1.76s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  17% 59/349 [01:38<08:19,  1.72s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  17% 60/349 [01:39<08:11,  1.70s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  17% 61/349 [01:41<08:04,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  18% 62/349 [01:42<07:56,  1.66s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  18% 63/349 [01:44<07:49,  1.64s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  18% 64/349 [01:46<07:38,  1.61s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  19% 65/349 [01:47<07:16,  1.54s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  19% 66/349 [01:48<06:56,  1.47s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  19% 67/349 [01:50<07:10,  1.53s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  19% 68/349 [01:51<06:59,  1.49s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  20% 69/349 [01:53<07:02,  1.51s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  20% 70/349 [01:54<07:04,  1.52s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  20% 71/349 [01:56<07:06,  1.53s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  21% 72/349 [01:58<07:06,  1.54s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  21% 73/349 [01:59<07:07,  1.55s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  21% 74/349 [02:01<07:19,  1.60s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  21% 75/349 [02:02<07:26,  1.63s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  22% 76/349 [02:04<07:30,  1.65s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  22% 77/349 [02:06<07:33,  1.67s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  22% 78/349 [02:08<07:34,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  23% 79/349 [02:09<07:33,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  23% 80/349 [02:11<07:32,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  23% 81/349 [02:13<07:47,  1.74s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  23% 82/349 [02:15<07:55,  1.78s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  24% 83/349 [02:17<08:00,  1.80s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  24% 84/349 [02:18<08:02,  1.82s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  24% 85/349 [02:20<08:04,  1.83s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  25% 86/349 [02:22<08:04,  1.84s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  25% 87/349 [02:24<07:52,  1.80s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  25% 88/349 [02:26<07:47,  1.79s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  26% 89/349 [02:27<07:43,  1.78s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  26% 90/349 [02:29<07:38,  1.77s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  26% 91/349 [02:31<07:35,  1.77s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  26% 92/349 [02:33<07:28,  1.75s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  27% 93/349 [02:34<07:22,  1.73s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  27% 94/349 [02:36<07:16,  1.71s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  27% 95/349 [02:38<07:05,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  28% 96/349 [02:39<07:01,  1.66s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  28% 97/349 [02:41<06:54,  1.64s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  28% 98/349 [02:42<06:38,  1.59s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  28% 99/349 [02:44<06:29,  1.56s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  29% 100/349 [02:45<06:10,  1.49s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  29% 101/349 [02:46<05:56,  1.44s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  29% 102/349 [02:48<05:59,  1.45s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  30% 103/349 [02:49<05:59,  1.46s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  30% 104/349 [02:51<05:59,  1.47s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  30% 105/349 [02:52<06:09,  1.51s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  30% 106/349 [02:54<06:14,  1.54s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  31% 107/349 [02:56<06:19,  1.57s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  31% 108/349 [02:57<06:21,  1.58s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  31% 109/349 [02:59<06:21,  1.59s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  32% 110/349 [03:01<06:31,  1.64s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  32% 111/349 [03:02<06:37,  1.67s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  32% 112/349 [03:04<06:42,  1.70s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  32% 113/349 [03:06<06:45,  1.72s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  33% 114/349 [03:08<06:45,  1.72s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  33% 115/349 [03:09<06:44,  1.73s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  33% 116/349 [03:11<06:52,  1.77s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  34% 117/349 [03:13<06:57,  1.80s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  34% 118/349 [03:15<06:59,  1.81s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  34% 119/349 [03:17<07:00,  1.83s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  34% 120/349 [03:19<07:00,  1.83s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  35% 121/349 [03:21<06:58,  1.84s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  35% 122/349 [03:22<06:56,  1.84s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  35% 123/349 [03:24<06:50,  1.82s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  36% 124/349 [03:26<06:47,  1.81s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  36% 125/349 [03:28<06:42,  1.80s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  36% 126/349 [03:30<06:39,  1.79s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  36% 127/349 [03:31<06:37,  1.79s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  37% 128/349 [03:33<06:30,  1.77s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  37% 129/349 [03:35<06:26,  1.76s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  37% 130/349 [03:36<06:21,  1.74s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  38% 131/349 [03:38<06:15,  1.72s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  38% 132/349 [03:40<06:11,  1.71s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  38% 133/349 [03:41<06:02,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  38% 134/349 [03:43<05:53,  1.64s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  39% 135/349 [03:44<05:41,  1.60s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  39% 136/349 [03:46<05:25,  1.53s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  39% 137/349 [03:47<05:17,  1.50s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  40% 138/349 [03:49<05:17,  1.51s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  40% 139/349 [03:50<05:16,  1.51s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  40% 140/349 [03:52<05:15,  1.51s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  40% 141/349 [03:53<05:22,  1.55s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  41% 142/349 [03:55<05:26,  1.58s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  41% 143/349 [03:57<05:30,  1.60s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  41% 144/349 [03:58<05:30,  1.61s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  42% 145/349 [04:00<05:30,  1.62s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  42% 146/349 [04:02<05:37,  1.66s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  42% 147/349 [04:04<05:41,  1.69s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  42% 148/349 [04:05<05:43,  1.71s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  43% 149/349 [04:07<05:44,  1.72s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  43% 150/349 [04:09<05:44,  1.73s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  43% 151/349 [04:11<05:44,  1.74s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  44% 152/349 [04:12<05:52,  1.79s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  44% 153/349 [04:14<05:56,  1.82s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  44% 154/349 [04:16<05:57,  1.84s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  44% 155/349 [04:18<05:58,  1.85s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  45% 156/349 [04:20<05:58,  1.86s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  45% 157/349 [04:22<05:54,  1.84s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  45% 158/349 [04:24<05:48,  1.83s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  46% 159/349 [04:25<05:46,  1.82s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  46% 160/349 [04:27<05:43,  1.82s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  46% 161/349 [04:29<05:41,  1.82s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  46% 162/349 [04:31<05:35,  1.80s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  47% 163/349 [04:33<05:31,  1.78s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  47% 164/349 [04:34<05:28,  1.78s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  47% 165/349 [04:36<05:21,  1.75s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  48% 166/349 [04:38<05:17,  1.73s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  48% 167/349 [04:39<05:10,  1.70s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  48% 168/349 [04:41<05:04,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  48% 169/349 [04:42<04:56,  1.65s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  49% 170/349 [04:44<04:46,  1.60s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  49% 171/349 [04:45<04:32,  1.53s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  49% 172/349 [04:47<04:27,  1.51s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  50% 173/349 [04:48<04:29,  1.53s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  50% 174/349 [04:50<04:30,  1.54s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  50% 175/349 [04:52<04:29,  1.55s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  50% 176/349 [04:53<04:35,  1.59s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  51% 177/349 [04:55<04:37,  1.61s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  51% 178/349 [04:57<04:38,  1.63s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  51% 179/349 [04:58<04:39,  1.64s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  52% 180/349 [05:00<04:43,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  52% 181/349 [05:02<04:46,  1.71s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  52% 182/349 [05:04<04:49,  1.74s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  52% 183/349 [05:05<04:49,  1.74s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  53% 184/349 [05:07<04:55,  1.79s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  53% 185/349 [05:09<04:58,  1.82s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  53% 186/349 [05:11<05:00,  1.84s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  54% 187/349 [05:13<04:59,  1.85s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  54% 188/349 [05:15<04:58,  1.86s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  54% 189/349 [05:17<04:55,  1.85s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  54% 190/349 [05:18<04:52,  1.84s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  55% 191/349 [05:20<04:49,  1.83s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  55% 192/349 [05:22<04:46,  1.83s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  55% 193/349 [05:24<04:41,  1.80s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  56% 194/349 [05:26<04:37,  1.79s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  56% 195/349 [05:27<04:33,  1.78s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  56% 196/349 [05:29<04:28,  1.75s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  56% 197/349 [05:31<04:23,  1.73s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  57% 198/349 [05:32<04:18,  1.71s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  57% 199/349 [05:34<04:12,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  57% 200/349 [05:35<04:03,  1.64s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  58% 201/349 [05:37<03:50,  1.56s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  58% 202/349 [05:38<03:46,  1.54s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  58% 203/349 [05:40<03:46,  1.55s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  58% 204/349 [05:42<03:47,  1.57s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  59% 205/349 [05:43<03:50,  1.60s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  59% 206/349 [05:45<03:51,  1.62s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  59% 207/349 [05:47<03:53,  1.64s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  60% 208/349 [05:48<03:52,  1.65s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  60% 209/349 [05:50<03:56,  1.69s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  60% 210/349 [05:52<03:56,  1.70s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  60% 211/349 [05:53<03:56,  1.71s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  61% 212/349 [05:55<04:01,  1.76s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  61% 213/349 [05:57<04:04,  1.80s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  61% 214/349 [05:59<04:04,  1.81s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  62% 215/349 [06:01<04:05,  1.83s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  62% 216/349 [06:03<04:02,  1.82s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  62% 217/349 [06:05<04:00,  1.82s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  62% 218/349 [06:06<03:57,  1.81s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  63% 219/349 [06:08<03:53,  1.80s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  63% 220/349 [06:10<03:50,  1.79s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  63% 221/349 [06:12<03:47,  1.78s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  64% 222/349 [06:13<03:43,  1.76s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  64% 223/349 [06:15<03:38,  1.73s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  64% 224/349 [06:17<03:34,  1.71s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  64% 225/349 [06:18<03:28,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  65% 226/349 [06:20<03:20,  1.63s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  65% 227/349 [06:21<03:08,  1.54s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  65% 228/349 [06:23<03:04,  1.53s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  66% 229/349 [06:24<03:05,  1.55s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  66% 230/349 [06:26<03:08,  1.59s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  66% 231/349 [06:28<03:11,  1.62s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  66% 232/349 [06:29<03:12,  1.64s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  67% 233/349 [06:31<03:15,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  67% 234/349 [06:33<03:16,  1.71s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  67% 235/349 [06:35<03:20,  1.76s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  68% 236/349 [06:37<03:23,  1.80s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  68% 237/349 [06:39<03:24,  1.82s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  68% 238/349 [06:40<03:22,  1.83s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  68% 239/349 [06:42<03:21,  1.83s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  69% 240/349 [06:44<03:17,  1.81s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  69% 241/349 [06:46<03:14,  1.80s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  69% 242/349 [06:47<03:10,  1.78s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  70% 243/349 [06:49<03:05,  1.75s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  70% 244/349 [06:51<03:00,  1.72s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  70% 245/349 [06:52<02:54,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  70% 246/349 [06:54<02:44,  1.59s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  71% 247/349 [06:55<02:37,  1.54s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  71% 248/349 [06:57<02:37,  1.56s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  71% 249/349 [06:58<02:37,  1.58s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  72% 250/349 [07:00<02:39,  1.62s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  72% 251/349 [07:02<02:43,  1.67s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  72% 252/349 [07:04<02:45,  1.70s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  72% 253/349 [07:06<02:48,  1.76s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  73% 254/349 [07:07<02:50,  1.79s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  73% 255/349 [07:09<02:50,  1.82s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  73% 256/349 [07:11<02:49,  1.82s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  74% 257/349 [07:13<02:46,  1.81s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  74% 258/349 [07:15<02:43,  1.80s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  74% 259/349 [07:16<02:39,  1.78s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  74% 260/349 [07:18<02:35,  1.75s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  75% 261/349 [07:20<02:31,  1.72s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  75% 262/349 [07:21<02:23,  1.65s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  75% 263/349 [07:23<02:15,  1.58s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  76% 264/349 [07:24<02:15,  1.60s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  76% 265/349 [07:26<02:17,  1.64s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  76% 266/349 [07:28<02:18,  1.67s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  77% 267/349 [07:30<02:20,  1.71s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  77% 268/349 [07:31<02:22,  1.76s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  77% 269/349 [07:33<02:23,  1.80s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  77% 270/349 [07:35<02:22,  1.81s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  78% 271/349 [07:37<02:21,  1.81s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  78% 272/349 [07:39<02:17,  1.79s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  78% 273/349 [07:40<02:13,  1.76s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  79% 274/349 [07:42<02:09,  1.73s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  79% 275/349 [07:44<02:03,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  79% 276/349 [07:45<01:56,  1.59s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  79% 277/349 [07:47<01:55,  1.60s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  80% 278/349 [07:48<01:56,  1.64s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  80% 279/349 [07:50<01:57,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  80% 280/349 [07:52<01:59,  1.74s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  81% 281/349 [07:54<01:59,  1.76s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  81% 282/349 [07:56<01:59,  1.78s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  81% 283/349 [07:57<01:56,  1.76s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  81% 284/349 [07:59<01:53,  1.75s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  82% 285/349 [08:01<01:49,  1.72s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  82% 286/349 [08:02<01:41,  1.62s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  82% 287/349 [08:04<01:36,  1.55s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  83% 288/349 [08:05<01:36,  1.58s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  83% 289/349 [08:07<01:38,  1.64s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  83% 290/349 [08:09<01:40,  1.70s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  83% 291/349 [08:11<01:40,  1.73s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  84% 292/349 [08:12<01:39,  1.75s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  84% 293/349 [08:14<01:37,  1.75s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  84% 294/349 [08:16<01:34,  1.72s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  85% 295/349 [08:17<01:26,  1.60s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  85% 296/349 [08:19<01:21,  1.53s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  85% 297/349 [08:20<01:23,  1.60s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  85% 298/349 [08:22<01:24,  1.66s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  86% 299/349 [08:24<01:25,  1.72s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  86% 300/349 [08:26<01:25,  1.73s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  86% 301/349 [08:27<01:23,  1.73s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  87% 302/349 [08:29<01:19,  1.70s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  87% 303/349 [08:30<01:14,  1.61s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  87% 304/349 [08:32<01:14,  1.65s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  87% 305/349 [08:34<01:15,  1.72s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  88% 306/349 [08:36<01:14,  1.74s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  88% 307/349 [08:38<01:12,  1.72s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  88% 308/349 [08:39<01:07,  1.66s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  89% 309/349 [08:40<01:03,  1.58s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  89% 310/349 [08:42<01:04,  1.65s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  89% 311/349 [08:44<01:04,  1.70s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  89% 312/349 [08:46<01:03,  1.71s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  90% 313/349 [08:47<01:00,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  90% 314/349 [08:49<00:56,  1.60s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  90% 315/349 [08:51<00:57,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  91% 316/349 [08:52<00:56,  1.71s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  91% 317/349 [08:54<00:53,  1.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  91% 318/349 [08:55<00:49,  1.59s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  91% 319/349 [08:57<00:50,  1.67s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  92% 320/349 [08:59<00:49,  1.70s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  92% 321/349 [09:01<00:46,  1.65s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  92% 322/349 [09:02<00:43,  1.60s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  93% 323/349 [09:04<00:43,  1.66s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  93% 324/349 [09:06<00:41,  1.65s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  93% 325/349 [09:07<00:38,  1.60s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  93% 326/349 [09:09<00:37,  1.64s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  94% 327/349 [09:10<00:34,  1.56s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  94% 328/349 [09:12<00:31,  1.52s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  94% 329/349 [09:13<00:31,  1.56s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  95% 330/349 [09:15<00:29,  1.53s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  95% 331/349 [09:16<00:28,  1.59s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  95% 332/349 [09:18<00:26,  1.56s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  95% 333/349 [09:20<00:25,  1.59s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  96% 334/349 [09:21<00:23,  1.56s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  96% 335/349 [09:23<00:22,  1.58s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  96% 336/349 [09:24<00:20,  1.54s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  97% 337/349 [09:25<00:17,  1.47s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  97% 338/349 [09:27<00:16,  1.46s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  97% 339/349 [09:28<00:13,  1.38s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  97% 340/349 [09:30<00:12,  1.41s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  98% 341/349 [09:31<00:11,  1.40s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  98% 342/349 [09:32<00:09,  1.36s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  98% 343/349 [09:34<00:08,  1.39s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  99% 344/349 [09:35<00:07,  1.44s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  99% 345/349 [09:37<00:05,  1.47s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  99% 346/349 [09:38<00:04,  1.47s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  99% 347/349 [09:40<00:02,  1.47s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset: 100% 348/349 [09:41<00:01,  1.44s/it]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset: 100% 349/349 [09:41<00:00,  1.05s/it]\u001b[A\n",
            "                                                                          \u001b[A2022-03-10 15:43:13 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 6.28 | nll_loss 4.986 | ppl 31.7 | wps 6963 | wpb 11550.8 | bsz 1316.4 | num_updates 944 | best_loss 6.28\n",
            "2022-03-10 15:43:13 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)\n",
            "2022-03-10 15:43:13 | INFO | train | epoch 016 | loss 6.206 | nll_loss 4.989 | ppl 31.75 | wps 1205.4 | ups 0.04 | wpb 32762.2 | bsz 3745.8 | num_updates 944 | lr 0.000165276 | gnorm 1.859 | train_wall 1016 | wall 1604\n",
            "2022-03-10 15:43:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 59\n",
            "epoch 017:   0% 0/59 [00:00<?, ?it/s]2022-03-10 15:43:13 | INFO | fairseq.trainer | begin training epoch 17\n",
            "2022-03-10 15:43:13 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 017:  98% 58/59 [19:06<00:18, 18.18s/it, loss=6.074, nll_loss=4.834, ppl=28.53, wps=1346.5, ups=0.04, wpb=32999.9, bsz=3817.6, num_updates=1000, lr=0.000175075, gnorm=2.045, train_wall=1862, wall=2715]2022-03-10 16:02:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 017 | valid on 'valid' subset:   0% 0/349 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   0% 1/349 [00:04<26:43,  4.61s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   1% 2/349 [00:06<16:49,  2.91s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   1% 3/349 [00:07<12:12,  2.12s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   1% 4/349 [00:08<10:34,  1.84s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   1% 5/349 [00:11<11:03,  1.93s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   2% 6/349 [00:12<10:44,  1.88s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   2% 7/349 [00:14<10:33,  1.85s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   2% 8/349 [00:16<11:00,  1.94s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   3% 9/349 [00:18<11:13,  1.98s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   3% 10/349 [00:20<11:05,  1.96s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   3% 11/349 [00:22<10:58,  1.95s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   3% 12/349 [00:24<10:40,  1.90s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   4% 13/349 [00:26<10:34,  1.89s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   4% 14/349 [00:28<10:22,  1.86s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   4% 15/349 [00:29<10:06,  1.82s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   5% 16/349 [00:31<09:48,  1.77s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   5% 17/349 [00:32<09:17,  1.68s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   5% 18/349 [00:34<08:52,  1.61s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   5% 19/349 [00:35<08:51,  1.61s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   6% 20/349 [00:37<08:50,  1.61s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   6% 21/349 [00:39<08:47,  1.61s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   6% 22/349 [00:41<09:08,  1.68s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   7% 23/349 [00:42<09:20,  1.72s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   7% 24/349 [00:44<09:26,  1.74s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   7% 25/349 [00:46<09:29,  1.76s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   7% 26/349 [00:48<10:00,  1.86s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   8% 27/349 [00:50<10:16,  1.91s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   8% 28/349 [00:52<10:28,  1.96s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   8% 29/349 [00:54<10:39,  2.00s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   9% 30/349 [00:56<10:30,  1.98s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   9% 31/349 [00:58<10:21,  1.95s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   9% 32/349 [01:00<10:14,  1.94s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:   9% 33/349 [01:02<10:00,  1.90s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  10% 34/349 [01:04<09:51,  1.88s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  10% 35/349 [01:05<09:45,  1.87s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  10% 36/349 [01:07<09:31,  1.83s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  11% 37/349 [01:09<09:19,  1.79s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  11% 38/349 [01:11<09:22,  1.81s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  11% 39/349 [01:13<09:23,  1.82s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  11% 40/349 [01:15<10:06,  1.96s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  12% 41/349 [01:17<10:18,  2.01s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  12% 42/349 [01:19<10:25,  2.04s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  12% 43/349 [01:21<10:34,  2.07s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  13% 44/349 [01:24<11:07,  2.19s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  13% 45/349 [01:26<11:25,  2.26s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  13% 46/349 [01:29<11:56,  2.37s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  13% 47/349 [01:32<12:44,  2.53s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  14% 48/349 [01:34<12:34,  2.51s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  14% 49/349 [01:36<12:15,  2.45s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  14% 50/349 [01:39<12:23,  2.49s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  15% 51/349 [01:42<12:29,  2.51s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  15% 52/349 [01:44<12:13,  2.47s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  15% 53/349 [01:46<12:10,  2.47s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  15% 54/349 [01:49<12:13,  2.49s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  16% 55/349 [01:51<12:09,  2.48s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  16% 56/349 [01:54<11:37,  2.38s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  16% 57/349 [01:56<11:12,  2.30s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  17% 58/349 [01:58<11:02,  2.28s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  17% 59/349 [02:00<10:33,  2.18s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  17% 60/349 [02:02<10:11,  2.11s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  17% 61/349 [02:04<09:56,  2.07s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  18% 62/349 [02:06<09:36,  2.01s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  18% 63/349 [02:07<09:13,  1.93s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  18% 64/349 [02:09<08:56,  1.88s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  19% 65/349 [02:11<08:31,  1.80s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  19% 66/349 [02:12<08:01,  1.70s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  19% 67/349 [02:14<07:48,  1.66s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  19% 68/349 [02:15<07:38,  1.63s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  20% 69/349 [02:17<07:44,  1.66s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  20% 70/349 [02:19<07:50,  1.68s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  20% 71/349 [02:21<07:51,  1.70s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  21% 72/349 [02:22<07:52,  1.71s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  21% 73/349 [02:24<07:53,  1.71s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  21% 74/349 [02:26<08:12,  1.79s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  21% 75/349 [02:28<08:21,  1.83s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  22% 76/349 [02:30<08:23,  1.84s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  22% 77/349 [02:32<08:22,  1.85s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  22% 78/349 [02:33<08:21,  1.85s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  23% 79/349 [02:35<08:24,  1.87s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  23% 80/349 [02:37<08:24,  1.87s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  23% 81/349 [02:39<08:41,  1.95s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  23% 82/349 [02:41<08:52,  1.99s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  24% 83/349 [02:44<08:58,  2.03s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  24% 84/349 [02:46<09:02,  2.05s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  24% 85/349 [02:48<09:02,  2.05s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  25% 86/349 [02:50<09:01,  2.06s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  25% 87/349 [02:52<08:54,  2.04s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  25% 88/349 [02:54<08:52,  2.04s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  26% 89/349 [02:56<08:48,  2.03s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  26% 90/349 [02:58<08:41,  2.01s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  26% 91/349 [03:00<08:38,  2.01s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  26% 92/349 [03:02<08:30,  1.98s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  27% 93/349 [03:04<08:24,  1.97s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  27% 94/349 [03:06<08:17,  1.95s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  27% 95/349 [03:07<08:02,  1.90s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  28% 96/349 [03:09<07:54,  1.88s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  28% 97/349 [03:11<07:44,  1.84s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  28% 98/349 [03:13<07:25,  1.78s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  28% 99/349 [03:14<07:12,  1.73s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  29% 100/349 [03:16<06:49,  1.64s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  29% 101/349 [03:17<06:34,  1.59s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  29% 102/349 [03:19<06:34,  1.60s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  30% 103/349 [03:20<06:31,  1.59s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  30% 104/349 [03:22<06:28,  1.59s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  30% 105/349 [03:24<06:35,  1.62s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  30% 106/349 [03:25<06:42,  1.66s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  31% 107/349 [03:27<06:46,  1.68s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  31% 108/349 [03:29<06:48,  1.70s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  31% 109/349 [03:31<06:50,  1.71s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  32% 110/349 [03:32<07:01,  1.76s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  32% 111/349 [03:34<07:08,  1.80s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  32% 112/349 [03:36<07:13,  1.83s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  32% 113/349 [03:38<07:15,  1.85s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  33% 114/349 [03:40<07:17,  1.86s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  33% 115/349 [03:42<07:16,  1.86s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  33% 116/349 [03:44<07:24,  1.91s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  34% 117/349 [03:46<07:28,  1.93s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  34% 118/349 [03:48<07:28,  1.94s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  34% 119/349 [03:50<07:29,  1.95s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  34% 120/349 [03:52<07:30,  1.97s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  35% 121/349 [03:54<07:29,  1.97s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  35% 122/349 [03:56<07:28,  1.97s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  35% 123/349 [03:58<07:21,  1.95s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  36% 124/349 [04:00<07:26,  1.98s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  36% 125/349 [04:02<07:23,  1.98s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  36% 126/349 [04:04<07:20,  1.97s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  36% 127/349 [04:06<07:17,  1.97s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  37% 128/349 [04:08<07:11,  1.95s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  37% 129/349 [04:09<07:05,  1.94s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  37% 130/349 [04:11<07:01,  1.92s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  38% 131/349 [04:13<06:56,  1.91s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  38% 132/349 [04:15<06:50,  1.89s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  38% 133/349 [04:17<06:42,  1.86s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  38% 134/349 [04:19<06:36,  1.85s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  39% 135/349 [04:20<06:27,  1.81s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  39% 136/349 [04:22<06:06,  1.72s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  39% 137/349 [04:23<05:53,  1.67s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  40% 138/349 [04:25<05:51,  1.67s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  40% 139/349 [04:27<05:50,  1.67s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  40% 140/349 [04:28<05:49,  1.67s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  40% 141/349 [04:30<05:56,  1.71s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  41% 142/349 [04:32<06:01,  1.75s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  41% 143/349 [04:34<06:08,  1.79s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  41% 144/349 [04:36<06:07,  1.79s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  42% 145/349 [04:38<06:06,  1.79s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  42% 146/349 [04:40<06:11,  1.83s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  42% 147/349 [04:42<06:21,  1.89s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  42% 148/349 [04:43<06:23,  1.91s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  43% 149/349 [04:45<06:25,  1.93s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  43% 150/349 [04:47<06:23,  1.93s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  43% 151/349 [04:49<06:19,  1.92s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  44% 152/349 [04:51<06:23,  1.95s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  44% 153/349 [04:53<06:22,  1.95s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  44% 154/349 [04:55<06:22,  1.96s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  44% 155/349 [04:57<06:23,  1.98s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  45% 156/349 [04:59<06:23,  1.98s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  45% 157/349 [05:01<06:19,  1.97s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  45% 158/349 [05:03<06:15,  1.96s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  46% 159/349 [05:05<06:13,  1.97s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  46% 160/349 [05:07<06:11,  1.97s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  46% 161/349 [05:09<06:10,  1.97s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  46% 162/349 [05:11<06:04,  1.95s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  47% 163/349 [05:13<05:59,  1.93s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  47% 164/349 [05:15<05:56,  1.93s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  47% 165/349 [05:17<05:50,  1.91s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  48% 166/349 [05:18<05:46,  1.89s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  48% 167/349 [05:20<05:39,  1.86s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  48% 168/349 [05:22<05:35,  1.85s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  48% 169/349 [05:24<05:28,  1.82s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  49% 170/349 [05:26<05:18,  1.78s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  49% 171/349 [05:27<05:02,  1.70s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  49% 172/349 [05:29<04:54,  1.67s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  50% 173/349 [05:30<04:54,  1.67s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  50% 174/349 [05:32<04:53,  1.68s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  50% 175/349 [05:34<04:51,  1.68s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  50% 176/349 [05:36<04:57,  1.72s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  51% 177/349 [05:37<05:00,  1.75s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  51% 178/349 [05:39<05:01,  1.76s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  51% 179/349 [05:41<05:02,  1.78s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  52% 180/349 [05:43<05:07,  1.82s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  52% 181/349 [05:45<05:09,  1.84s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  52% 182/349 [05:47<05:09,  1.85s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  52% 183/349 [05:49<05:10,  1.87s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  53% 184/349 [05:51<05:15,  1.91s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  53% 185/349 [05:53<05:18,  1.94s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  53% 186/349 [05:55<05:20,  1.97s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  54% 187/349 [05:57<05:20,  1.98s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  54% 188/349 [05:59<05:18,  1.98s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  54% 189/349 [06:01<05:14,  1.96s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  54% 190/349 [06:02<05:11,  1.96s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  55% 191/349 [06:04<05:09,  1.96s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  55% 192/349 [06:06<05:09,  1.97s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  55% 193/349 [06:08<05:04,  1.95s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  56% 194/349 [06:10<05:00,  1.94s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  56% 195/349 [06:12<04:56,  1.93s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  56% 196/349 [06:14<04:52,  1.91s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  56% 197/349 [06:16<04:48,  1.90s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  57% 198/349 [06:18<04:42,  1.87s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  57% 199/349 [06:19<04:37,  1.85s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  57% 200/349 [06:21<04:28,  1.80s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  58% 201/349 [06:23<04:13,  1.71s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  58% 202/349 [06:24<04:07,  1.68s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  58% 203/349 [06:26<04:07,  1.70s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  58% 204/349 [06:28<04:05,  1.70s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  59% 205/349 [06:30<04:10,  1.74s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  59% 206/349 [06:31<04:12,  1.77s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  59% 207/349 [06:33<04:13,  1.78s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  60% 208/349 [06:35<04:13,  1.80s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  60% 209/349 [06:37<04:16,  1.83s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  60% 210/349 [06:39<04:17,  1.85s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  60% 211/349 [06:41<04:18,  1.87s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  61% 212/349 [06:43<04:21,  1.91s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  61% 213/349 [06:45<04:23,  1.93s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  61% 214/349 [06:47<04:22,  1.95s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  62% 215/349 [06:49<04:22,  1.96s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  62% 216/349 [06:51<04:20,  1.96s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  62% 217/349 [06:53<04:18,  1.96s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  62% 218/349 [06:55<04:15,  1.95s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  63% 219/349 [06:56<04:12,  1.94s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  63% 220/349 [06:58<04:09,  1.93s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  63% 221/349 [07:00<04:06,  1.93s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  64% 222/349 [07:02<04:05,  1.93s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  64% 223/349 [07:04<04:00,  1.91s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  64% 224/349 [07:06<03:57,  1.90s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  64% 225/349 [07:08<03:53,  1.89s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  65% 226/349 [07:10<03:46,  1.84s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  65% 227/349 [07:11<03:33,  1.75s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  65% 228/349 [07:13<03:28,  1.72s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  66% 229/349 [07:16<04:35,  2.29s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  66% 230/349 [07:23<06:51,  3.46s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  66% 231/349 [07:29<08:20,  4.24s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  66% 232/349 [07:35<09:18,  4.78s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  67% 233/349 [07:41<10:01,  5.18s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  67% 234/349 [07:47<10:25,  5.44s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  67% 235/349 [07:53<10:41,  5.63s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  68% 236/349 [07:59<10:52,  5.78s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  68% 237/349 [08:05<10:56,  5.86s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  68% 238/349 [08:11<11:04,  5.98s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  68% 239/349 [08:17<11:01,  6.01s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  69% 240/349 [08:24<10:59,  6.05s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  69% 241/349 [08:30<11:03,  6.15s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  69% 242/349 [08:36<10:53,  6.11s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  70% 243/349 [08:42<10:39,  6.04s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  70% 244/349 [08:48<10:34,  6.04s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  70% 245/349 [08:54<10:28,  6.04s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  70% 246/349 [09:00<10:11,  5.93s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  71% 247/349 [09:05<10:01,  5.89s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  71% 248/349 [09:21<14:55,  8.87s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  71% 249/349 [09:27<13:21,  8.02s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  72% 250/349 [09:33<12:20,  7.48s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  72% 251/349 [09:40<11:38,  7.13s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  72% 252/349 [09:46<11:07,  6.88s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  72% 253/349 [09:53<10:47,  6.74s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  73% 254/349 [09:59<10:34,  6.68s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  73% 255/349 [10:05<10:17,  6.57s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  73% 256/349 [10:12<10:08,  6.54s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  74% 257/349 [10:18<09:56,  6.49s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  74% 258/349 [10:24<09:40,  6.38s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  74% 259/349 [10:30<09:20,  6.23s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  74% 260/349 [10:36<08:57,  6.04s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  75% 261/349 [10:42<08:47,  6.00s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  75% 262/349 [10:47<08:26,  5.82s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  75% 263/349 [10:52<08:04,  5.63s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  76% 264/349 [10:58<07:57,  5.61s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  76% 265/349 [11:04<07:57,  5.68s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  76% 266/349 [11:09<07:52,  5.70s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  77% 267/349 [11:15<07:55,  5.80s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  77% 268/349 [11:22<07:57,  5.89s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  77% 269/349 [11:28<07:58,  5.99s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  77% 270/349 [11:34<08:00,  6.09s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  78% 271/349 [11:40<07:56,  6.11s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  78% 272/349 [11:47<07:56,  6.18s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  78% 273/349 [11:53<07:53,  6.23s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  79% 274/349 [11:59<07:50,  6.27s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  79% 275/349 [12:05<07:38,  6.20s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  79% 276/349 [12:11<07:24,  6.09s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  79% 277/349 [12:17<07:20,  6.12s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  80% 278/349 [12:24<07:21,  6.22s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  80% 279/349 [12:30<07:16,  6.24s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  80% 280/349 [12:37<07:14,  6.30s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  81% 281/349 [12:43<07:04,  6.25s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  81% 282/349 [12:49<06:53,  6.17s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  81% 283/349 [12:55<06:42,  6.10s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  81% 284/349 [13:00<06:27,  5.96s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  82% 285/349 [13:06<06:26,  6.04s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  82% 286/349 [13:12<06:06,  5.82s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  82% 287/349 [13:17<05:49,  5.63s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  83% 288/349 [13:23<05:41,  5.60s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  83% 289/349 [13:28<05:34,  5.58s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  83% 290/349 [13:34<05:31,  5.61s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  83% 291/349 [13:39<05:25,  5.62s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  84% 292/349 [13:45<05:20,  5.62s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  84% 293/349 [13:51<05:15,  5.63s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  84% 294/349 [13:56<05:07,  5.59s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  85% 295/349 [14:01<04:51,  5.39s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  85% 296/349 [14:06<04:40,  5.30s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  85% 297/349 [14:12<04:38,  5.36s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  85% 298/349 [14:17<04:38,  5.46s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  86% 299/349 [14:23<04:37,  5.56s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  86% 300/349 [14:29<04:30,  5.53s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  86% 301/349 [14:34<04:23,  5.48s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  87% 302/349 [14:39<04:13,  5.40s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  87% 303/349 [14:44<04:00,  5.22s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  87% 304/349 [14:50<04:00,  5.34s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  87% 305/349 [14:55<04:00,  5.47s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  88% 306/349 [15:01<03:55,  5.47s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  88% 307/349 [15:06<03:44,  5.35s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  88% 308/349 [15:11<03:35,  5.25s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  89% 309/349 [15:16<03:22,  5.06s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  89% 310/349 [15:21<03:20,  5.14s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  89% 311/349 [15:26<03:19,  5.25s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  89% 312/349 [15:32<03:15,  5.29s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  90% 313/349 [15:37<03:09,  5.27s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  90% 314/349 [15:42<03:00,  5.15s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  90% 315/349 [15:47<02:58,  5.25s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  91% 316/349 [15:53<02:52,  5.23s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  91% 317/349 [15:58<02:47,  5.22s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  91% 318/349 [16:03<02:38,  5.10s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  91% 319/349 [16:08<02:34,  5.14s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  92% 320/349 [16:13<02:29,  5.14s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  92% 321/349 [16:18<02:21,  5.06s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  92% 322/349 [16:23<02:14,  4.98s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  93% 323/349 [16:28<02:12,  5.09s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  93% 324/349 [16:33<02:06,  5.06s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  93% 325/349 [16:38<01:59,  4.96s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  93% 326/349 [16:43<01:53,  4.96s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  94% 327/349 [16:47<01:42,  4.68s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  94% 328/349 [16:49<01:22,  3.91s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  94% 329/349 [16:54<01:24,  4.20s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  95% 330/349 [16:58<01:22,  4.37s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  95% 331/349 [17:03<01:20,  4.48s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  95% 332/349 [17:08<01:17,  4.59s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  95% 333/349 [17:13<01:13,  4.61s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  96% 334/349 [17:17<01:07,  4.50s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  96% 335/349 [17:21<01:03,  4.53s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  96% 336/349 [17:26<00:57,  4.44s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  97% 337/349 [17:30<00:51,  4.31s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  97% 338/349 [17:34<00:46,  4.24s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  97% 339/349 [17:37<00:40,  4.03s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  97% 340/349 [17:39<00:29,  3.31s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  98% 341/349 [17:40<00:22,  2.76s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  98% 342/349 [17:42<00:16,  2.36s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  98% 343/349 [17:43<00:12,  2.12s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  99% 344/349 [17:45<00:09,  2.00s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  99% 345/349 [17:47<00:07,  1.92s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  99% 346/349 [17:48<00:05,  1.82s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  99% 347/349 [17:50<00:03,  1.75s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset: 100% 348/349 [17:52<00:01,  1.67s/it]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset: 100% 349/349 [17:52<00:00,  1.21s/it]\u001b[A\n",
            "                                                                          \u001b[A2022-03-10 16:20:33 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 6.268 | nll_loss 4.954 | ppl 31 | wps 3765.4 | wpb 11550.8 | bsz 1316.4 | num_updates 1003 | best_loss 6.268\n",
            "2022-03-10 16:20:33 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)\n",
            "2022-03-10 16:20:33 | INFO | train | epoch 017 | loss 6.031 | nll_loss 4.785 | ppl 27.57 | wps 863.2 | ups 0.03 | wpb 32762.2 | bsz 3745.8 | num_updates 1003 | lr 0.0001756 | gnorm 2.331 | train_wall 1162 | wall 3843\n",
            "2022-03-10 16:20:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 59\n",
            "epoch 018:   0% 0/59 [00:00<?, ?it/s]2022-03-10 16:20:33 | INFO | fairseq.trainer | begin training epoch 18\n",
            "2022-03-10 16:20:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 018:  98% 58/59 [18:54<00:16, 16.34s/it]2022-03-10 16:39:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 018 | valid on 'valid' subset:   0% 0/349 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   0% 1/349 [00:04<27:16,  4.70s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   1% 2/349 [00:06<18:13,  3.15s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   1% 3/349 [00:07<12:52,  2.23s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   1% 4/349 [00:09<10:47,  1.88s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   1% 5/349 [00:11<11:25,  1.99s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   2% 6/349 [00:13<11:04,  1.94s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   2% 7/349 [00:15<10:49,  1.90s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   2% 8/349 [00:17<11:11,  1.97s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   3% 9/349 [00:19<11:25,  2.02s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   3% 10/349 [00:21<11:17,  2.00s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   3% 11/349 [00:23<11:10,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   3% 12/349 [00:25<10:47,  1.92s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   4% 13/349 [00:26<10:35,  1.89s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   4% 14/349 [00:28<10:16,  1.84s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   4% 15/349 [00:30<09:58,  1.79s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   5% 16/349 [00:31<09:34,  1.73s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   5% 17/349 [00:33<09:10,  1.66s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   5% 18/349 [00:34<08:42,  1.58s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   5% 19/349 [00:36<08:49,  1.60s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   6% 20/349 [00:37<08:49,  1.61s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   6% 21/349 [00:39<08:47,  1.61s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   6% 22/349 [00:41<09:17,  1.70s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   7% 23/349 [00:43<09:35,  1.76s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   7% 24/349 [00:45<09:45,  1.80s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   7% 25/349 [00:47<09:51,  1.83s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   7% 26/349 [00:49<10:17,  1.91s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   8% 27/349 [00:51<10:35,  1.97s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   8% 28/349 [00:53<10:47,  2.02s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   8% 29/349 [00:55<10:54,  2.04s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   9% 30/349 [00:57<10:48,  2.03s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   9% 31/349 [00:59<10:44,  2.03s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   9% 32/349 [01:01<10:40,  2.02s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:   9% 33/349 [01:03<10:25,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  10% 34/349 [01:05<10:11,  1.94s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  10% 35/349 [01:07<09:54,  1.89s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  10% 36/349 [01:08<09:31,  1.83s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  11% 37/349 [01:10<09:04,  1.75s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  11% 38/349 [01:11<08:33,  1.65s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  11% 39/349 [01:13<08:17,  1.61s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  11% 40/349 [01:15<08:26,  1.64s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  12% 41/349 [01:16<08:30,  1.66s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  12% 42/349 [01:18<08:32,  1.67s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  12% 43/349 [01:20<08:32,  1.68s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  13% 44/349 [01:22<08:55,  1.76s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  13% 45/349 [01:24<09:12,  1.82s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  13% 46/349 [01:26<09:22,  1.86s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  13% 47/349 [01:27<09:28,  1.88s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  14% 48/349 [01:29<09:32,  1.90s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  14% 49/349 [01:31<09:33,  1.91s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  14% 50/349 [01:33<09:50,  1.97s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  15% 51/349 [01:36<09:59,  2.01s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  15% 52/349 [01:38<10:03,  2.03s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  15% 53/349 [01:40<10:05,  2.05s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  15% 54/349 [01:42<10:10,  2.07s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  16% 55/349 [01:44<10:02,  2.05s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  16% 56/349 [01:46<09:56,  2.04s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  16% 57/349 [01:48<10:01,  2.06s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  17% 58/349 [01:50<09:54,  2.04s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  17% 59/349 [01:52<09:36,  1.99s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  17% 60/349 [01:54<09:23,  1.95s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  17% 61/349 [01:56<09:14,  1.92s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  18% 62/349 [01:57<09:04,  1.90s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  18% 63/349 [01:59<08:51,  1.86s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  18% 64/349 [02:01<08:38,  1.82s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  19% 65/349 [02:02<08:10,  1.73s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  19% 66/349 [02:04<07:44,  1.64s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  19% 67/349 [02:05<07:41,  1.64s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  19% 68/349 [02:07<07:40,  1.64s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  20% 69/349 [02:09<07:51,  1.69s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  20% 70/349 [02:11<08:02,  1.73s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  20% 71/349 [02:13<08:07,  1.75s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  21% 72/349 [02:14<08:11,  1.77s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  21% 73/349 [02:16<08:12,  1.79s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  21% 74/349 [02:18<08:24,  1.84s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  21% 75/349 [02:20<08:32,  1.87s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  22% 76/349 [02:22<08:37,  1.90s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  22% 77/349 [02:24<08:39,  1.91s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  22% 78/349 [02:26<08:41,  1.92s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  23% 79/349 [02:28<08:41,  1.93s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  23% 80/349 [02:30<08:41,  1.94s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  23% 81/349 [02:32<08:51,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  23% 82/349 [02:34<08:56,  2.01s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  24% 83/349 [02:36<08:58,  2.02s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  24% 84/349 [02:38<08:59,  2.04s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  24% 85/349 [02:40<09:00,  2.05s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  25% 86/349 [02:42<08:59,  2.05s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  25% 87/349 [02:44<08:50,  2.02s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  25% 88/349 [02:46<08:46,  2.02s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  26% 89/349 [02:48<08:44,  2.02s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  26% 90/349 [02:50<08:41,  2.01s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  26% 91/349 [02:52<08:38,  2.01s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  26% 92/349 [02:54<08:29,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  27% 93/349 [02:56<08:22,  1.96s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  27% 94/349 [02:58<08:16,  1.95s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  27% 95/349 [03:00<08:05,  1.91s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  28% 96/349 [03:02<08:00,  1.90s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  28% 97/349 [03:03<07:51,  1.87s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  28% 98/349 [03:05<07:33,  1.81s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  28% 99/349 [03:07<07:23,  1.77s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  29% 100/349 [03:08<06:58,  1.68s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  29% 101/349 [03:10<06:46,  1.64s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  29% 102/349 [03:12<06:49,  1.66s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  30% 103/349 [03:13<06:52,  1.68s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  30% 104/349 [03:15<06:52,  1.68s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  30% 105/349 [03:17<07:00,  1.72s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  30% 106/349 [03:19<07:05,  1.75s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  31% 107/349 [03:20<07:09,  1.77s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  31% 108/349 [03:22<07:10,  1.79s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  31% 109/349 [03:24<07:10,  1.79s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  32% 110/349 [03:26<07:18,  1.83s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  32% 111/349 [03:28<07:24,  1.87s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  32% 112/349 [03:30<07:27,  1.89s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  32% 113/349 [03:32<07:27,  1.90s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  33% 114/349 [03:34<07:28,  1.91s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  33% 115/349 [03:36<07:29,  1.92s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  33% 116/349 [03:38<07:38,  1.97s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  34% 117/349 [03:40<07:44,  2.00s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  34% 118/349 [03:42<07:46,  2.02s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  34% 119/349 [03:44<07:48,  2.04s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  34% 120/349 [03:46<07:48,  2.05s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  35% 121/349 [03:48<07:47,  2.05s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  35% 122/349 [03:50<07:45,  2.05s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  35% 123/349 [03:52<07:37,  2.02s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  36% 124/349 [03:54<07:32,  2.01s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  36% 125/349 [03:56<07:28,  2.00s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  36% 126/349 [03:58<07:25,  2.00s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  36% 127/349 [04:00<07:24,  2.00s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  37% 128/349 [04:02<07:16,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  37% 129/349 [04:04<07:11,  1.96s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  37% 130/349 [04:06<07:07,  1.95s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  38% 131/349 [04:08<07:05,  1.95s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  38% 132/349 [04:10<07:44,  2.14s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  38% 133/349 [04:13<08:10,  2.27s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  38% 134/349 [04:16<08:29,  2.37s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  39% 135/349 [04:18<08:39,  2.43s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  39% 136/349 [04:20<08:01,  2.26s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  39% 137/349 [04:22<07:21,  2.08s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  40% 138/349 [04:23<06:59,  1.99s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  40% 139/349 [04:25<06:42,  1.92s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  40% 140/349 [04:27<06:32,  1.88s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  40% 141/349 [04:29<06:31,  1.88s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  41% 142/349 [04:31<06:29,  1.88s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  41% 143/349 [04:33<06:26,  1.88s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  41% 144/349 [04:34<06:24,  1.88s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  42% 145/349 [04:36<06:22,  1.88s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  42% 146/349 [04:38<06:27,  1.91s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  42% 147/349 [04:40<06:29,  1.93s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  42% 148/349 [04:42<06:29,  1.94s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  43% 149/349 [04:44<06:29,  1.95s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  43% 150/349 [04:46<06:28,  1.95s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  43% 151/349 [04:48<06:27,  1.96s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  44% 152/349 [04:50<06:32,  1.99s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  44% 153/349 [04:52<06:35,  2.02s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  44% 154/349 [04:54<06:36,  2.03s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  44% 155/349 [04:56<06:37,  2.05s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  45% 156/349 [04:59<06:36,  2.06s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  45% 157/349 [05:01<06:30,  2.03s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  45% 158/349 [05:03<06:25,  2.02s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  46% 159/349 [05:04<06:21,  2.01s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  46% 160/349 [05:06<06:17,  2.00s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  46% 161/349 [05:08<06:14,  1.99s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  46% 162/349 [05:10<06:10,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  47% 163/349 [05:12<06:06,  1.97s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  47% 164/349 [05:14<06:03,  1.97s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  47% 165/349 [05:16<05:58,  1.95s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  48% 166/349 [05:18<05:52,  1.93s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  48% 167/349 [05:20<05:46,  1.90s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  48% 168/349 [05:22<05:41,  1.89s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  48% 169/349 [05:24<05:33,  1.85s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  49% 170/349 [05:25<05:23,  1.80s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  49% 171/349 [05:27<05:06,  1.72s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  49% 172/349 [05:28<05:03,  1.71s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  50% 173/349 [05:30<05:05,  1.73s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  50% 174/349 [05:32<05:07,  1.76s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  50% 175/349 [05:34<05:07,  1.77s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  50% 176/349 [05:36<05:11,  1.80s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  51% 177/349 [05:38<05:13,  1.82s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  51% 178/349 [05:39<05:14,  1.84s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  51% 179/349 [05:41<05:14,  1.85s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  52% 180/349 [05:43<05:18,  1.88s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  52% 181/349 [05:45<05:20,  1.91s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  52% 182/349 [05:47<05:20,  1.92s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  52% 183/349 [05:49<05:19,  1.93s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  53% 184/349 [05:51<05:24,  1.97s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  53% 185/349 [05:53<05:26,  1.99s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  53% 186/349 [05:55<05:27,  2.01s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  54% 187/349 [05:57<05:26,  2.02s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  54% 188/349 [05:59<05:25,  2.02s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  54% 189/349 [06:01<05:21,  2.01s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  54% 190/349 [06:03<05:17,  2.00s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  55% 191/349 [06:05<05:14,  1.99s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  55% 192/349 [06:07<05:12,  1.99s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  55% 193/349 [06:09<05:09,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  56% 194/349 [06:11<05:06,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  56% 195/349 [06:13<05:07,  2.00s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  56% 196/349 [06:15<05:03,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  56% 197/349 [06:17<05:01,  1.99s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  57% 198/349 [06:19<05:00,  1.99s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  57% 199/349 [06:21<04:57,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  57% 200/349 [06:23<04:51,  1.95s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  58% 201/349 [06:25<04:35,  1.86s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  58% 202/349 [06:27<04:33,  1.86s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  58% 203/349 [06:28<04:30,  1.85s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  58% 204/349 [06:30<04:27,  1.84s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  59% 205/349 [06:32<04:28,  1.87s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  59% 206/349 [06:34<04:30,  1.89s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  59% 207/349 [06:36<04:30,  1.91s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  60% 208/349 [06:38<04:30,  1.92s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  60% 209/349 [06:40<04:32,  1.95s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  60% 210/349 [06:42<04:35,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  60% 211/349 [06:44<04:35,  2.00s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  61% 212/349 [06:46<04:40,  2.05s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  61% 213/349 [06:48<04:45,  2.10s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  61% 214/349 [06:51<04:48,  2.13s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  62% 215/349 [06:53<04:47,  2.15s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  62% 216/349 [06:55<04:42,  2.13s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  62% 217/349 [06:57<04:39,  2.11s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  62% 218/349 [06:59<04:38,  2.12s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  63% 219/349 [07:01<04:34,  2.11s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  63% 220/349 [07:03<04:32,  2.11s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  63% 221/349 [07:05<04:29,  2.11s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  64% 222/349 [07:08<04:26,  2.10s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  64% 223/349 [07:10<04:21,  2.08s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  64% 224/349 [07:12<04:16,  2.05s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  64% 225/349 [07:14<04:10,  2.02s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  65% 226/349 [07:15<04:02,  1.97s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  65% 227/349 [07:17<03:48,  1.87s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  65% 228/349 [07:19<03:48,  1.89s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  66% 229/349 [07:21<03:48,  1.91s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  66% 230/349 [07:23<03:52,  1.96s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  66% 231/349 [07:25<03:54,  1.99s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  66% 232/349 [07:27<03:54,  2.00s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  67% 233/349 [07:29<03:55,  2.03s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  67% 234/349 [07:31<03:55,  2.05s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  67% 235/349 [07:34<04:01,  2.12s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  68% 236/349 [07:36<04:02,  2.14s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  68% 237/349 [07:38<04:01,  2.16s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  68% 238/349 [07:40<03:59,  2.16s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  68% 239/349 [07:42<03:57,  2.16s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  69% 240/349 [07:44<03:54,  2.15s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  69% 241/349 [07:46<03:50,  2.14s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  69% 242/349 [07:49<03:46,  2.11s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  70% 243/349 [07:51<03:40,  2.08s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  70% 244/349 [07:53<03:35,  2.05s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  70% 245/349 [07:54<03:30,  2.02s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  70% 246/349 [07:56<03:19,  1.94s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  71% 247/349 [07:58<03:12,  1.89s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  71% 248/349 [08:00<03:16,  1.94s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  71% 249/349 [08:02<03:13,  1.93s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  72% 250/349 [08:04<03:12,  1.94s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  72% 251/349 [08:06<03:12,  1.97s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  72% 252/349 [08:08<03:12,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  72% 253/349 [08:10<03:13,  2.02s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  73% 254/349 [08:12<03:14,  2.05s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  73% 255/349 [08:14<03:15,  2.08s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  73% 256/349 [08:16<03:13,  2.08s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  74% 257/349 [08:19<03:10,  2.08s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  74% 258/349 [08:21<03:07,  2.07s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  74% 259/349 [08:23<03:03,  2.03s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  74% 260/349 [08:24<02:59,  2.02s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  75% 261/349 [08:26<02:55,  1.99s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  75% 262/349 [08:28<02:46,  1.91s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  75% 263/349 [08:30<02:37,  1.83s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  76% 264/349 [08:32<02:37,  1.85s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  76% 265/349 [08:34<02:37,  1.88s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  76% 266/349 [08:36<02:36,  1.89s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  77% 267/349 [08:38<02:37,  1.92s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  77% 268/349 [08:40<02:39,  1.97s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  77% 269/349 [08:42<02:40,  2.00s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  77% 270/349 [08:44<02:38,  2.01s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  78% 271/349 [08:46<02:36,  2.01s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  78% 272/349 [08:48<02:33,  2.00s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  78% 273/349 [08:50<02:30,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  79% 274/349 [08:52<02:26,  1.95s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  79% 275/349 [08:53<02:20,  1.90s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  79% 276/349 [08:55<02:12,  1.82s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  79% 277/349 [08:57<02:12,  1.84s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  80% 278/349 [08:59<02:13,  1.88s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  80% 279/349 [09:01<02:14,  1.92s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  80% 280/349 [09:03<02:16,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  81% 281/349 [09:05<02:16,  2.01s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  81% 282/349 [09:07<02:14,  2.01s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  81% 283/349 [09:09<02:12,  2.00s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  81% 284/349 [09:11<02:09,  1.99s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  82% 285/349 [09:13<02:05,  1.96s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  82% 286/349 [09:14<01:56,  1.85s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  82% 287/349 [09:16<01:51,  1.80s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  83% 288/349 [09:18<01:51,  1.83s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  83% 289/349 [09:20<01:53,  1.89s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  83% 290/349 [09:22<01:54,  1.95s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  83% 291/349 [09:24<01:54,  1.97s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  84% 292/349 [09:26<01:52,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  84% 293/349 [09:28<01:51,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  84% 294/349 [09:30<01:47,  1.95s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  85% 295/349 [09:32<01:38,  1.83s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  85% 296/349 [09:33<01:32,  1.75s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  85% 297/349 [09:35<01:34,  1.81s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  85% 298/349 [09:37<01:35,  1.87s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  86% 299/349 [09:39<01:37,  1.94s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  86% 300/349 [09:41<01:36,  1.97s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  86% 301/349 [09:43<01:34,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  87% 302/349 [09:45<01:31,  1.95s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  87% 303/349 [09:47<01:25,  1.86s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  87% 304/349 [09:49<01:25,  1.90s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  87% 305/349 [09:51<01:26,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  88% 306/349 [09:53<01:25,  2.00s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  88% 307/349 [09:55<01:23,  1.99s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  88% 308/349 [09:57<01:19,  1.94s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  89% 309/349 [09:58<01:14,  1.86s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  89% 310/349 [10:01<01:15,  1.93s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  89% 311/349 [10:03<01:14,  1.97s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  89% 312/349 [10:05<01:13,  1.98s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  90% 313/349 [10:06<01:09,  1.94s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  90% 314/349 [10:08<01:05,  1.86s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  90% 315/349 [10:10<01:06,  1.94s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  91% 316/349 [10:12<01:05,  1.97s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  91% 317/349 [10:14<01:02,  1.94s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  91% 318/349 [10:16<00:57,  1.86s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  91% 319/349 [10:18<00:58,  1.94s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  92% 320/349 [10:20<00:56,  1.96s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  92% 321/349 [10:22<00:53,  1.91s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  92% 322/349 [10:23<00:50,  1.86s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  93% 323/349 [10:26<00:49,  1.91s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  93% 324/349 [10:27<00:47,  1.90s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  93% 325/349 [10:29<00:44,  1.85s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  93% 326/349 [10:31<00:43,  1.90s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  94% 327/349 [10:33<00:39,  1.80s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  94% 328/349 [10:34<00:37,  1.77s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  94% 329/349 [10:36<00:36,  1.82s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  95% 330/349 [10:38<00:34,  1.79s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  95% 331/349 [10:40<00:33,  1.85s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  95% 332/349 [10:42<00:30,  1.81s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  95% 333/349 [10:44<00:29,  1.85s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  96% 334/349 [10:45<00:27,  1.82s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  96% 335/349 [10:47<00:25,  1.84s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  96% 336/349 [10:49<00:23,  1.79s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  97% 337/349 [10:51<00:20,  1.71s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  97% 338/349 [10:52<00:18,  1.69s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  97% 339/349 [10:54<00:15,  1.59s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  97% 340/349 [10:55<00:14,  1.60s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  98% 341/349 [10:57<00:12,  1.60s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  98% 342/349 [10:58<00:10,  1.56s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  98% 343/349 [11:00<00:09,  1.59s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  99% 344/349 [11:02<00:08,  1.67s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  99% 345/349 [11:04<00:06,  1.70s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  99% 346/349 [11:05<00:05,  1.70s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  99% 347/349 [11:07<00:03,  1.72s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset: 100% 348/349 [11:09<00:01,  1.68s/it]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset: 100% 349/349 [11:09<00:00,  1.22s/it]\u001b[A\n",
            "                                                                          \u001b[A2022-03-10 16:50:56 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 5.982 | nll_loss 4.642 | ppl 24.97 | wps 6049.3 | wpb 11550.8 | bsz 1316.4 | num_updates 1062 | best_loss 5.982\n",
            "2022-03-10 16:50:56 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)\n",
            "2022-03-10 16:50:56 | INFO | train | epoch 018 | loss 5.805 | nll_loss 4.521 | ppl 22.95 | wps 1059.9 | ups 0.03 | wpb 32762.2 | bsz 3745.8 | num_updates 1062 | lr 0.000185923 | gnorm 1.824 | train_wall 1150 | wall 5667\n",
            "2022-03-10 16:50:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 59\n",
            "epoch 019:   0% 0/59 [00:00<?, ?it/s]2022-03-10 16:50:57 | INFO | fairseq.trainer | begin training epoch 19\n",
            "2022-03-10 16:50:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 019:  98% 58/59 [18:09<00:19, 19.38s/it, loss=5.706, nll_loss=4.407, ppl=21.21, wps=892.6, ups=0.03, wpb=32731.3, bsz=3733.5, num_updates=1100, lr=0.000192573, gnorm=1.745, train_wall=1917, wall=6382]2022-03-10 17:09:25 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 019 | valid on 'valid' subset:   0% 0/349 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   0% 1/349 [00:04<27:34,  4.75s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   1% 2/349 [00:06<17:34,  3.04s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   1% 3/349 [00:07<12:44,  2.21s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   1% 4/349 [00:09<10:54,  1.90s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   1% 5/349 [00:11<12:10,  2.12s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   2% 6/349 [00:13<11:36,  2.03s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   2% 7/349 [00:15<11:12,  1.97s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   2% 8/349 [00:17<11:29,  2.02s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   3% 9/349 [00:19<11:45,  2.08s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   3% 10/349 [00:21<11:41,  2.07s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   3% 11/349 [00:23<11:32,  2.05s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   3% 12/349 [00:25<11:12,  2.00s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   4% 13/349 [00:27<11:00,  1.96s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   4% 14/349 [00:29<10:50,  1.94s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   4% 15/349 [00:31<10:30,  1.89s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   5% 16/349 [00:32<10:12,  1.84s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   5% 17/349 [00:34<09:38,  1.74s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   5% 18/349 [00:35<09:12,  1.67s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   5% 19/349 [00:38<10:04,  1.83s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   6% 20/349 [00:39<09:44,  1.78s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   6% 21/349 [00:41<09:28,  1.73s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   6% 22/349 [00:43<10:19,  1.89s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   7% 23/349 [00:45<10:17,  1.89s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   7% 24/349 [00:47<10:17,  1.90s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   7% 25/349 [00:49<10:08,  1.88s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   7% 26/349 [00:51<10:38,  1.98s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   8% 27/349 [00:53<10:51,  2.02s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   8% 28/349 [00:55<11:00,  2.06s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   8% 29/349 [00:58<11:05,  2.08s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   9% 30/349 [01:00<10:56,  2.06s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   9% 31/349 [01:01<10:47,  2.04s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   9% 32/349 [01:03<10:40,  2.02s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:   9% 33/349 [01:05<10:27,  1.99s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  10% 34/349 [01:07<10:19,  1.97s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  10% 35/349 [01:09<10:05,  1.93s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  10% 36/349 [01:11<09:49,  1.88s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  11% 37/349 [01:13<09:24,  1.81s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  11% 38/349 [01:14<08:54,  1.72s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  11% 39/349 [01:16<08:33,  1.66s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  11% 40/349 [01:17<08:37,  1.67s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  12% 41/349 [01:19<08:42,  1.70s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  12% 42/349 [01:21<08:42,  1.70s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  12% 43/349 [01:22<08:41,  1.70s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  13% 44/349 [01:25<09:31,  1.87s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  13% 45/349 [01:27<09:35,  1.89s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  13% 46/349 [01:29<09:38,  1.91s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  13% 47/349 [01:31<09:38,  1.91s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  14% 48/349 [01:33<09:39,  1.93s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  14% 49/349 [01:34<09:39,  1.93s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  14% 50/349 [01:37<09:58,  2.00s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  15% 51/349 [01:39<10:08,  2.04s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  15% 52/349 [01:41<10:14,  2.07s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  15% 53/349 [01:43<10:14,  2.08s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  15% 54/349 [01:45<10:18,  2.10s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  16% 55/349 [01:47<10:08,  2.07s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  16% 56/349 [01:49<09:59,  2.05s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  16% 57/349 [01:51<09:52,  2.03s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  17% 58/349 [01:53<09:47,  2.02s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  17% 59/349 [01:55<09:35,  1.98s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  17% 60/349 [01:57<09:28,  1.97s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  17% 61/349 [01:59<09:21,  1.95s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  18% 62/349 [02:01<09:12,  1.92s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  18% 63/349 [02:03<08:59,  1.89s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  18% 64/349 [02:04<08:48,  1.85s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  19% 65/349 [02:06<08:25,  1.78s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  19% 66/349 [02:07<08:03,  1.71s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  19% 67/349 [02:09<07:54,  1.68s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  19% 68/349 [02:11<07:45,  1.66s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  20% 69/349 [02:12<07:56,  1.70s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  20% 70/349 [02:14<08:05,  1.74s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  20% 71/349 [02:16<08:08,  1.76s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  21% 72/349 [02:18<08:08,  1.76s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  21% 73/349 [02:20<08:08,  1.77s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  21% 74/349 [02:22<08:23,  1.83s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  21% 75/349 [02:24<08:38,  1.89s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  22% 76/349 [02:26<08:44,  1.92s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  22% 77/349 [02:28<08:48,  1.94s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  22% 78/349 [02:30<08:53,  1.97s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  23% 79/349 [02:32<08:53,  1.97s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  23% 80/349 [02:34<08:52,  1.98s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  23% 81/349 [02:36<09:03,  2.03s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  23% 82/349 [02:38<09:09,  2.06s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  24% 83/349 [02:40<09:17,  2.10s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  24% 84/349 [02:43<09:55,  2.25s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  24% 85/349 [02:46<10:52,  2.47s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  25% 86/349 [02:48<10:46,  2.46s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  25% 87/349 [02:50<10:05,  2.31s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  25% 88/349 [02:52<09:38,  2.22s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  26% 89/349 [02:54<09:21,  2.16s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  26% 90/349 [02:56<09:05,  2.11s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  26% 91/349 [02:58<08:54,  2.07s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  26% 92/349 [03:00<08:44,  2.04s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  27% 93/349 [03:02<08:35,  2.01s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  27% 94/349 [03:04<08:34,  2.02s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  27% 95/349 [03:06<08:20,  1.97s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  28% 96/349 [03:08<08:12,  1.95s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  28% 97/349 [03:10<08:02,  1.92s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  28% 98/349 [03:11<07:43,  1.85s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  28% 99/349 [03:13<07:31,  1.81s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  29% 100/349 [03:15<07:14,  1.74s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  29% 101/349 [03:16<06:57,  1.68s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  29% 102/349 [03:18<07:15,  1.76s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  30% 103/349 [03:20<07:23,  1.80s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  30% 104/349 [03:22<07:12,  1.77s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  30% 105/349 [03:24<07:29,  1.84s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  30% 106/349 [03:26<08:00,  1.98s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  31% 107/349 [03:28<07:50,  1.94s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  31% 108/349 [03:30<07:53,  1.96s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  31% 109/349 [03:32<07:57,  1.99s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  32% 110/349 [03:34<08:01,  2.02s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  32% 111/349 [03:36<08:15,  2.08s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  32% 112/349 [03:38<08:26,  2.14s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  32% 113/349 [03:41<08:21,  2.13s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  33% 114/349 [03:43<08:26,  2.15s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  33% 115/349 [03:45<08:36,  2.21s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  33% 116/349 [03:48<08:46,  2.26s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  34% 117/349 [03:50<08:41,  2.25s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  34% 118/349 [03:52<08:48,  2.29s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  34% 119/349 [03:55<09:02,  2.36s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  34% 120/349 [03:57<09:01,  2.37s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  35% 121/349 [03:59<08:55,  2.35s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  35% 122/349 [04:02<08:47,  2.32s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  35% 123/349 [04:04<08:49,  2.34s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  36% 124/349 [04:06<08:38,  2.30s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  36% 125/349 [04:08<08:27,  2.27s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  36% 126/349 [04:11<08:16,  2.23s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  36% 127/349 [04:13<08:26,  2.28s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  37% 128/349 [04:15<08:18,  2.25s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  37% 129/349 [04:17<08:01,  2.19s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  37% 130/349 [04:19<07:56,  2.18s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  38% 131/349 [04:22<08:03,  2.22s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  38% 132/349 [04:24<07:55,  2.19s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  38% 133/349 [04:26<07:32,  2.09s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  38% 134/349 [04:27<07:14,  2.02s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  39% 135/349 [04:30<07:15,  2.04s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  39% 136/349 [04:31<06:51,  1.93s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  39% 137/349 [04:33<06:42,  1.90s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  40% 138/349 [04:35<06:37,  1.88s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  40% 139/349 [04:37<06:37,  1.89s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  40% 140/349 [04:39<06:39,  1.91s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  40% 141/349 [04:41<06:43,  1.94s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  41% 142/349 [04:43<06:47,  1.97s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  41% 143/349 [04:45<06:51,  2.00s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  41% 144/349 [04:47<06:49,  2.00s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  42% 145/349 [04:49<06:52,  2.02s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  42% 146/349 [04:51<07:06,  2.10s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  42% 147/349 [04:53<07:11,  2.14s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  42% 148/349 [04:56<07:24,  2.21s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  43% 149/349 [04:58<07:39,  2.30s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  43% 150/349 [05:01<07:38,  2.30s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  43% 151/349 [05:03<07:27,  2.26s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  44% 152/349 [05:05<07:37,  2.32s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  44% 153/349 [05:08<07:52,  2.41s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  44% 154/349 [05:10<07:50,  2.41s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  44% 155/349 [05:13<07:43,  2.39s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  45% 156/349 [05:15<07:38,  2.38s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  45% 157/349 [05:17<07:26,  2.33s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  45% 158/349 [05:19<07:19,  2.30s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  46% 159/349 [05:22<07:22,  2.33s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  46% 160/349 [05:24<07:16,  2.31s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  46% 161/349 [05:26<07:17,  2.32s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  46% 162/349 [05:29<07:18,  2.35s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  47% 163/349 [05:31<07:16,  2.35s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  47% 164/349 [05:33<07:09,  2.32s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  47% 165/349 [05:35<06:48,  2.22s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  48% 166/349 [05:37<06:31,  2.14s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  48% 167/349 [05:39<06:18,  2.08s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  48% 168/349 [05:41<06:08,  2.04s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  48% 169/349 [05:43<05:55,  1.98s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  49% 170/349 [05:45<05:42,  1.91s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  49% 171/349 [05:47<05:25,  1.83s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  49% 172/349 [05:48<05:15,  1.78s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  50% 173/349 [05:50<05:12,  1.78s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  50% 174/349 [05:52<05:11,  1.78s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  50% 175/349 [05:54<05:09,  1.78s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  50% 176/349 [05:55<05:13,  1.81s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  51% 177/349 [05:57<05:13,  1.82s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  51% 178/349 [05:59<05:12,  1.83s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  51% 179/349 [06:01<05:12,  1.84s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  52% 180/349 [06:03<05:21,  1.90s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  52% 181/349 [06:05<05:25,  1.94s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  52% 182/349 [06:07<05:27,  1.96s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  52% 183/349 [06:09<05:29,  1.99s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  53% 184/349 [06:11<05:36,  2.04s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  53% 185/349 [06:13<05:40,  2.08s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  53% 186/349 [06:16<05:41,  2.10s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  54% 187/349 [06:18<05:41,  2.11s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  54% 188/349 [06:20<05:40,  2.11s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  54% 189/349 [06:22<05:36,  2.10s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  54% 190/349 [06:24<05:33,  2.10s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  55% 191/349 [06:26<05:31,  2.10s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  55% 192/349 [06:28<05:27,  2.09s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  55% 193/349 [06:30<05:22,  2.06s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  56% 194/349 [06:32<05:15,  2.03s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  56% 195/349 [06:34<05:09,  2.01s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  56% 196/349 [06:36<05:04,  1.99s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  56% 197/349 [06:38<04:59,  1.97s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  57% 198/349 [06:40<04:54,  1.95s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  57% 199/349 [06:42<04:47,  1.91s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  57% 200/349 [06:43<04:38,  1.87s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  58% 201/349 [06:45<04:25,  1.79s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  58% 202/349 [06:47<04:31,  1.85s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  58% 203/349 [06:49<04:55,  2.03s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  58% 204/349 [06:51<04:51,  2.01s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  59% 205/349 [06:53<04:44,  1.98s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  59% 206/349 [06:55<04:39,  1.95s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  59% 207/349 [06:57<04:34,  1.94s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  60% 208/349 [06:59<04:31,  1.93s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  60% 209/349 [07:01<04:34,  1.96s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  60% 210/349 [07:03<04:35,  1.99s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  60% 211/349 [07:05<04:38,  2.02s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  61% 212/349 [07:07<04:43,  2.07s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  61% 213/349 [07:10<04:44,  2.09s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  61% 214/349 [07:12<04:45,  2.11s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  62% 215/349 [07:14<04:44,  2.13s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  62% 216/349 [07:16<04:41,  2.12s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  62% 217/349 [07:18<04:39,  2.12s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  62% 218/349 [07:20<04:34,  2.10s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  63% 219/349 [07:22<04:28,  2.07s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  63% 220/349 [07:24<04:22,  2.04s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  63% 221/349 [07:26<04:19,  2.02s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  64% 222/349 [07:28<04:15,  2.01s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  64% 223/349 [07:30<04:09,  1.98s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  64% 224/349 [07:32<04:05,  1.97s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  64% 225/349 [07:34<03:59,  1.94s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  65% 226/349 [07:36<03:51,  1.88s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  65% 227/349 [07:37<03:37,  1.78s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  65% 228/349 [07:39<03:42,  1.84s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  66% 229/349 [07:41<03:39,  1.83s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  66% 230/349 [07:43<03:39,  1.84s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  66% 231/349 [07:45<03:37,  1.84s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  66% 232/349 [07:47<03:37,  1.86s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  67% 233/349 [07:49<03:41,  1.91s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  67% 234/349 [07:51<03:43,  1.95s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  67% 235/349 [07:53<03:47,  2.00s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  68% 236/349 [07:55<03:49,  2.03s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  68% 237/349 [07:57<03:49,  2.05s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  68% 238/349 [07:59<03:47,  2.05s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  68% 239/349 [08:01<03:44,  2.04s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  69% 240/349 [08:03<03:39,  2.01s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  69% 241/349 [08:05<03:35,  1.99s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  69% 242/349 [08:07<03:30,  1.97s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  70% 243/349 [08:09<03:27,  1.96s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  70% 244/349 [08:11<03:23,  1.94s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  70% 245/349 [08:12<03:18,  1.91s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  70% 246/349 [08:14<03:06,  1.81s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  71% 247/349 [08:16<02:58,  1.75s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  71% 248/349 [08:18<03:02,  1.81s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  71% 249/349 [08:19<02:58,  1.79s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  72% 250/349 [08:21<03:02,  1.84s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  72% 251/349 [08:23<03:05,  1.90s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  72% 252/349 [08:25<03:07,  1.93s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  72% 253/349 [08:27<03:10,  1.98s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  73% 254/349 [08:29<03:10,  2.01s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  73% 255/349 [08:32<03:09,  2.02s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  73% 256/349 [08:34<03:08,  2.02s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  74% 257/349 [08:36<03:04,  2.00s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  74% 258/349 [08:37<03:00,  1.98s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  74% 259/349 [08:39<02:56,  1.96s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  74% 260/349 [08:41<02:51,  1.92s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  75% 261/349 [08:43<02:46,  1.89s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  75% 262/349 [08:45<02:37,  1.82s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  75% 263/349 [08:46<02:30,  1.75s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  76% 264/349 [08:48<02:29,  1.76s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  76% 265/349 [08:50<02:30,  1.79s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  76% 266/349 [08:52<02:30,  1.82s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  77% 267/349 [08:54<02:34,  1.89s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  77% 268/349 [08:56<02:38,  1.95s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  77% 269/349 [08:58<02:40,  2.00s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  77% 270/349 [09:00<02:38,  2.01s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  78% 271/349 [09:02<02:35,  1.99s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  78% 272/349 [09:04<02:31,  1.97s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  78% 273/349 [09:06<02:27,  1.94s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  79% 274/349 [09:08<02:22,  1.90s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  79% 275/349 [09:09<02:17,  1.85s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  79% 276/349 [09:11<02:08,  1.76s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  79% 277/349 [09:13<02:07,  1.77s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  80% 278/349 [09:15<02:08,  1.81s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  80% 279/349 [09:17<02:27,  2.10s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  80% 280/349 [09:20<02:45,  2.39s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  81% 281/349 [09:23<02:37,  2.31s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  81% 282/349 [09:25<02:29,  2.23s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  81% 283/349 [09:27<02:21,  2.14s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  81% 284/349 [09:28<02:14,  2.07s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  82% 285/349 [09:30<02:08,  2.00s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  82% 286/349 [09:32<01:57,  1.87s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  82% 287/349 [09:33<01:50,  1.78s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  83% 288/349 [09:35<01:48,  1.78s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  83% 289/349 [09:37<01:51,  1.86s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  83% 290/349 [09:39<01:53,  1.92s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  83% 291/349 [09:41<01:52,  1.94s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  84% 292/349 [09:43<01:50,  1.94s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  84% 293/349 [09:45<01:48,  1.94s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  84% 294/349 [09:47<01:44,  1.90s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  85% 295/349 [09:49<01:36,  1.78s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  85% 296/349 [09:50<01:30,  1.70s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  85% 297/349 [09:52<01:32,  1.78s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  85% 298/349 [09:54<01:33,  1.84s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  86% 299/349 [09:56<01:35,  1.90s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  86% 300/349 [09:58<01:33,  1.92s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  86% 301/349 [10:00<01:31,  1.91s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  87% 302/349 [10:02<01:28,  1.87s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  87% 303/349 [10:03<01:22,  1.79s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  87% 304/349 [10:05<01:23,  1.85s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  87% 305/349 [10:07<01:24,  1.92s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  88% 306/349 [10:09<01:22,  1.93s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  88% 307/349 [10:11<01:20,  1.92s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  88% 308/349 [10:13<01:15,  1.85s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  89% 309/349 [10:14<01:11,  1.78s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  89% 310/349 [10:17<01:12,  1.87s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  89% 311/349 [10:19<01:13,  1.93s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  89% 312/349 [10:21<01:11,  1.93s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  90% 313/349 [10:22<01:08,  1.89s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  90% 314/349 [10:24<01:03,  1.81s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  90% 315/349 [10:26<01:04,  1.88s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  91% 316/349 [10:28<01:02,  1.91s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  91% 317/349 [10:30<01:00,  1.88s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  91% 318/349 [10:31<00:55,  1.79s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  91% 319/349 [10:33<00:56,  1.87s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  92% 320/349 [10:35<00:54,  1.89s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  92% 321/349 [10:37<00:51,  1.83s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  92% 322/349 [10:39<00:48,  1.78s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  93% 323/349 [10:41<00:47,  1.84s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  93% 324/349 [10:42<00:45,  1.82s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  93% 325/349 [10:44<00:42,  1.77s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  93% 326/349 [10:46<00:41,  1.82s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  94% 327/349 [10:48<00:38,  1.74s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  94% 328/349 [10:49<00:35,  1.70s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  94% 329/349 [10:51<00:34,  1.75s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  95% 330/349 [10:53<00:32,  1.73s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  95% 331/349 [10:55<00:32,  1.79s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  95% 332/349 [10:56<00:29,  1.75s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  95% 333/349 [10:58<00:28,  1.80s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  96% 334/349 [11:00<00:26,  1.77s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  96% 335/349 [11:02<00:25,  1.80s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  96% 336/349 [11:03<00:22,  1.75s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  97% 337/349 [11:05<00:19,  1.66s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  97% 338/349 [11:07<00:18,  1.65s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  97% 339/349 [11:08<00:15,  1.58s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  97% 340/349 [11:10<00:14,  1.60s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  98% 341/349 [11:11<00:12,  1.59s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  98% 342/349 [11:13<00:10,  1.54s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  98% 343/349 [11:14<00:09,  1.57s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  99% 344/349 [11:16<00:08,  1.63s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  99% 345/349 [11:18<00:06,  1.66s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  99% 346/349 [11:19<00:04,  1.66s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  99% 347/349 [11:21<00:03,  1.67s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset: 100% 348/349 [11:23<00:01,  1.63s/it]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset: 100% 349/349 [11:23<00:00,  1.18s/it]\u001b[A\n",
            "                                                                          \u001b[A2022-03-10 17:20:49 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 5.896 | nll_loss 4.55 | ppl 23.43 | wps 5924.6 | wpb 11550.8 | bsz 1316.4 | num_updates 1121 | best_loss 5.896\n",
            "2022-03-10 17:20:49 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)\n",
            "2022-03-10 17:20:49 | INFO | train | epoch 019 | loss 5.554 | nll_loss 4.23 | ppl 18.77 | wps 1078.5 | ups 0.03 | wpb 32762.2 | bsz 3745.8 | num_updates 1121 | lr 0.000196247 | gnorm 1.625 | train_wall 1104 | wall 7459\n",
            "2022-03-10 17:20:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 59\n",
            "epoch 020:   0% 0/59 [00:00<?, ?it/s]2022-03-10 17:20:49 | INFO | fairseq.trainer | begin training epoch 20\n",
            "2022-03-10 17:20:49 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 020:  98% 58/59 [18:11<00:18, 18.68s/it]2022-03-10 17:39:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 020 | valid on 'valid' subset:   0% 0/349 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   0% 1/349 [00:04<28:20,  4.89s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   1% 2/349 [00:07<19:19,  3.34s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   1% 3/349 [00:08<13:27,  2.33s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   1% 4/349 [00:09<11:29,  2.00s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   1% 5/349 [00:11<11:55,  2.08s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   2% 6/349 [00:13<11:27,  2.01s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   2% 7/349 [00:15<11:10,  1.96s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   2% 8/349 [00:17<11:41,  2.06s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   3% 9/349 [00:20<12:01,  2.12s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   3% 10/349 [00:22<11:51,  2.10s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   3% 11/349 [00:24<11:47,  2.09s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   3% 12/349 [00:26<11:28,  2.04s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   4% 13/349 [00:28<11:17,  2.02s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   4% 14/349 [00:30<11:04,  1.99s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   4% 15/349 [00:31<10:45,  1.93s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   5% 16/349 [00:33<10:19,  1.86s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   5% 17/349 [00:35<09:42,  1.75s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   5% 18/349 [00:36<09:16,  1.68s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   5% 19/349 [00:38<09:18,  1.69s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   6% 20/349 [00:40<09:17,  1.69s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   6% 21/349 [00:41<09:16,  1.70s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   6% 22/349 [00:43<09:36,  1.76s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   7% 23/349 [00:45<09:51,  1.81s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   7% 24/349 [00:47<09:59,  1.84s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   7% 25/349 [00:49<10:01,  1.86s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   7% 26/349 [00:51<10:37,  1.97s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   8% 27/349 [00:53<10:59,  2.05s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   8% 28/349 [00:56<11:15,  2.10s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   8% 29/349 [00:59<12:45,  2.39s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   9% 30/349 [01:02<13:43,  2.58s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   9% 31/349 [01:05<14:08,  2.67s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   9% 32/349 [01:07<13:03,  2.47s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:   9% 33/349 [01:09<12:06,  2.30s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  10% 34/349 [01:10<11:24,  2.17s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  10% 35/349 [01:12<10:48,  2.07s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  10% 36/349 [01:14<10:17,  1.97s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  11% 37/349 [01:16<09:46,  1.88s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  11% 38/349 [01:17<09:13,  1.78s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  11% 39/349 [01:19<08:51,  1.71s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  11% 40/349 [01:21<08:52,  1.72s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  12% 41/349 [01:22<08:51,  1.73s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  12% 42/349 [01:24<08:50,  1.73s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  12% 43/349 [01:26<08:49,  1.73s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  13% 44/349 [01:28<09:08,  1.80s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  13% 45/349 [01:30<09:18,  1.84s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  13% 46/349 [01:32<09:26,  1.87s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  13% 47/349 [01:33<09:29,  1.89s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  14% 48/349 [01:35<09:30,  1.90s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  14% 49/349 [01:37<09:31,  1.90s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  14% 50/349 [01:40<09:58,  2.00s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  15% 51/349 [01:42<10:16,  2.07s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  15% 52/349 [01:44<10:26,  2.11s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  15% 53/349 [01:46<10:30,  2.13s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  15% 54/349 [01:48<10:36,  2.16s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  16% 55/349 [01:50<10:23,  2.12s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  16% 56/349 [01:52<10:11,  2.09s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  16% 57/349 [01:54<10:04,  2.07s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  17% 58/349 [01:56<09:58,  2.06s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  17% 59/349 [01:58<09:44,  2.01s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  17% 60/349 [02:00<09:33,  1.98s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  17% 61/349 [02:02<09:24,  1.96s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  18% 62/349 [02:04<09:13,  1.93s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  18% 63/349 [02:06<08:58,  1.88s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  18% 64/349 [02:08<08:45,  1.84s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  19% 65/349 [02:09<08:21,  1.77s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  19% 66/349 [02:11<08:00,  1.70s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  19% 67/349 [02:12<07:54,  1.68s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  19% 68/349 [02:14<07:51,  1.68s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  20% 69/349 [02:16<08:05,  1.73s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  20% 70/349 [02:18<08:12,  1.76s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  20% 71/349 [02:20<08:17,  1.79s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  21% 72/349 [02:21<08:20,  1.81s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  21% 73/349 [02:23<08:22,  1.82s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  21% 74/349 [02:25<08:37,  1.88s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  21% 75/349 [02:27<08:45,  1.92s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  22% 76/349 [02:29<08:51,  1.95s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  22% 77/349 [02:31<08:54,  1.96s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  22% 78/349 [02:33<08:55,  1.98s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  23% 79/349 [02:35<08:54,  1.98s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  23% 80/349 [02:37<08:58,  2.00s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  23% 81/349 [02:40<09:15,  2.07s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  23% 82/349 [02:42<09:27,  2.12s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  24% 83/349 [02:44<09:34,  2.16s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  24% 84/349 [02:46<09:36,  2.17s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  24% 85/349 [02:49<09:37,  2.19s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  25% 86/349 [02:51<09:39,  2.20s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  25% 87/349 [02:53<09:26,  2.16s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  25% 88/349 [02:55<09:20,  2.15s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  26% 89/349 [02:57<09:14,  2.13s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  26% 90/349 [02:59<09:08,  2.12s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  26% 91/349 [03:01<09:03,  2.11s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  26% 92/349 [03:03<08:50,  2.06s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  27% 93/349 [03:05<08:39,  2.03s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  27% 94/349 [03:07<08:31,  2.01s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  27% 95/349 [03:09<08:20,  1.97s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  28% 96/349 [03:11<08:14,  1.95s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  28% 97/349 [03:13<08:08,  1.94s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  28% 98/349 [03:14<07:47,  1.86s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  28% 99/349 [03:16<07:36,  1.83s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  29% 100/349 [03:18<07:13,  1.74s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  29% 101/349 [03:19<06:55,  1.68s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  29% 102/349 [03:21<06:56,  1.68s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  30% 103/349 [03:23<06:55,  1.69s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  30% 104/349 [03:24<06:54,  1.69s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  30% 105/349 [03:26<07:10,  1.76s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  30% 106/349 [03:28<07:19,  1.81s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  31% 107/349 [03:30<07:25,  1.84s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  31% 108/349 [03:32<07:28,  1.86s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  31% 109/349 [03:34<07:31,  1.88s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  32% 110/349 [03:36<07:41,  1.93s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  32% 111/349 [03:38<07:48,  1.97s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  32% 112/349 [03:40<07:51,  1.99s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  32% 113/349 [03:42<07:53,  2.01s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  33% 114/349 [03:44<07:55,  2.02s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  33% 115/349 [03:46<07:53,  2.02s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  33% 116/349 [03:48<08:02,  2.07s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  34% 117/349 [03:51<08:07,  2.10s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  34% 118/349 [03:53<08:08,  2.11s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  34% 119/349 [03:55<08:09,  2.13s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  34% 120/349 [03:57<08:10,  2.14s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  35% 121/349 [03:59<08:10,  2.15s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  35% 122/349 [04:01<08:07,  2.15s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  35% 123/349 [04:03<07:59,  2.12s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  36% 124/349 [04:06<07:56,  2.12s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  36% 125/349 [04:08<07:53,  2.11s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  36% 126/349 [04:10<07:50,  2.11s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  36% 127/349 [04:12<07:48,  2.11s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  37% 128/349 [04:14<07:41,  2.09s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  37% 129/349 [04:16<07:35,  2.07s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  37% 130/349 [04:18<07:30,  2.06s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  38% 131/349 [04:20<07:23,  2.04s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  38% 132/349 [04:22<07:17,  2.01s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  38% 133/349 [04:24<07:09,  1.99s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  38% 134/349 [04:26<06:57,  1.94s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  39% 135/349 [04:27<06:43,  1.89s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  39% 136/349 [04:29<06:22,  1.80s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  39% 137/349 [04:31<06:08,  1.74s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  40% 138/349 [04:32<06:10,  1.76s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  40% 139/349 [04:34<06:10,  1.76s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  40% 140/349 [04:36<06:09,  1.77s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  40% 141/349 [04:38<06:19,  1.82s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  41% 142/349 [04:40<06:24,  1.86s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  41% 143/349 [04:42<06:27,  1.88s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  41% 144/349 [04:44<06:29,  1.90s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  42% 145/349 [04:46<06:30,  1.92s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  42% 146/349 [04:48<06:36,  1.95s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  42% 147/349 [04:50<06:40,  1.98s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  42% 148/349 [04:52<06:42,  2.00s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  43% 149/349 [04:54<06:43,  2.02s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  43% 150/349 [04:56<06:44,  2.03s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  43% 151/349 [04:58<06:43,  2.04s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  44% 152/349 [05:00<06:49,  2.08s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  44% 153/349 [05:02<06:52,  2.11s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  44% 154/349 [05:05<06:59,  2.15s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  44% 155/349 [05:07<07:11,  2.22s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  45% 156/349 [05:09<07:04,  2.20s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  45% 157/349 [05:11<06:56,  2.17s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  45% 158/349 [05:13<06:48,  2.14s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  46% 159/349 [05:15<06:44,  2.13s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  46% 160/349 [05:18<06:40,  2.12s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  46% 161/349 [05:20<06:38,  2.12s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  46% 162/349 [05:22<06:30,  2.09s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  47% 163/349 [05:24<06:24,  2.07s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  47% 164/349 [05:26<06:19,  2.05s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  47% 165/349 [05:28<06:14,  2.03s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  48% 166/349 [05:30<06:08,  2.01s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  48% 167/349 [05:32<06:03,  2.00s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  48% 168/349 [05:34<05:59,  1.99s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  48% 169/349 [05:35<05:49,  1.94s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  49% 170/349 [05:37<05:36,  1.88s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  49% 171/349 [05:39<05:18,  1.79s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  49% 172/349 [05:40<05:10,  1.75s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  50% 173/349 [05:42<05:12,  1.78s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  50% 174/349 [05:44<05:13,  1.79s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  50% 175/349 [05:46<05:13,  1.80s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  50% 176/349 [05:48<05:18,  1.84s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  51% 177/349 [05:50<05:21,  1.87s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  51% 178/349 [05:52<05:24,  1.90s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  51% 179/349 [05:54<05:26,  1.92s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  52% 180/349 [05:56<05:30,  1.96s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  52% 181/349 [05:58<05:33,  1.98s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  52% 182/349 [06:00<05:35,  2.01s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  52% 183/349 [06:02<05:37,  2.03s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  53% 184/349 [06:04<05:41,  2.07s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  53% 185/349 [06:06<05:44,  2.10s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  53% 186/349 [06:08<05:46,  2.12s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  54% 187/349 [06:11<05:45,  2.13s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  54% 188/349 [06:13<05:44,  2.14s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  54% 189/349 [06:15<05:40,  2.13s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  54% 190/349 [06:17<05:37,  2.12s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  55% 191/349 [06:19<05:34,  2.12s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  55% 192/349 [06:21<05:31,  2.11s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  55% 193/349 [06:23<05:25,  2.09s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  56% 194/349 [06:25<05:20,  2.07s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  56% 195/349 [06:27<05:17,  2.06s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  56% 196/349 [06:29<05:13,  2.05s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  56% 197/349 [06:31<05:08,  2.03s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  57% 198/349 [06:33<05:03,  2.01s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  57% 199/349 [06:35<04:59,  1.99s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  57% 200/349 [06:37<04:48,  1.94s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  58% 201/349 [06:39<04:31,  1.83s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  58% 202/349 [06:40<04:25,  1.81s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  58% 203/349 [06:42<04:29,  1.85s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  58% 204/349 [06:44<04:28,  1.85s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  59% 205/349 [06:46<04:31,  1.89s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  59% 206/349 [06:48<04:33,  1.92s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  59% 207/349 [06:50<04:34,  1.93s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  60% 208/349 [06:52<04:34,  1.95s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  60% 209/349 [06:54<04:37,  1.99s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  60% 210/349 [06:56<04:40,  2.02s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  60% 211/349 [06:58<04:39,  2.03s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  61% 212/349 [07:00<04:44,  2.08s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  61% 213/349 [07:03<04:46,  2.11s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  61% 214/349 [07:05<04:47,  2.13s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  62% 215/349 [07:07<04:47,  2.14s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  62% 216/349 [07:09<04:44,  2.14s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  62% 217/349 [07:11<04:41,  2.13s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  62% 218/349 [07:13<04:38,  2.13s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  63% 219/349 [07:15<04:34,  2.11s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  63% 220/349 [07:17<04:30,  2.09s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  63% 221/349 [07:19<04:26,  2.08s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  64% 222/349 [07:22<04:22,  2.06s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  64% 223/349 [07:24<04:17,  2.05s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  64% 224/349 [07:26<04:13,  2.03s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  64% 225/349 [07:27<04:06,  1.99s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  65% 226/349 [07:29<03:56,  1.93s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  65% 227/349 [07:31<03:40,  1.81s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  65% 228/349 [07:32<03:37,  1.80s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  66% 229/349 [07:34<03:40,  1.84s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  66% 230/349 [07:36<03:44,  1.89s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  66% 231/349 [07:38<03:46,  1.92s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  66% 232/349 [07:40<03:46,  1.94s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  67% 233/349 [07:42<03:48,  1.97s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  67% 234/349 [07:44<03:48,  1.99s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  67% 235/349 [07:47<03:52,  2.04s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  68% 236/349 [07:49<03:53,  2.07s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  68% 237/349 [07:51<03:54,  2.09s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  68% 238/349 [07:53<03:54,  2.11s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  68% 239/349 [07:55<03:51,  2.11s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  69% 240/349 [07:57<03:48,  2.09s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  69% 241/349 [07:59<03:44,  2.08s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  69% 242/349 [08:01<03:40,  2.06s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  70% 243/349 [08:03<03:34,  2.03s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  70% 244/349 [08:05<03:29,  2.00s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  70% 245/349 [08:07<03:24,  1.97s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  70% 246/349 [08:09<03:10,  1.85s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  71% 247/349 [08:10<03:02,  1.79s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  71% 248/349 [08:12<03:03,  1.82s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  71% 249/349 [08:14<03:05,  1.86s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  72% 250/349 [08:16<03:08,  1.91s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  72% 251/349 [08:18<03:12,  1.97s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  72% 252/349 [08:20<03:14,  2.00s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  72% 253/349 [08:22<03:16,  2.04s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  73% 254/349 [08:25<03:16,  2.07s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  73% 255/349 [08:27<03:16,  2.09s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  73% 256/349 [08:29<03:15,  2.10s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  74% 257/349 [08:31<03:11,  2.09s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  74% 258/349 [08:33<03:09,  2.08s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  74% 259/349 [08:35<03:05,  2.06s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  74% 260/349 [08:37<03:00,  2.03s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  75% 261/349 [08:39<02:55,  2.00s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  75% 262/349 [08:41<02:47,  1.92s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  75% 263/349 [08:42<02:37,  1.83s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  76% 264/349 [08:44<02:38,  1.86s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  76% 265/349 [08:46<02:40,  1.91s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  76% 266/349 [08:48<02:41,  1.94s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  77% 267/349 [08:50<02:44,  2.00s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  77% 268/349 [08:53<02:45,  2.05s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  77% 269/349 [08:55<02:46,  2.08s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  77% 270/349 [08:57<02:44,  2.08s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  78% 271/349 [08:59<02:42,  2.09s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  78% 272/349 [09:01<02:39,  2.07s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  78% 273/349 [09:03<02:35,  2.05s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  79% 274/349 [09:05<02:31,  2.02s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  79% 275/349 [09:07<02:24,  1.95s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  79% 276/349 [09:08<02:14,  1.84s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  79% 277/349 [09:10<02:14,  1.87s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  80% 278/349 [09:12<02:15,  1.91s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  80% 279/349 [09:14<02:16,  1.96s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  80% 280/349 [09:16<02:18,  2.01s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  81% 281/349 [09:18<02:19,  2.05s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  81% 282/349 [09:21<02:18,  2.07s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  81% 283/349 [09:23<02:15,  2.05s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  81% 284/349 [09:25<02:12,  2.05s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  82% 285/349 [09:27<02:09,  2.03s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  82% 286/349 [09:28<01:59,  1.90s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  82% 287/349 [09:30<01:53,  1.82s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  83% 288/349 [09:32<01:55,  1.89s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  83% 289/349 [09:34<01:57,  1.96s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  83% 290/349 [09:36<01:59,  2.02s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  83% 291/349 [09:38<01:59,  2.06s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  84% 292/349 [09:40<01:58,  2.08s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  84% 293/349 [09:43<01:55,  2.07s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  84% 294/349 [09:44<01:52,  2.04s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  85% 295/349 [09:46<01:42,  1.89s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  85% 296/349 [09:48<01:35,  1.79s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  85% 297/349 [09:50<01:36,  1.86s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  85% 298/349 [09:52<01:38,  1.93s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  86% 299/349 [09:54<01:40,  2.01s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  86% 300/349 [09:56<01:40,  2.05s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  86% 301/349 [09:58<01:37,  2.04s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  87% 302/349 [10:00<01:34,  2.02s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  87% 303/349 [10:02<01:27,  1.89s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  87% 304/349 [10:04<01:27,  1.94s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  87% 305/349 [10:06<01:28,  2.02s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  88% 306/349 [10:08<01:28,  2.05s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  88% 307/349 [10:10<01:25,  2.04s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  88% 308/349 [10:12<01:20,  1.97s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  89% 309/349 [10:14<01:15,  1.88s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  89% 310/349 [10:16<01:16,  1.96s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  89% 311/349 [10:18<01:16,  2.02s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  89% 312/349 [10:20<01:14,  2.03s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  90% 313/349 [10:22<01:12,  2.00s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  90% 314/349 [10:23<01:06,  1.90s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  90% 315/349 [10:26<01:07,  1.98s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  91% 316/349 [10:28<01:06,  2.02s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  91% 317/349 [10:30<01:03,  1.98s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  91% 318/349 [10:31<00:58,  1.88s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  91% 319/349 [10:33<00:59,  1.98s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  92% 320/349 [10:36<00:58,  2.00s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  92% 321/349 [10:37<00:54,  1.94s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  92% 322/349 [10:39<00:50,  1.87s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  93% 323/349 [10:41<00:50,  1.94s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  93% 324/349 [10:43<00:48,  1.95s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  93% 325/349 [10:45<00:45,  1.89s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  93% 326/349 [10:47<00:44,  1.94s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  94% 327/349 [10:48<00:40,  1.83s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  94% 328/349 [10:50<00:37,  1.78s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  94% 329/349 [10:52<00:36,  1.84s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  95% 330/349 [10:54<00:34,  1.81s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  95% 331/349 [10:56<00:33,  1.88s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  95% 332/349 [10:58<00:31,  1.83s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  95% 333/349 [11:00<00:30,  1.89s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  96% 334/349 [11:01<00:27,  1.84s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  96% 335/349 [11:03<00:26,  1.88s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  96% 336/349 [11:05<00:23,  1.83s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  97% 337/349 [11:07<00:20,  1.74s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  97% 338/349 [11:08<00:18,  1.71s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  97% 339/349 [11:10<00:16,  1.61s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  97% 340/349 [11:11<00:14,  1.62s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  98% 341/349 [11:13<00:12,  1.62s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  98% 342/349 [11:14<00:11,  1.57s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  98% 343/349 [11:16<00:09,  1.61s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  99% 344/349 [11:18<00:08,  1.68s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  99% 345/349 [11:20<00:06,  1.71s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  99% 346/349 [11:21<00:05,  1.71s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  99% 347/349 [11:23<00:03,  1.71s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset: 100% 348/349 [11:25<00:01,  1.68s/it]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset: 100% 349/349 [11:25<00:00,  1.22s/it]\u001b[A\n",
            "                                                                          \u001b[A2022-03-10 17:50:46 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 5.775 | nll_loss 4.38 | ppl 20.82 | wps 5908.1 | wpb 11550.8 | bsz 1316.4 | num_updates 1180 | best_loss 5.775\n",
            "2022-03-10 17:50:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 1180 updates\n",
            "2022-03-10 17:50:46 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/checkpoint20.pt\n",
            "2022-03-10 17:50:48 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/checkpoint20.pt\n",
            "2022-03-10 17:50:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint20.pt (epoch 20 @ 1180 updates, score 5.775) (writing took 10.716965322993929 seconds)\n",
            "2022-03-10 17:50:57 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)\n",
            "2022-03-10 17:50:57 | INFO | train | epoch 020 | loss 5.399 | nll_loss 4.048 | ppl 16.55 | wps 1068.8 | ups 0.03 | wpb 32762.2 | bsz 3745.8 | num_updates 1180 | lr 0.000206571 | gnorm 1.742 | train_wall 1107 | wall 9268\n",
            "2022-03-10 17:50:57 | INFO | fairseq_cli.train | done training in 9266.1 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/checkpoints/checkpoint_best.pt /content/drive/MyDrive/15M/TPU_wit600k"
      ],
      "metadata": {
        "id": "sRY0_M4dMF3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip \"/content/checkpoints\" \"/content/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o856tjyOG52I",
        "outputId": "edfc2aef-4ef4-4faf-942d-a16a96dddd93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/ (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/checkpoints.zip /content/drive/MyDrive/15M/GPU_2"
      ],
      "metadata": {
        "id": "65U8GbrbMjtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r GPU.zip GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp01edyVLGUq",
        "outputId": "d6dc1a32-9926-4b38-8da0-671a677aaa55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: GPU/ (stored 0%)\n",
            "  adding: GPU/data_enth_bin/ (stored 0%)\n",
            "  adding: GPU/data_enth_bin/test.src-trg.trg.idx (deflated 76%)\n",
            "  adding: GPU/data_enth_bin/train.src-trg.src.idx (deflated 80%)\n",
            "  adding: GPU/data_enth_bin/valid.src-trg.src.idx (deflated 76%)\n",
            "  adding: GPU/data_enth_bin/train.src-trg.src.bin (deflated 47%)\n",
            "  adding: GPU/data_enth_bin/train.src-trg.trg.idx (deflated 80%)\n",
            "  adding: GPU/data_enth_bin/test.src-trg.src.idx (deflated 76%)\n",
            "  adding: GPU/data_enth_bin/preprocess.log (deflated 59%)\n",
            "  adding: GPU/data_enth_bin/valid.src-trg.trg.idx (deflated 76%)\n",
            "  adding: GPU/data_enth_bin/valid.src-trg.trg.bin (deflated 51%)\n",
            "  adding: GPU/data_enth_bin/dict.src.txt (deflated 58%)\n",
            "  adding: GPU/data_enth_bin/dict.trg.txt (deflated 77%)\n",
            "  adding: GPU/data_enth_bin/test.src-trg.trg.bin (deflated 52%)\n",
            "  adding: GPU/data_enth_bin/train.src-trg.trg.bin (deflated 54%)\n",
            "  adding: GPU/data_enth_bin/test.src-trg.src.bin (deflated 44%)\n",
            "  adding: GPU/data_enth_bin/valid.src-trg.src.bin (deflated 44%)\n",
            "  adding: GPU/log.txt (deflated 80%)\n",
            "  adding: GPU/translated.txt (deflated 84%)\n",
            "  adding: GPU/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: GPU/train_th_220k (deflated 84%)\n",
            "  adding: GPU/train_en_220k (deflated 68%)\n",
            "  adding: GPU/bpe/ (stored 0%)\n",
            "  adding: GPU/bpe/train.bpe.trg (deflated 83%)\n",
            "  adding: GPU/bpe/test.bpe.src (deflated 67%)\n",
            "  adding: GPU/bpe/test.bpe.trg (deflated 84%)\n",
            "  adding: GPU/bpe/trg.bpe (deflated 77%)\n",
            "  adding: GPU/bpe/val.bpe.trg (deflated 84%)\n",
            "  adding: GPU/bpe/train.bpe.src (deflated 68%)\n",
            "  adding: GPU/bpe/val.bpe.src (deflated 65%)\n",
            "  adding: GPU/bpe/src.bpe (deflated 61%)\n",
            "  adding: GPU/val_en_220k (deflated 66%)\n",
            "  adding: GPU/test_th_220k (deflated 84%)\n",
            "  adding: GPU/.zip (stored 0%)\n",
            "  adding: GPU/REF.txt (deflated 83%)\n",
            "  adding: GPU/test_en_220k (deflated 67%)\n",
            "  adding: GPU/val_th_220k (deflated 84%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/GPU.zip /content/drive/MyDrive/15M/GPU_Taskmaster"
      ],
      "metadata": {
        "id": "Z9gzg1KpLUHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python /content/fairseq/fairseq_cli/train.py ./data_enth_bin --arch transformer_wmt_en_de \\\n",
        "# --optimizer adam --adam-betas '(0.9,0.98)' --clip-norm 0.0 \\\n",
        "# --lr-scheduler inverse_sqrt --warmup-init-lr 1e-07 --warmup-updates 4000 \\\n",
        "# --lr 0.0007 --min-lr 1e-09 --max-epoch 1\\\n",
        "# --weight-decay 0.0 --criterion label_smoothed_cross_entropy \\\n",
        "# --label-smoothing 0.1 --max-tokens 4096 --update-freq 2 \\\n",
        "# --log-interval 10 --save-interval-updates 1000 \\\n",
        "# --keep-interval-updates 5 --distributed-world-size 1"
      ],
      "metadata": {
        "id": "L2kyXqys3FBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !fairseq-generate ./data_enth_bin \\\n",
        "# --path checkpoints/checkpoint_best.pt \\\n",
        "# --batch-size 128 --beam 5 --remove-bpe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPW-Lrij520V",
        "outputId": "a696d3b0-a447-4337-848b-9181316cb971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-09 02:18:10 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2022-03-09 02:18:11 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'checkpoints/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 32, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 32, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': './data_enth_bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2022-03-09 02:18:11 | INFO | fairseq.tasks.translation | [src] dictionary: 14000 types\n",
            "2022-03-09 02:18:11 | INFO | fairseq.tasks.translation | [trg] dictionary: 14312 types\n",
            "2022-03-09 02:18:11 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/checkpoint_best.pt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-generate\", line 8, in <module>\n",
            "    sys.exit(cli_main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/generate.py\", line 413, in cli_main\n",
            "    main(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/generate.py\", line 50, in main\n",
            "    return _main(cfg, sys.stdout)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/generate.py\", line 106, in _main\n",
            "    task.load_dataset(cfg.dataset.gen_subset, task_cfg=saved_cfg.task)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq/tasks/translation.py\", line 356, in load_dataset\n",
            "    pad_to_multiple=self.cfg.required_seq_len_multiple,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq/tasks/translation.py\", line 86, in load_langpair_dataset\n",
            "    prefix + src, src_dict, dataset_impl\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq/data/data_utils.py\", line 110, in load_indexed_dataset\n",
            "    dictionary=dictionary,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq/data/indexed_dataset.py\", line 86, in make_dataset\n",
            "    return MMapIndexedDataset(path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq/data/indexed_dataset.py\", line 494, in __init__\n",
            "    self._do_init(path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq/data/indexed_dataset.py\", line 508, in _do_init\n",
            "    data_file_path(self._path), mode=\"r\", order=\"C\"\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/memmap.py\", line 267, in __new__\n",
            "    mm = mmap.mmap(fid.fileno(), bytes, access=acc, offset=start)\n",
            "ValueError: cannot mmap an empty file\n",
            "Exception ignored in: <function MMapIndexedDataset.__del__ at 0x7f38054370e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq/data/indexed_dataset.py\", line 513, in __del__\n",
            "    self._bin_buffer_mmap._mmap.close()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\", line 83, in __getattr__\n",
            "    raise AttributeError\n",
            "AttributeError: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-generate ./data_enth_bin \\\n",
        "--path checkpoints/checkpoint_best.pt \\\n",
        "--batch-size 128 --beam 5 --remove-bpe \\\n",
        "| grep -P \"[D|T]-[0-9]+\" > log.txt\n",
        "# | grep -P \"D-[0-9]+\" > log.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydxSpRd8EqlA",
        "outputId": "ceed255f-f16b-4d7e-d398-df1e6ff63ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-10 14:13:12 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2022-03-10 14:13:14 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'checkpoints/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 128, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 128, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': './data_enth_bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2022-03-10 14:13:14 | INFO | fairseq.tasks.translation | [src] dictionary: 33456 types\n",
            "2022-03-10 14:13:14 | INFO | fairseq.tasks.translation | [trg] dictionary: 17208 types\n",
            "2022-03-10 14:13:14 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/checkpoint_best.pt\n",
            "2022-03-10 14:13:16 | INFO | fairseq.data.data_utils | loaded 1,000 examples from: ./data_enth_bin/test.src-trg.src\n",
            "2022-03-10 14:13:16 | INFO | fairseq.data.data_utils | loaded 1,000 examples from: ./data_enth_bin/test.src-trg.trg\n",
            "2022-03-10 14:13:16 | INFO | fairseq.tasks.translation | ./data_enth_bin test src-trg 1000 examples\n",
            "2022-03-10 14:13:35 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2022-03-10 14:13:35 | INFO | fairseq_cli.generate | Translated 1,000 sentences (8,300 tokens) in 16.8s (59.67 sentences/s, 495.25 tokens/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REF = []\n",
        "translated = []\n",
        "for line in open(\"log.txt\",'r',encoding='utf8').readlines():\n",
        "  splited_line = line.split('\\t')\n",
        "  if 'T' in splited_line[0]:\n",
        "    REF.append(splited_line[1].strip())\n",
        "  else:\n",
        "    translated.append(splited_line[2].strip())\n",
        "  # print(splited_line)\n",
        "  # break\n",
        "open('REF.txt','w',encoding='utf8').write('\\n'.join(REF))\n",
        "open('translated.txt','w',encoding='utf8').write('\\n'.join(translated))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc3INjoTBPMQ",
        "outputId": "65b7393c-4e10-4ab9-c7a9-ecd685e5aabf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32811"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat translated.txt | sacrebleu REF.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqAvPp4slP-r",
        "outputId": "54755885-22ce-4246-da88-ac030d9c47e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            " \"name\": \"BLEU\",\n",
            " \"score\": 13.0,\n",
            " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.0.0\",\n",
            " \"verbose_score\": \"41.2/19.2/9.1/4.8 (BP = 0.953 ratio = 0.954 hyp_len = 7300 ref_len = 7651)\",\n",
            " \"nrefs\": \"1\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"no\",\n",
            " \"tok\": \"13a\",\n",
            " \"smooth\": \"exp\",\n",
            " \"version\": \"2.0.0\"\n",
            "}\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r GPU.zip TPU_witt600k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS8KixYdMSln",
        "outputId": "c1fa5c0c-146d-4723-8fa9-48b021bc9a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: TPU_witt600k/ (stored 0%)\n",
            "  adding: TPU_witt600k/train_en_220k (deflated 61%)\n",
            "  adding: TPU_witt600k/data_enth_bin/ (stored 0%)\n",
            "  adding: TPU_witt600k/data_enth_bin/train.src-trg.src.idx (deflated 81%)\n",
            "  adding: TPU_witt600k/data_enth_bin/test.src-trg.trg.idx (deflated 77%)\n",
            "  adding: TPU_witt600k/data_enth_bin/train.src-trg.trg.idx (deflated 81%)\n",
            "  adding: TPU_witt600k/data_enth_bin/dict.src.txt (deflated 62%)\n",
            "  adding: TPU_witt600k/data_enth_bin/test.src-trg.src.idx (deflated 78%)\n",
            "  adding: TPU_witt600k/data_enth_bin/valid.src-trg.src.idx (deflated 81%)\n",
            "  adding: TPU_witt600k/data_enth_bin/train.src-trg.trg.bin (deflated 35%)\n",
            "  adding: TPU_witt600k/data_enth_bin/preprocess.log (deflated 59%)\n",
            "  adding: TPU_witt600k/data_enth_bin/dict.trg.txt (deflated 73%)\n",
            "  adding: TPU_witt600k/data_enth_bin/valid.src-trg.trg.idx (deflated 80%)\n",
            "  adding: TPU_witt600k/data_enth_bin/test.src-trg.src.bin (deflated 36%)\n",
            "  adding: TPU_witt600k/data_enth_bin/train.src-trg.src.bin (deflated 39%)\n",
            "  adding: TPU_witt600k/data_enth_bin/valid.src-trg.trg.bin (deflated 35%)\n",
            "  adding: TPU_witt600k/data_enth_bin/valid.src-trg.src.bin (deflated 38%)\n",
            "  adding: TPU_witt600k/data_enth_bin/test.src-trg.trg.bin (deflated 31%)\n",
            "  adding: TPU_witt600k/val_en_220k (deflated 61%)\n",
            "  adding: TPU_witt600k/train_th_220k (deflated 77%)\n",
            "  adding: TPU_witt600k/test_en_220k (deflated 57%)\n",
            "  adding: TPU_witt600k/log.txt (deflated 74%)\n",
            "  adding: TPU_witt600k/val_th_220k (deflated 77%)\n",
            "  adding: TPU_witt600k/REF.txt (deflated 76%)\n",
            "  adding: TPU_witt600k/translated.txt (deflated 82%)\n",
            "  adding: TPU_witt600k/test_th_220k (deflated 76%)\n",
            "  adding: TPU_witt600k/bpe/ (stored 0%)\n",
            "  adding: TPU_witt600k/bpe/trg.bpe (deflated 74%)\n",
            "  adding: TPU_witt600k/bpe/val.bpe.src (deflated 61%)\n",
            "  adding: TPU_witt600k/bpe/train.bpe.trg (deflated 77%)\n",
            "  adding: TPU_witt600k/bpe/src.bpe (deflated 65%)\n",
            "  adding: TPU_witt600k/bpe/train.bpe.src (deflated 61%)\n",
            "  adding: TPU_witt600k/bpe/val.bpe.trg (deflated 77%)\n",
            "  adding: TPU_witt600k/bpe/test.bpe.src (deflated 57%)\n",
            "  adding: TPU_witt600k/bpe/test.bpe.trg (deflated 76%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/GPU.zip /content/drive/MyDrive/15M/TPU_wit600k"
      ],
      "metadata": {
        "id": "2uQm0M1dNANl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction**"
      ],
      "metadata": {
        "id": "74vHvdQoQch2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "MXto_fM0Q-8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(\"/content/en_test.csv\")\n",
        "test_df[:1520]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "H47FDN-HQsMO",
        "outputId": "cfb76646-7424-4f89-96d6-e652be57e3b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-62dd74a1-8565-418c-8d48-55944769e0a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What! on fire!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>what is your hobby?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>This is a tragic love story.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Is this road safe?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Please turn in your assignments on time.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>1515</td>\n",
              "      <td>He criticised the outgoing head of the U.N.'s ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>1516</td>\n",
              "      <td>\"In the past, the United States government sto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>1517</td>\n",
              "      <td>ExxonMobil wishes to assure members of the pub...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>1518</td>\n",
              "      <td>The inquest was opened at the request of famil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1519</th>\n",
              "      <td>1519</td>\n",
              "      <td>Despite beginning out-patient treatment next w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1520 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62dd74a1-8565-418c-8d48-55944769e0a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-62dd74a1-8565-418c-8d48-55944769e0a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-62dd74a1-8565-418c-8d48-55944769e0a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Unnamed: 0                                                  0\n",
              "0              0                                     What! on fire!\n",
              "1              1                                what is your hobby?\n",
              "2              2                       This is a tragic love story.\n",
              "3              3                                 Is this road safe?\n",
              "4              4           Please turn in your assignments on time.\n",
              "...          ...                                                ...\n",
              "1515        1515  He criticised the outgoing head of the U.N.'s ...\n",
              "1516        1516  \"In the past, the United States government sto...\n",
              "1517        1517  ExxonMobil wishes to assure members of the pub...\n",
              "1518        1518  The inquest was opened at the request of famil...\n",
              "1519        1519  Despite beginning out-patient treatment next w...\n",
              "\n",
              "[1520 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_label = test_df['th']\n",
        "#test_label = list(test_label)\n",
        "test_df = test_df['0'][:1520]\n",
        "test_df = list(test_df)\n",
        "test_df[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPLpgMlXQriN",
        "outputId": "6ec2545d-ab7b-45fc-b756-451b48b1e66d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What! on fire!',\n",
              " 'what is your hobby?',\n",
              " 'This is a tragic love story.',\n",
              " 'Is this road safe?',\n",
              " 'Please turn in your assignments on time.']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fairseq.models.transformer import TransformerModel\n",
        "model = TransformerModel.from_pretrained(\n",
        "    \"/content/drive/MyDrive/15M/TPU_wit600k\", # model name or path\n",
        "    checkpoint_file=\"checkpoint_best.pt\", # checkpoint file\n",
        "    data_name_or_path='/content/data_enth_bin', # path of folder enth\n",
        "    bpe='subword_nmt', # bpe engine \n",
        "    bpe_codes='/content/bpe/src.bpe' # bpe codes (file from subword_nmt learn bpe)\n",
        " )\n",
        "# use function translate to translate the sentence\n",
        "model.translate(\"I love you\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "2J0ekif7Lhe9",
        "outputId": "fcf5a9b9-a290-4b0b-f93d-1e81777cfa33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-10 14:14:48 | INFO | fairseq.file_utils | loading archive file /content/drive/MyDrive/15M/TPU_wit600k\n",
            "2022-03-10 14:14:48 | INFO | fairseq.file_utils | loading archive file /content/data_enth_bin\n",
            "2022-03-10 14:14:49 | INFO | fairseq.tasks.translation | [src] dictionary: 33456 types\n",
            "2022-03-10 14:14:49 | INFO | fairseq.tasks.translation | [trg] dictionary: 17208 types\n",
            "2022-03-10 14:14:50 | INFO | fairseq.models.fairseq_model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 0, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 14000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 14000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 20, 'max_update': 150000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [3], 'lr': [0.0007], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 10000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_wmt_en_de', activation_dropout=0.0, activation_fn='relu', adam_betas=(0.9, 0.999), adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_wmt_en_de', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe='subword_nmt', bpe_codes='/content/bpe/src.bpe', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/content/data_enth_bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0007], lr_scheduler='inverse_sqrt', max_epoch=20, max_source_positions=1024, max_target_positions=1024, max_tokens=14000, max_tokens_valid=14000, max_update=150000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=5, save_interval_updates=10000, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[3], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': '/content/data_enth_bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0007]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'subword_nmt', 'bpe_codes': '/content/bpe/src.bpe', 'bpe_separator': '@@'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'รัก คุณ'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "result = []\n",
        "for text in tqdm(test_df):\n",
        "  result.append(model.translate(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "abde3afb14734d09ad55969c1f3d1559",
            "1d23bca4039c4647af24985c33448adb",
            "90c491d0e9d64cdb85178a4621527fa0",
            "23ed090048234a68b25fff2f21f20177",
            "ffb0f5bccaa142f4836ef24a184fb5da",
            "b029e82544fe4d2cb52c694416e9a5e6",
            "2577063f727349e08cbd9c77c8afefb8",
            "cc11ffeee2504f558eb157dda42209f0",
            "409185a17e3b4a688d4bf13f35ff5c00",
            "9b8465db0b5040f89c0e9e5ac481418c",
            "fc2cce5039394848946894d1d6623c79"
          ]
        },
        "id": "I3b5WLQiRMpO",
        "outputId": "a91012d4-f707-49b8-a47b-a2fa7108f032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abde3afb14734d09ad55969c1f3d1559",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1520 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb26Mw89WGIf",
        "outputId": "91f2d7ab-5056-4161-f492-7285b45362a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['! ! ! !',\n",
              " 'สิ่ง ของ คุณ คือ อะไร ?',\n",
              " 'แสดง ความ รัก ของ เขา คือ ความ รัก ของ เขา',\n",
              " 'เอา ถนน นี้ ไป สู่ ถนน หรือ ไม่ ?',\n",
              " 'ทำ ให้ เปิด ใช้ งาน ของ คุณ']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = pd.DataFrame([result])\n",
        "b = a.transpose()\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "QKILtwqrWYFw",
        "outputId": "7b7c2b07-d4c0-4653-cb56-7f9a0b5e3551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-81308f83-e219-408d-be9e-182f2a1688f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>! ! ! !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>สิ่ง ของ คุณ คือ อะไร ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>แสดง ความ รัก ของ เขา คือ ความ รัก ของ เขา</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>เอา ถนน นี้ ไป สู่ ถนน หรือ ไม่ ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ทำ ให้ เปิด ใช้ งาน ของ คุณ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>แสดง ความคิด ของ ตน เอง ไม่ ได้ รับ การ แสดง ค...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>\" \" \" \" \" \" \" \" เป็น คน แสดง ความ สำเร็จ ใน ปี...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>การ กระทำ ของ ตน เอง ได้ รับ การ กระทำ ผิด กฎห...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>แสดง ความ รู้สึก ว่า เขา ไม่ ได้ รับ ความ สนใจ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1519</th>\n",
              "      <td>แสดง ความคิด ของ ตน เอง ไม่ ได้ รับ การ แสดง ค...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1520 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81308f83-e219-408d-be9e-182f2a1688f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81308f83-e219-408d-be9e-182f2a1688f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81308f83-e219-408d-be9e-182f2a1688f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                      0\n",
              "0                                               ! ! ! !\n",
              "1                               สิ่ง ของ คุณ คือ อะไร ?\n",
              "2            แสดง ความ รัก ของ เขา คือ ความ รัก ของ เขา\n",
              "3                     เอา ถนน นี้ ไป สู่ ถนน หรือ ไม่ ?\n",
              "4                           ทำ ให้ เปิด ใช้ งาน ของ คุณ\n",
              "...                                                 ...\n",
              "1515  แสดง ความคิด ของ ตน เอง ไม่ ได้ รับ การ แสดง ค...\n",
              "1516  \" \" \" \" \" \" \" \" เป็น คน แสดง ความ สำเร็จ ใน ปี...\n",
              "1517  การ กระทำ ของ ตน เอง ได้ รับ การ กระทำ ผิด กฎห...\n",
              "1518  แสดง ความ รู้สึก ว่า เขา ไม่ ได้ รับ ความ สนใจ...\n",
              "1519  แสดง ความคิด ของ ตน เอง ไม่ ได้ รับ การ แสดง ค...\n",
              "\n",
              "[1520 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.to_csv('hopeless.csv')"
      ],
      "metadata": {
        "id": "ybX1wEzVWSEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test_df)):\n",
        "  print('S-EN: ',test_df[i])\n",
        "  print('True: ',test_label[i])\n",
        "  print('pred: ',result[i])\n",
        "  print('-----------------------------------')"
      ],
      "metadata": {
        "id": "9d1vvuiQULpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "ft83AmSw3T3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d33cc835-58b2-496b-ad38-86321bb4d3b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r fairseq.zip fairseq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HJdrAxfAeSA",
        "outputId": "141dd489-1e1e-4be1-dd2b-42baa5aa2b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps\n",
            "\tzip warning: name not matched: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/utils\n",
            "updating: fairseq/ (stored 0%)\n",
            "updating: fairseq/hubconf.py (deflated 54%)\n",
            "updating: fairseq/.gitignore (deflated 48%)\n",
            "updating: fairseq/fairseq.egg-info/ (stored 0%)\n",
            "updating: fairseq/fairseq.egg-info/dependency_links.txt (stored 0%)\n",
            "updating: fairseq/fairseq.egg-info/requires.txt (deflated 26%)\n",
            "updating: fairseq/fairseq.egg-info/SOURCES.txt (deflated 85%)\n",
            "updating: fairseq/fairseq.egg-info/entry_points.txt (deflated 66%)\n",
            "updating: fairseq/fairseq.egg-info/top_level.txt (deflated 10%)\n",
            "updating: fairseq/fairseq.egg-info/PKG-INFO (deflated 69%)\n",
            "updating: fairseq/fairseq.egg-info/not-zip-safe (stored 0%)\n",
            "updating: fairseq/CONTRIBUTING.md (deflated 59%)\n",
            "updating: fairseq/.isort.cfg (deflated 39%)\n",
            "updating: fairseq/docs/ (stored 0%)\n",
            "updating: fairseq/docs/getting_started.rst (deflated 58%)\n",
            "updating: fairseq/docs/data.rst (deflated 69%)\n",
            "updating: fairseq/docs/_static/ (stored 0%)\n",
            "updating: fairseq/docs/_static/theme_overrides.css (deflated 47%)\n",
            "updating: fairseq/docs/make.bat (deflated 45%)\n",
            "updating: fairseq/docs/hydra_integration.md (deflated 62%)\n",
            "updating: fairseq/docs/command_line_tools.rst (deflated 74%)\n",
            "updating: fairseq/docs/Makefile (deflated 44%)\n",
            "updating: fairseq/docs/overview.rst (deflated 54%)\n",
            "updating: fairseq/docs/lr_scheduler.rst (deflated 70%)\n",
            "updating: fairseq/docs/index.rst (deflated 48%)\n",
            "updating: fairseq/docs/modules.rst (deflated 34%)\n",
            "updating: fairseq/docs/tutorial_classifying_names.rst (deflated 67%)\n",
            "updating: fairseq/docs/criterions.rst (deflated 67%)\n",
            "updating: fairseq/docs/optim.rst (deflated 73%)\n",
            "updating: fairseq/docs/tasks.rst (deflated 57%)\n",
            "updating: fairseq/docs/fairseq.gif (deflated 14%)\n",
            "updating: fairseq/docs/fairseq_logo.png (deflated 23%)\n",
            "updating: fairseq/docs/conf.py (deflated 56%)\n",
            "updating: fairseq/docs/models.rst (deflated 73%)\n",
            "updating: fairseq/docs/tutorial_simple_lstm.rst (deflated 73%)\n",
            "updating: fairseq/docs/docutils.conf (stored 0%)\n",
            "updating: fairseq/docs/requirements.txt (deflated 7%)\n",
            "updating: fairseq/examples/ (stored 0%)\n",
            "updating: fairseq/examples/speech_synthesis/ (stored 0%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/ (stored 0%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/get_feature_manifest.py (deflated 73%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/get_common_voice_audio_manifest.py (deflated 65%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/vad/ (stored 0%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/vad/__init__.py (deflated 66%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/denoise_and_vad_audio.py (deflated 67%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/speaker_embedder/ (stored 0%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/speaker_embedder/__init__.py (deflated 65%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/__init__.py (deflated 25%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/get_vctk_audio_manifest.py (deflated 61%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/denoiser/ (stored 0%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/denoiser/utils.py (deflated 63%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/denoiser/demucs.py (deflated 71%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/denoiser/pretrained.py (deflated 64%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/denoiser/__init__.py (deflated 25%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/denoiser/resample.py (deflated 63%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/get_ljspeech_audio_manifest.py (deflated 59%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/get_speaker_embedding.py (deflated 61%)\n",
            "updating: fairseq/examples/speech_synthesis/generate_waveform.py (deflated 69%)\n",
            "updating: fairseq/examples/speech_synthesis/utils.py (deflated 66%)\n",
            "updating: fairseq/examples/speech_synthesis/docs/ (stored 0%)\n",
            "updating: fairseq/examples/speech_synthesis/docs/common_voice_example.md (deflated 55%)\n",
            "updating: fairseq/examples/speech_synthesis/docs/vctk_example.md (deflated 54%)\n",
            "updating: fairseq/examples/speech_synthesis/docs/ljspeech_example.md (deflated 61%)\n",
            "updating: fairseq/examples/speech_synthesis/data_utils.py (deflated 71%)\n",
            "updating: fairseq/examples/speech_synthesis/evaluation/ (stored 0%)\n",
            "updating: fairseq/examples/speech_synthesis/evaluation/eval_f0.py (deflated 67%)\n",
            "updating: fairseq/examples/speech_synthesis/evaluation/eval_asr.py (deflated 65%)\n",
            "updating: fairseq/examples/speech_synthesis/evaluation/get_eval_manifest.py (deflated 60%)\n",
            "updating: fairseq/examples/speech_synthesis/evaluation/__init__.py (deflated 25%)\n",
            "updating: fairseq/examples/speech_synthesis/evaluation/eval_sp.py (deflated 66%)\n",
            "updating: fairseq/examples/speech_synthesis/README.md (deflated 45%)\n",
            "updating: fairseq/examples/speech_synthesis/__init__.py (deflated 25%)\n",
            "updating: fairseq/examples/.gitignore (deflated 6%)\n",
            "updating: fairseq/examples/flores101/ (stored 0%)\n",
            "updating: fairseq/examples/flores101/flores_logo.png (deflated 10%)\n",
            "updating: fairseq/examples/flores101/README.md (deflated 54%)\n",
            "updating: fairseq/examples/wmt20/ (stored 0%)\n",
            "updating: fairseq/examples/wmt20/README.md (deflated 70%)\n",
            "updating: fairseq/examples/normformer/ (stored 0%)\n",
            "updating: fairseq/examples/normformer/train_lm.sh (deflated 67%)\n",
            "updating: fairseq/examples/normformer/README.md (deflated 60%)\n",
            "updating: fairseq/examples/roberta/ (stored 0%)\n",
            "updating: fairseq/examples/roberta/README.race.md (deflated 52%)\n",
            "updating: fairseq/examples/roberta/wsc/ (stored 0%)\n",
            "updating: fairseq/examples/roberta/wsc/wsc_criterion.py (deflated 72%)\n",
            "updating: fairseq/examples/roberta/wsc/wsc_utils.py (deflated 72%)\n",
            "updating: fairseq/examples/roberta/wsc/wsc_task.py (deflated 76%)\n",
            "updating: fairseq/examples/roberta/wsc/README.md (deflated 61%)\n",
            "updating: fairseq/examples/roberta/wsc/__init__.py (deflated 34%)\n",
            "updating: fairseq/examples/roberta/multiprocessing_bpe_encoder.py (deflated 64%)\n",
            "updating: fairseq/examples/roberta/README.pretraining.md (deflated 55%)\n",
            "updating: fairseq/examples/roberta/commonsense_qa/ (stored 0%)\n",
            "updating: fairseq/examples/roberta/commonsense_qa/download_cqa_data.sh (deflated 49%)\n",
            "updating: fairseq/examples/roberta/commonsense_qa/commonsense_qa_task.py (deflated 67%)\n",
            "updating: fairseq/examples/roberta/commonsense_qa/README.md (deflated 53%)\n",
            "updating: fairseq/examples/roberta/commonsense_qa/__init__.py (deflated 27%)\n",
            "updating: fairseq/examples/roberta/config/ (stored 0%)\n",
            "updating: fairseq/examples/roberta/config/pretraining/ (stored 0%)\n",
            "updating: fairseq/examples/roberta/config/pretraining/base.yaml (deflated 42%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/ (stored 0%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/rte.yaml (deflated 50%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/mrpc.yaml (deflated 50%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/mnli.yaml (deflated 50%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/qnli.yaml (deflated 50%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/sts_b.yaml (deflated 49%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/cola.yaml (deflated 50%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/qqp.yaml (deflated 50%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/sst_2.yaml (deflated 50%)\n",
            "updating: fairseq/examples/roberta/README.custom_classification.md (deflated 58%)\n",
            "updating: fairseq/examples/roberta/preprocess_RACE.sh (deflated 64%)\n",
            "updating: fairseq/examples/roberta/README.glue.md (deflated 49%)\n",
            "updating: fairseq/examples/roberta/preprocess_GLUE_tasks.sh (deflated 71%)\n",
            "updating: fairseq/examples/roberta/README.md (deflated 64%)\n",
            "updating: fairseq/examples/roberta/preprocess_RACE.py (deflated 66%)\n",
            "updating: fairseq/examples/translation_moe/ (stored 0%)\n",
            "updating: fairseq/examples/translation_moe/translation_moe_src/ (stored 0%)\n",
            "updating: fairseq/examples/translation_moe/translation_moe_src/mean_pool_gating_network.py (deflated 61%)\n",
            "updating: fairseq/examples/translation_moe/translation_moe_src/logsumexp_moe.py (deflated 44%)\n",
            "updating: fairseq/examples/translation_moe/translation_moe_src/__init__.py (deflated 27%)\n",
            "updating: fairseq/examples/translation_moe/translation_moe_src/translation_moe.py (deflated 72%)\n",
            "updating: fairseq/examples/translation_moe/score.py (deflated 67%)\n",
            "updating: fairseq/examples/translation_moe/README.md (deflated 58%)\n",
            "updating: fairseq/examples/joint_alignment_translation/ (stored 0%)\n",
            "updating: fairseq/examples/joint_alignment_translation/README.md (deflated 52%)\n",
            "updating: fairseq/examples/joint_alignment_translation/prepare-wmt18en2de_no_norm_no_escape_no_agressive.sh (deflated 59%)\n",
            "updating: fairseq/examples/shuffled_word_order/ (stored 0%)\n",
            "updating: fairseq/examples/shuffled_word_order/README.finetuning.md (deflated 62%)\n",
            "updating: fairseq/examples/shuffled_word_order/README.md (deflated 74%)\n",
            "updating: fairseq/examples/adaptive_span/ (stored 0%)\n",
            "updating: fairseq/examples/adaptive_span/adaptive_span_model.py (deflated 73%)\n",
            "updating: fairseq/examples/adaptive_span/adaptive_span_model_wrapper.py (deflated 67%)\n",
            "updating: fairseq/examples/adaptive_span/adagrad_with_grad_clip.py (deflated 67%)\n",
            "updating: fairseq/examples/adaptive_span/truncated_bptt_lm_task.py (deflated 67%)\n",
            "updating: fairseq/examples/adaptive_span/README.md (deflated 60%)\n",
            "updating: fairseq/examples/adaptive_span/adaptive_span_attention.py (deflated 69%)\n",
            "updating: fairseq/examples/adaptive_span/__init__.py (deflated 49%)\n",
            "updating: fairseq/examples/adaptive_span/adaptive_span_loss.py (deflated 69%)\n",
            "updating: fairseq/examples/translation/ (stored 0%)\n",
            "updating: fairseq/examples/translation/prepare-iwslt17-multilingual.sh (deflated 68%)\n",
            "updating: fairseq/examples/translation/prepare-wmt14en2de.sh (deflated 62%)\n",
            "updating: fairseq/examples/translation/prepare-iwslt14.sh (deflated 61%)\n",
            "updating: fairseq/examples/translation/README.md (deflated 73%)\n",
            "updating: fairseq/examples/translation/prepare-wmt14en2fr.sh (deflated 63%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/ (stored 0%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/models/ (stored 0%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/models/s2t_dualinputtransformer.py (deflated 82%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/models/__init__.py (deflated 29%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/models/s2t_dualinputxmtransformer.py (deflated 82%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/docs/ (stored 0%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/docs/iwslt2021.md (deflated 60%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/docs/ende-mustc.md (deflated 69%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/configs/ (stored 0%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/configs/mustc_noise.list (deflated 65%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/scripts/ (stored 0%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/scripts/g2p_encode.py (deflated 67%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/README.md (deflated 56%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/__init__.py (deflated 28%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/criterions/ (stored 0%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/criterions/text_guide_cross_entropy_acc.py (deflated 75%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/criterions/__init__.py (deflated 42%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/tasks/ (stored 0%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/tasks/speech_text_joint.py (deflated 75%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/tasks/__init__.py (deflated 29%)\n",
            "updating: fairseq/examples/scaling_nmt/ (stored 0%)\n",
            "updating: fairseq/examples/scaling_nmt/README.md (deflated 56%)\n",
            "updating: fairseq/examples/MMPT/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/.gitignore (deflated 46%)\n",
            "updating: fairseq/examples/MMPT/videoclip.png (deflated 5%)\n",
            "updating: fairseq/examples/MMPT/endtask.md (deflated 55%)\n",
            "updating: fairseq/examples/MMPT/CONFIG.md (deflated 59%)\n",
            "updating: fairseq/examples/MMPT/projects/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/mmfusionmtm.yaml (deflated 54%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/youcookcap.yaml (deflated 50%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/test_coin.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/coin.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/vtt.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/youcook.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/test_crosstask.yaml (deflated 61%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/test_youcookcap.yaml (deflated 47%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/how2.yaml (deflated 52%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/test_vttqa.yaml (deflated 45%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/vttqa.yaml (deflated 49%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/crosstask.yaml (deflated 58%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/test_crosstask_zs.yaml (deflated 60%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/test_youcook.yaml (deflated 49%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/test_vtt.yaml (deflated 45%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm.yaml (deflated 25%)\n",
            "updating: fairseq/examples/MMPT/projects/mfmmlm.yaml (deflated 65%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip.yaml (deflated 43%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_crosstask_videoclip.yaml (deflated 62%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_vttqa_zs.yaml (deflated 47%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_youcook_videoclip.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/coin_videoclip.yaml (deflated 52%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_coin_zs.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/how2.yaml (deflated 55%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_vtt_zs.yaml (deflated 47%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_vtt_videoclip.yaml (deflated 48%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_crosstask_zs_videoclip.yaml (deflated 61%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_coin_videoclip.yaml (deflated 53%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_youcook_zs.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_vttqa_videoclip.yaml (deflated 48%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_didemo_zs.yaml (deflated 50%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/crosstask_videoclip.yaml (deflated 59%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/youcook_videoclip.yaml (deflated 52%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/vtt_videoclip.yaml (deflated 52%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/vttqa_videoclip.yaml (deflated 50%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoretri.yaml (deflated 64%)\n",
            "updating: fairseq/examples/MMPT/projects/task/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/projects/task/youcookcap.yaml (deflated 48%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_crosstask_videoclip.yaml (deflated 33%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_coin.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/task/coin.yaml (deflated 49%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_vttqa_zs.yaml (deflated 39%)\n",
            "updating: fairseq/examples/MMPT/projects/task/vtt.yaml (deflated 50%)\n",
            "updating: fairseq/examples/MMPT/projects/task/ft.yaml (deflated 40%)\n",
            "updating: fairseq/examples/MMPT/projects/task/youcook.yaml (deflated 50%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_youcook_videoclip.yaml (deflated 32%)\n",
            "updating: fairseq/examples/MMPT/projects/task/coin_videoclip.yaml (deflated 32%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_coin_zs.yaml (deflated 37%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_crosstask.yaml (deflated 61%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_youcookcap.yaml (deflated 48%)\n",
            "updating: fairseq/examples/MMPT/projects/task/how2.yaml (deflated 50%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_vtt_zs.yaml (deflated 39%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_vtt_videoclip.yaml (deflated 32%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_vttqa.yaml (deflated 45%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_crosstask_zs_videoclip.yaml (deflated 33%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_coin_videoclip.yaml (deflated 33%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_youcook_zs.yaml (deflated 39%)\n",
            "updating: fairseq/examples/MMPT/projects/task/default.yaml (deflated 38%)\n",
            "updating: fairseq/examples/MMPT/projects/task/vttqa.yaml (deflated 44%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_vttqa_videoclip.yaml (deflated 32%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_didemo_zs.yaml (deflated 49%)\n",
            "updating: fairseq/examples/MMPT/projects/task/crosstask.yaml (deflated 61%)\n",
            "updating: fairseq/examples/MMPT/projects/task/crosstask_videoclip.yaml (deflated 35%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_crosstask_zs.yaml (deflated 60%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_youcook.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_vtt.yaml (deflated 45%)\n",
            "updating: fairseq/examples/MMPT/projects/task/youcook_videoclip.yaml (deflated 44%)\n",
            "updating: fairseq/examples/MMPT/projects/task/vtt_videoclip.yaml (deflated 43%)\n",
            "updating: fairseq/examples/MMPT/projects/task/vttqa_videoclip.yaml (deflated 44%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test.yaml (deflated 32%)\n",
            "updating: fairseq/examples/MMPT/locallaunch.py (deflated 69%)\n",
            "updating: fairseq/examples/MMPT/vlm.png (deflated 6%)\n",
            "updating: fairseq/examples/MMPT/mmpt_cli/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt_cli/predict.py (deflated 68%)\n",
            "updating: fairseq/examples/MMPT/mmpt_cli/localjob.py (deflated 71%)\n",
            "updating: fairseq/examples/MMPT/scripts/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/scripts/text_token_extractor/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/scripts/text_token_extractor/pretokenization.py (deflated 63%)\n",
            "updating: fairseq/examples/MMPT/scripts/text_token_extractor/configs/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/scripts/text_token_extractor/configs/bert-base-uncased.yaml (deflated 28%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/pathbuilder.py (deflated 69%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/videoreader.py (deflated 76%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/model.py (deflated 59%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/random_sequence_shuffler.py (deflated 61%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/extract.py (deflated 72%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/how2/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/how2/s3d.sh (deflated 29%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/shard_feature.py (deflated 64%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/preprocessing.py (deflated 70%)\n",
            "updating: fairseq/examples/MMPT/setup.py (deflated 41%)\n",
            "updating: fairseq/examples/MMPT/README.md (deflated 60%)\n",
            "updating: fairseq/examples/MMPT/mmpt/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/losses/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/losses/fairseqmmloss.py (deflated 59%)\n",
            "updating: fairseq/examples/MMPT/mmpt/losses/__init__.py (deflated 43%)\n",
            "updating: fairseq/examples/MMPT/mmpt/losses/loss.py (deflated 79%)\n",
            "updating: fairseq/examples/MMPT/mmpt/losses/nce.py (deflated 77%)\n",
            "updating: fairseq/examples/MMPT/mmpt/models/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/models/mmfusionnlg.py (deflated 78%)\n",
            "updating: fairseq/examples/MMPT/mmpt/models/mmfusion.py (deflated 84%)\n",
            "updating: fairseq/examples/MMPT/mmpt/models/fairseqmmmodel.py (deflated 59%)\n",
            "updating: fairseq/examples/MMPT/mmpt/models/transformermodel.py (deflated 83%)\n",
            "updating: fairseq/examples/MMPT/mmpt/models/__init__.py (deflated 46%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/dedupprocessor.py (deflated 73%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/models/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/models/s3dg.py (deflated 75%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/how2processor.py (deflated 79%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/how2retriprocessor.py (deflated 76%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/dsprocessor.py (deflated 77%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/processor.py (deflated 75%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/__init__.py (deflated 62%)\n",
            "updating: fairseq/examples/MMPT/mmpt/modules/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/modules/vectorpool.py (deflated 77%)\n",
            "updating: fairseq/examples/MMPT/mmpt/modules/retri.py (deflated 84%)\n",
            "updating: fairseq/examples/MMPT/mmpt/modules/mm.py (deflated 69%)\n",
            "updating: fairseq/examples/MMPT/mmpt/modules/__init__.py (deflated 31%)\n",
            "updating: fairseq/examples/MMPT/mmpt/evaluators/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/evaluators/metric.py (deflated 72%)\n",
            "updating: fairseq/examples/MMPT/mmpt/evaluators/evaluator.py (deflated 66%)\n",
            "updating: fairseq/examples/MMPT/mmpt/evaluators/predictor.py (deflated 79%)\n",
            "updating: fairseq/examples/MMPT/mmpt/evaluators/__init__.py (deflated 36%)\n",
            "updating: fairseq/examples/MMPT/mmpt/utils/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/utils/load_config.py (deflated 67%)\n",
            "updating: fairseq/examples/MMPT/mmpt/utils/__init__.py (deflated 60%)\n",
            "updating: fairseq/examples/MMPT/mmpt/utils/shardedtensor.py (deflated 62%)\n",
            "updating: fairseq/examples/MMPT/mmpt/__init__.py (deflated 43%)\n",
            "updating: fairseq/examples/MMPT/mmpt/datasets/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/datasets/fairseqmmdataset.py (deflated 61%)\n",
            "updating: fairseq/examples/MMPT/mmpt/datasets/__init__.py (deflated 33%)\n",
            "updating: fairseq/examples/MMPT/mmpt/datasets/mmdataset.py (deflated 69%)\n",
            "updating: fairseq/examples/MMPT/mmpt/tasks/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/tasks/task.py (deflated 74%)\n",
            "updating: fairseq/examples/MMPT/mmpt/tasks/vlmtask.py (deflated 49%)\n",
            "updating: fairseq/examples/MMPT/mmpt/tasks/fairseqmmtask.py (deflated 64%)\n",
            "updating: fairseq/examples/MMPT/mmpt/tasks/__init__.py (deflated 53%)\n",
            "updating: fairseq/examples/MMPT/mmpt/tasks/retritask.py (deflated 72%)\n",
            "updating: fairseq/examples/MMPT/mmpt/tasks/milncetask.py (deflated 57%)\n",
            "updating: fairseq/examples/MMPT/DATASET.md (deflated 53%)\n",
            "updating: fairseq/examples/MMPT/pretraining.md (deflated 49%)\n",
            "updating: fairseq/examples/unsupervised_quality_estimation/ (stored 0%)\n",
            "updating: fairseq/examples/unsupervised_quality_estimation/repeat_lines.py (deflated 51%)\n",
            "updating: fairseq/examples/unsupervised_quality_estimation/meteor.py (deflated 66%)\n",
            "updating: fairseq/examples/unsupervised_quality_estimation/README.md (deflated 64%)\n",
            "updating: fairseq/examples/unsupervised_quality_estimation/aggregate_scores.py (deflated 55%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/ (stored 0%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/models/ (stored 0%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/models/discriminative_reranking_model.py (deflated 76%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/models/__init__.py (deflated 30%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/drnmt_rerank.py (deflated 70%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/config/ (stored 0%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/config/deen.yaml (deflated 48%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/scripts/ (stored 0%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/scripts/prep_data.py (deflated 71%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/README.md (deflated 67%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/criterions/ (stored 0%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/criterions/__init__.py (deflated 32%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/criterions/discriminative_reranking_criterion.py (deflated 65%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/tasks/ (stored 0%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/tasks/discriminative_reranking_task.py (deflated 76%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/tasks/__init__.py (deflated 35%)\n",
            "updating: fairseq/examples/pay_less_attention_paper/ (stored 0%)\n",
            "updating: fairseq/examples/pay_less_attention_paper/README.md (deflated 74%)\n",
            "updating: fairseq/examples/megatron_11b/ (stored 0%)\n",
            "updating: fairseq/examples/megatron_11b/detok.py (deflated 49%)\n",
            "updating: fairseq/examples/megatron_11b/README.md (deflated 59%)\n",
            "updating: fairseq/examples/constrained_decoding/ (stored 0%)\n",
            "updating: fairseq/examples/constrained_decoding/tok.py (deflated 46%)\n",
            "updating: fairseq/examples/constrained_decoding/README.md (deflated 60%)\n",
            "updating: fairseq/examples/constrained_decoding/normalize.py (deflated 44%)\n",
            "updating: fairseq/examples/operators/ (stored 0%)\n",
            "updating: fairseq/examples/operators/utils.h (deflated 42%)\n",
            "updating: fairseq/examples/operators/alignment_train_kernel.cu (deflated 74%)\n",
            "updating: fairseq/examples/operators/alignment_train_cpu.cpp (deflated 71%)\n",
            "updating: fairseq/examples/operators/alignment_train_cuda.cpp (deflated 43%)\n",
            "updating: fairseq/examples/operators/alignment_train_cuda.h (deflated 33%)\n",
            "updating: fairseq/examples/quant_noise/ (stored 0%)\n",
            "updating: fairseq/examples/quant_noise/transformer_quantization_config.yaml (deflated 50%)\n",
            "updating: fairseq/examples/quant_noise/README.md (deflated 68%)\n",
            "updating: fairseq/examples/hubert/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/dump_km_label.py (deflated 60%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/dump_hubert_feature_s2t.py (deflated 59%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/dump_w2v2_feature.py (deflated 60%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/feature_utils.py (deflated 54%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/README.md (deflated 59%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/dump_hubert_feature.py (deflated 60%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/learn_kmeans.py (deflated 66%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/dump_mfcc_feature.py (deflated 59%)\n",
            "updating: fairseq/examples/hubert/update_ckpt.py (deflated 45%)\n",
            "updating: fairseq/examples/hubert/config/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/decode/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/decode/ax_sweep/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/decode/ax_sweep/transformer.yaml (deflated 57%)\n",
            "updating: fairseq/examples/hubert/config/decode/ax_sweep/ngram.yaml (deflated 57%)\n",
            "updating: fairseq/examples/hubert/config/decode/infer_viterbi.yaml (deflated 45%)\n",
            "updating: fairseq/examples/hubert/config/decode/infer_fsqlm.yaml (deflated 57%)\n",
            "updating: fairseq/examples/hubert/config/decode/infer_kenlm.yaml (deflated 57%)\n",
            "updating: fairseq/examples/hubert/config/decode/run/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/decode/run/submitit_slurm_8gpu.yaml (deflated 53%)\n",
            "updating: fairseq/examples/hubert/config/decode/run/submitit_slurm.yaml (deflated 53%)\n",
            "updating: fairseq/examples/hubert/config/finetune/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/finetune/base_10h.yaml (deflated 55%)\n",
            "updating: fairseq/examples/hubert/config/finetune/lm/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/finetune/lm/ls_4gram.yaml (deflated 43%)\n",
            "updating: fairseq/examples/hubert/config/finetune/run/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/finetune/run/submitit_reg.yaml (deflated 46%)\n",
            "updating: fairseq/examples/hubert/config/finetune/ckpt/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/finetune/ckpt/it1.yaml (deflated 22%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/hubert_base_librispeech.yaml (deflated 54%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/data/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/data/iter2.yaml (deflated 14%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/data/iter1.yaml (deflated 14%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/hubert_large_librivox.yaml (deflated 56%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/run/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/run/submitit_reg.yaml (deflated 46%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/hubert_xlarge_librivox.yaml (deflated 56%)\n",
            "updating: fairseq/examples/hubert/measure_teacher_quality.py (deflated 69%)\n",
            "updating: fairseq/examples/hubert/tests/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/tests/sample.large.L20.len (stored 0%)\n",
            "updating: fairseq/examples/hubert/tests/sample.base.L9.len (stored 0%)\n",
            "updating: fairseq/examples/hubert/tests/test_finetuned_asr.sh (deflated 53%)\n",
            "updating: fairseq/examples/hubert/tests/6313-76958-0021.flac (deflated 4%)\n",
            "updating: fairseq/examples/hubert/tests/sample.xlarge.L30.npy (deflated 7%)\n",
            "updating: fairseq/examples/hubert/tests/sample.base.L9.km500.km (deflated 66%)\n",
            "updating: fairseq/examples/hubert/tests/sample.large.hypo.word (deflated 31%)\n",
            "updating: fairseq/examples/hubert/tests/sample.xlarge.hypo.word (deflated 31%)\n",
            "updating: fairseq/examples/hubert/tests/test_feature_and_unit.sh (deflated 69%)\n",
            "updating: fairseq/examples/hubert/tests/sample.base.L9.npy (deflated 7%)\n",
            "updating: fairseq/examples/hubert/tests/sample.large.L20.npy (deflated 7%)\n",
            "updating: fairseq/examples/hubert/tests/sample.xlarge.L30.len (stored 0%)\n",
            "updating: fairseq/examples/hubert/README.md (deflated 68%)\n",
            "updating: fairseq/examples/m2m_100/ (stored 0%)\n",
            "updating: fairseq/examples/m2m_100/process_data/ (stored 0%)\n",
            "updating: fairseq/examples/m2m_100/process_data/dedup_data.py (deflated 70%)\n",
            "updating: fairseq/examples/m2m_100/process_data/remove_too_much_punc.py (deflated 62%)\n",
            "updating: fairseq/examples/m2m_100/process_data/clean_histogram.py (deflated 70%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/ (stored 0%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/thirdparty/ (stored 0%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/thirdparty/.gitignore (deflated 43%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/seg_ja.sh (deflated 30%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/tokenizer_ar.sh (deflated 41%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/tokenize_indic.py (deflated 47%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/README.md (deflated 44%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/tokenize_zh.py (deflated 33%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/seg_ko.sh (deflated 31%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/tokenize_thai.py (deflated 32%)\n",
            "updating: fairseq/examples/m2m_100/tok.sh (deflated 65%)\n",
            "updating: fairseq/examples/m2m_100/install_dependecies.sh (deflated 60%)\n",
            "updating: fairseq/examples/m2m_100/README.md (deflated 67%)\n",
            "updating: fairseq/examples/rxf/ (stored 0%)\n",
            "updating: fairseq/examples/rxf/rxf_src/ (stored 0%)\n",
            "updating: fairseq/examples/rxf/rxf_src/sentence_prediction_r3f.py (deflated 72%)\n",
            "updating: fairseq/examples/rxf/rxf_src/__init__.py (deflated 28%)\n",
            "updating: fairseq/examples/rxf/rxf_src/label_smoothed_cross_entropy_r3f.py (deflated 70%)\n",
            "updating: fairseq/examples/rxf/README.md (deflated 51%)\n",
            "updating: fairseq/examples/rxf/__init__.py (deflated 27%)\n",
            "updating: fairseq/examples/criss/ (stored 0%)\n",
            "updating: fairseq/examples/criss/download_and_preprocess_flores_test.sh (deflated 55%)\n",
            "updating: fairseq/examples/criss/mining/ (stored 0%)\n",
            "updating: fairseq/examples/criss/mining/mine_example.sh (deflated 72%)\n",
            "updating: fairseq/examples/criss/mining/mine.py (deflated 70%)\n",
            "updating: fairseq/examples/criss/unsupervised_mt/ (stored 0%)\n",
            "updating: fairseq/examples/criss/unsupervised_mt/eval.sh (deflated 66%)\n",
            "updating: fairseq/examples/criss/save_encoder.py (deflated 68%)\n",
            "updating: fairseq/examples/criss/sentence_retrieval/ (stored 0%)\n",
            "updating: fairseq/examples/criss/sentence_retrieval/encoder_analysis.py (deflated 65%)\n",
            "updating: fairseq/examples/criss/sentence_retrieval/sentence_retrieval_tatoeba.sh (deflated 65%)\n",
            "updating: fairseq/examples/criss/download_and_preprocess_tatoeba.sh (deflated 53%)\n",
            "updating: fairseq/examples/criss/README.md (deflated 54%)\n",
            "updating: fairseq/examples/speech_recognition/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/models/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/models/vggtransformer.py (deflated 80%)\n",
            "updating: fairseq/examples/speech_recognition/models/__init__.py (deflated 39%)\n",
            "updating: fairseq/examples/speech_recognition/models/w2l_conv_glu_enc.py (deflated 66%)\n",
            "updating: fairseq/examples/speech_recognition/new/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/new/decoders/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/new/decoders/decoder.py (deflated 57%)\n",
            "updating: fairseq/examples/speech_recognition/new/decoders/flashlight_decoder.py (deflated 78%)\n",
            "updating: fairseq/examples/speech_recognition/new/decoders/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/new/decoders/base_decoder.py (deflated 62%)\n",
            "updating: fairseq/examples/speech_recognition/new/decoders/viterbi_decoder.py (deflated 40%)\n",
            "updating: fairseq/examples/speech_recognition/new/decoders/decoder_config.py (deflated 67%)\n",
            "updating: fairseq/examples/speech_recognition/new/README.md (deflated 60%)\n",
            "updating: fairseq/examples/speech_recognition/new/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/new/infer.py (deflated 71%)\n",
            "updating: fairseq/examples/speech_recognition/new/conf/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/new/conf/infer.yaml (deflated 44%)\n",
            "updating: fairseq/examples/speech_recognition/new/conf/hydra/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/new/conf/hydra/sweeper/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/new/conf/hydra/sweeper/ax.yaml (deflated 50%)\n",
            "updating: fairseq/examples/speech_recognition/w2l_decoder.py (deflated 77%)\n",
            "updating: fairseq/examples/speech_recognition/kaldi/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/kaldi/add-self-loop-simple.cc (deflated 60%)\n",
            "updating: fairseq/examples/speech_recognition/kaldi/kaldi_initializer.py (deflated 82%)\n",
            "updating: fairseq/examples/speech_recognition/kaldi/config/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/kaldi/config/kaldi_initializer.yaml (deflated 23%)\n",
            "updating: fairseq/examples/speech_recognition/kaldi/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/kaldi/kaldi_decoder.py (deflated 72%)\n",
            "updating: fairseq/examples/speech_recognition/data/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/data/data_utils.py (deflated 63%)\n",
            "updating: fairseq/examples/speech_recognition/data/replabels.py (deflated 66%)\n",
            "updating: fairseq/examples/speech_recognition/data/asr_dataset.py (deflated 65%)\n",
            "updating: fairseq/examples/speech_recognition/data/collaters.py (deflated 69%)\n",
            "updating: fairseq/examples/speech_recognition/data/__init__.py (deflated 28%)\n",
            "updating: fairseq/examples/speech_recognition/utils/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/utils/wer_utils.py (deflated 74%)\n",
            "updating: fairseq/examples/speech_recognition/README.md (deflated 62%)\n",
            "updating: fairseq/examples/speech_recognition/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/infer.py (deflated 71%)\n",
            "updating: fairseq/examples/speech_recognition/datasets/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/datasets/asr_prep_json.py (deflated 61%)\n",
            "updating: fairseq/examples/speech_recognition/datasets/prepare-librispeech.sh (deflated 66%)\n",
            "updating: fairseq/examples/speech_recognition/criterions/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/criterions/ASG_loss.py (deflated 68%)\n",
            "updating: fairseq/examples/speech_recognition/criterions/__init__.py (deflated 46%)\n",
            "updating: fairseq/examples/speech_recognition/criterions/cross_entropy_acc.py (deflated 67%)\n",
            "updating: fairseq/examples/speech_recognition/tasks/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/tasks/__init__.py (deflated 38%)\n",
            "updating: fairseq/examples/speech_recognition/tasks/speech_recognition.py (deflated 66%)\n",
            "updating: fairseq/examples/stories/ (stored 0%)\n",
            "updating: fairseq/examples/stories/README.md (deflated 59%)\n",
            "updating: fairseq/examples/bart/ (stored 0%)\n",
            "updating: fairseq/examples/bart/README.summarization.md (deflated 57%)\n",
            "updating: fairseq/examples/bart/summarize.py (deflated 63%)\n",
            "updating: fairseq/examples/bart/README.glue.md (deflated 52%)\n",
            "updating: fairseq/examples/bart/README.md (deflated 63%)\n",
            "updating: fairseq/examples/noisychannel/ (stored 0%)\n",
            "updating: fairseq/examples/noisychannel/rerank_tune.py (deflated 71%)\n",
            "updating: fairseq/examples/noisychannel/rerank_generate.py (deflated 83%)\n",
            "updating: fairseq/examples/noisychannel/rerank_score_lm.py (deflated 64%)\n",
            "updating: fairseq/examples/noisychannel/rerank_score_bw.py (deflated 75%)\n",
            "updating: fairseq/examples/noisychannel/README.md (deflated 70%)\n",
            "updating: fairseq/examples/noisychannel/__init__.py (deflated 27%)\n",
            "updating: fairseq/examples/noisychannel/rerank.py (deflated 79%)\n",
            "updating: fairseq/examples/noisychannel/rerank_utils.py (deflated 80%)\n",
            "updating: fairseq/examples/noisychannel/rerank_options.py (deflated 78%)\n",
            "updating: fairseq/examples/layerdrop/ (stored 0%)\n",
            "updating: fairseq/examples/layerdrop/README.md (deflated 64%)\n",
            "updating: fairseq/examples/backtranslation/ (stored 0%)\n",
            "updating: fairseq/examples/backtranslation/tokenized_bleu.sh (deflated 51%)\n",
            "updating: fairseq/examples/backtranslation/deduplicate_lines.py (deflated 53%)\n",
            "updating: fairseq/examples/backtranslation/prepare-de-monolingual.sh (deflated 72%)\n",
            "updating: fairseq/examples/backtranslation/prepare-wmt18en2de.sh (deflated 63%)\n",
            "updating: fairseq/examples/backtranslation/extract_bt_data.py (deflated 63%)\n",
            "updating: fairseq/examples/backtranslation/README.md (deflated 70%)\n",
            "updating: fairseq/examples/backtranslation/sacrebleu.sh (deflated 46%)\n",
            "updating: fairseq/examples/moe_lm/ (stored 0%)\n",
            "updating: fairseq/examples/moe_lm/model_card.md (deflated 59%)\n",
            "updating: fairseq/examples/moe_lm/data_card.md (deflated 66%)\n",
            "updating: fairseq/examples/moe_lm/README.md (deflated 62%)\n",
            "updating: fairseq/examples/pointer_generator/ (stored 0%)\n",
            "updating: fairseq/examples/pointer_generator/README.xsum.md (deflated 63%)\n",
            "updating: fairseq/examples/pointer_generator/preprocess.py (deflated 70%)\n",
            "updating: fairseq/examples/pointer_generator/pointer_generator_src/ (stored 0%)\n",
            "updating: fairseq/examples/pointer_generator/pointer_generator_src/__init__.py (deflated 27%)\n",
            "updating: fairseq/examples/pointer_generator/pointer_generator_src/transformer_pg.py (deflated 73%)\n",
            "updating: fairseq/examples/pointer_generator/README.md (deflated 56%)\n",
            "updating: fairseq/examples/pointer_generator/postprocess.py (deflated 65%)\n",
            "updating: fairseq/examples/language_model/ (stored 0%)\n",
            "updating: fairseq/examples/language_model/prepare-wikitext-103.sh (deflated 54%)\n",
            "updating: fairseq/examples/language_model/README.adaptive_inputs.md (deflated 52%)\n",
            "updating: fairseq/examples/language_model/README.md (deflated 60%)\n",
            "updating: fairseq/examples/language_model/README.conv.md (deflated 47%)\n",
            "updating: fairseq/examples/linformer/ (stored 0%)\n",
            "updating: fairseq/examples/linformer/README.md (deflated 44%)\n",
            "updating: fairseq/examples/linformer/linformer_src/ (stored 0%)\n",
            "updating: fairseq/examples/linformer/linformer_src/models/ (stored 0%)\n",
            "updating: fairseq/examples/linformer/linformer_src/models/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/linformer/linformer_src/models/linformer_roberta.py (deflated 69%)\n",
            "updating: fairseq/examples/linformer/linformer_src/modules/ (stored 0%)\n",
            "updating: fairseq/examples/linformer/linformer_src/modules/multihead_linear_attention.py (deflated 79%)\n",
            "updating: fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder_layer.py (deflated 65%)\n",
            "updating: fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder.py (deflated 60%)\n",
            "updating: fairseq/examples/linformer/linformer_src/modules/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/linformer/linformer_src/__init__.py (deflated 28%)\n",
            "updating: fairseq/examples/simultaneous_translation/ (stored 0%)\n",
            "updating: fairseq/examples/simultaneous_translation/eval/ (stored 0%)\n",
            "updating: fairseq/examples/simultaneous_translation/eval/agents/ (stored 0%)\n",
            "updating: fairseq/examples/simultaneous_translation/eval/agents/simul_t2t_enja.py (deflated 69%)\n",
            "updating: fairseq/examples/simultaneous_translation/models/ (stored 0%)\n",
            "updating: fairseq/examples/simultaneous_translation/models/convtransformer_simul_trans.py (deflated 74%)\n",
            "updating: fairseq/examples/simultaneous_translation/models/__init__.py (deflated 41%)\n",
            "updating: fairseq/examples/simultaneous_translation/models/transformer_monotonic_attention.py (deflated 75%)\n",
            "updating: fairseq/examples/simultaneous_translation/docs/ (stored 0%)\n",
            "updating: fairseq/examples/simultaneous_translation/docs/enja-waitk.md (deflated 55%)\n",
            "updating: fairseq/examples/simultaneous_translation/docs/ende-mma.md (deflated 70%)\n",
            "updating: fairseq/examples/simultaneous_translation/modules/ (stored 0%)\n",
            "updating: fairseq/examples/simultaneous_translation/modules/monotonic_transformer_layer.py (deflated 78%)\n",
            "updating: fairseq/examples/simultaneous_translation/modules/monotonic_multihead_attention.py (deflated 77%)\n",
            "updating: fairseq/examples/simultaneous_translation/modules/__init__.py (deflated 42%)\n",
            "updating: fairseq/examples/simultaneous_translation/modules/fixed_pre_decision.py (deflated 76%)\n",
            "updating: fairseq/examples/simultaneous_translation/tests/ (stored 0%)\n",
            "updating: fairseq/examples/simultaneous_translation/tests/test_alignment_train.py (deflated 68%)\n",
            "updating: fairseq/examples/simultaneous_translation/tests/test_text_models.py (deflated 79%)\n",
            "updating: fairseq/examples/simultaneous_translation/utils/ (stored 0%)\n",
            "updating: fairseq/examples/simultaneous_translation/utils/functions.py (deflated 61%)\n",
            "updating: fairseq/examples/simultaneous_translation/utils/monotonic_attention.py (deflated 70%)\n",
            "updating: fairseq/examples/simultaneous_translation/utils/__init__.py (deflated 41%)\n",
            "updating: fairseq/examples/simultaneous_translation/utils/p_choose_strategy.py (deflated 68%)\n",
            "updating: fairseq/examples/simultaneous_translation/README.md (deflated 48%)\n",
            "updating: fairseq/examples/simultaneous_translation/__init__.py (deflated 27%)\n",
            "updating: fairseq/examples/cross_lingual_language_model/ (stored 0%)\n",
            "updating: fairseq/examples/cross_lingual_language_model/README.md (deflated 53%)\n",
            "updating: fairseq/examples/laser/ (stored 0%)\n",
            "updating: fairseq/examples/laser/README.md (deflated 62%)\n",
            "updating: fairseq/examples/laser/laser_src/ (stored 0%)\n",
            "updating: fairseq/examples/laser/laser_src/laser_lstm.py (deflated 79%)\n",
            "updating: fairseq/examples/laser/laser_src/laser_transformer.py (deflated 73%)\n",
            "updating: fairseq/examples/laser/laser_src/laser_task.py (deflated 74%)\n",
            "updating: fairseq/examples/laser/laser_src/__init__.py (deflated 40%)\n",
            "updating: fairseq/examples/laser/laser_src/multitask_data_utils.py (deflated 69%)\n",
            "updating: fairseq/examples/conv_seq2seq/ (stored 0%)\n",
            "updating: fairseq/examples/conv_seq2seq/README.md (deflated 67%)\n",
            "updating: fairseq/examples/camembert/ (stored 0%)\n",
            "updating: fairseq/examples/camembert/README.md (deflated 66%)\n",
            "updating: fairseq/examples/wmt19/ (stored 0%)\n",
            "updating: fairseq/examples/wmt19/README.md (deflated 71%)\n",
            "updating: fairseq/examples/data2vec/ (stored 0%)\n",
            "updating: fairseq/examples/data2vec/models/ (stored 0%)\n",
            "updating: fairseq/examples/data2vec/models/data2vec_text.py (deflated 75%)\n",
            "updating: fairseq/examples/data2vec/models/data2vec_audio.py (deflated 77%)\n",
            "updating: fairseq/examples/data2vec/config/ (stored 0%)\n",
            "updating: fairseq/examples/data2vec/config/audio/ (stored 0%)\n",
            "updating: fairseq/examples/data2vec/config/audio/pretraining/ (stored 0%)\n",
            "updating: fairseq/examples/data2vec/config/audio/pretraining/base_librispeech.yaml (deflated 51%)\n",
            "updating: fairseq/examples/data2vec/config/text/ (stored 0%)\n",
            "updating: fairseq/examples/data2vec/config/text/pretraining/ (stored 0%)\n",
            "updating: fairseq/examples/data2vec/config/text/pretraining/base.yaml (deflated 52%)\n",
            "updating: fairseq/examples/data2vec/README.md (deflated 64%)\n",
            "updating: fairseq/examples/mbart/ (stored 0%)\n",
            "updating: fairseq/examples/mbart/README.md (deflated 58%)\n",
            "updating: fairseq/examples/fully_sharded_data_parallel/ (stored 0%)\n",
            "updating: fairseq/examples/fully_sharded_data_parallel/README.md (deflated 73%)\n",
            "updating: fairseq/examples/fast_noisy_channel/ (stored 0%)\n",
            "updating: fairseq/examples/fast_noisy_channel/noisy_channel_translation.py (deflated 72%)\n",
            "updating: fairseq/examples/fast_noisy_channel/noisy_channel_sequence_generator.py (deflated 77%)\n",
            "updating: fairseq/examples/fast_noisy_channel/README.md (deflated 77%)\n",
            "updating: fairseq/examples/fast_noisy_channel/__init__.py (deflated 42%)\n",
            "updating: fairseq/examples/fast_noisy_channel/noisy_channel_beam_search.py (deflated 65%)\n",
            "updating: fairseq/examples/textless_nlp/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/tools/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/tools/resynthesize_speech.py (deflated 67%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/tools/README.md (deflated 51%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/abx_metrics/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/abx_metrics/dump_abx_feats.py (deflated 63%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/abx_metrics/README.md (deflated 54%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/README.md (deflated 39%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/cut_as.py (deflated 56%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/dict.ltr.txt (deflated 31%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/bleu_utils.py (deflated 67%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/ppx.py (deflated 61%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/README.md (deflated 61%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/self_auto_bleu.py (deflated 69%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/continuation_eval.py (deflated 60%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/README.md (deflated 69%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/utils.py (deflated 70%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/w2v2_feature_reader.py (deflated 54%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/cpc_feature_reader.py (deflated 73%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/hubert_feature_reader.py (deflated 57%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/logmel_feature_reader.py (deflated 49%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/clustering/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/clustering/utils.py (deflated 44%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/clustering/cluster_kmeans.py (deflated 72%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/clustering/quantize_with_kmeans.py (deflated 66%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/clustering/dump_feats.py (deflated 63%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/clustering/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/glow.py (deflated 72%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/convert_to_16k.py (deflated 60%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/utils.py (deflated 59%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/synthesize_audio_from_units.py (deflated 66%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tts_data.py (deflated 64%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/README.md (deflated 72%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/multiproc.py (deflated 48%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/waveglow_denoiser.py (deflated 63%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/utils.py (deflated 68%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/cmudict.py (deflated 56%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/symbols.py (deflated 36%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/text.py (deflated 60%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/stft.py (deflated 64%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py (deflated 82%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/cleaners.py (deflated 61%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/audio_processing.py (deflated 59%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/layers.py (deflated 68%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/numbers.py (deflated 68%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/ulm/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/ulm/sample.py (deflated 64%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/ulm/README.md (deflated 63%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/README.md (deflated 52%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/generate_waveform.py (deflated 59%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/eval/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/eval/cont_metrics.py (deflated 78%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/eval/__init__.py (deflated 25%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/inference_dataset.py (deflated 68%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/quantize_f0.py (deflated 63%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/prepare_dataset.py (deflated 66%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/preprocess_f0.py (deflated 56%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/data_utils.py (deflated 65%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/truncated_laplace.py (deflated 48%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/scripts/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/scripts/join_units_manifest.py (deflated 60%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/scripts/prepare_f0_quantization.sh (deflated 52%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/scripts/prepare_data.sh (deflated 54%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/sample/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/sample/sample.py (deflated 75%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/sample/__init__.py (deflated 25%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/README.md (deflated 66%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/naive_decoder.py (deflated 55%)\n",
            "updating: fairseq/examples/textless_nlp/speech-resynth/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/speech-resynth/img/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/speech-resynth/img/fig.png (deflated 3%)\n",
            "updating: fairseq/examples/textless_nlp/speech-resynth/README.md (deflated 55%)\n",
            "updating: fairseq/examples/attention_head_selection/ (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/README.md (deflated 76%)\n",
            "updating: fairseq/examples/attention_head_selection/src/ (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/models/ (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/models/head_selection_s2t_transformer.py (deflated 76%)\n",
            "updating: fairseq/examples/attention_head_selection/src/models/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/models/head_selection_transformer.py (deflated 81%)\n",
            "updating: fairseq/examples/attention_head_selection/src/data/ (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/data/speech_to_text_dataset_with_domain.py (deflated 76%)\n",
            "updating: fairseq/examples/attention_head_selection/src/data/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/modules/ (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/modules/attn_head_selector.py (deflated 69%)\n",
            "updating: fairseq/examples/attention_head_selection/src/modules/multihead_functional.py (deflated 75%)\n",
            "updating: fairseq/examples/attention_head_selection/src/modules/head_selection_transformer_layer.py (deflated 80%)\n",
            "updating: fairseq/examples/attention_head_selection/src/modules/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/modules/multihead_attention_selection.py (deflated 79%)\n",
            "updating: fairseq/examples/attention_head_selection/src/speech_to_text_head_selection.py (deflated 76%)\n",
            "updating: fairseq/examples/attention_head_selection/src/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/loss/ (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/loss/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/loss/attention_head_selection.py (deflated 51%)\n",
            "updating: fairseq/examples/wmt21/ (stored 0%)\n",
            "updating: fairseq/examples/wmt21/scripts/ (stored 0%)\n",
            "updating: fairseq/examples/wmt21/scripts/normalize-punctuation.perl (deflated 56%)\n",
            "updating: fairseq/examples/wmt21/scripts/replace-unicode-punctuation.perl (deflated 46%)\n",
            "updating: fairseq/examples/wmt21/eval.sh (deflated 52%)\n",
            "updating: fairseq/examples/wmt21/README.md (deflated 43%)\n",
            "updating: fairseq/examples/__init__.py (deflated 30%)\n",
            "updating: fairseq/examples/nonautoregressive_translation/ (stored 0%)\n",
            "updating: fairseq/examples/nonautoregressive_translation/README.md (deflated 61%)\n",
            "updating: fairseq/examples/nonautoregressive_translation/scripts.md (deflated 82%)\n",
            "updating: fairseq/examples/wav2vec/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/xlsr/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/xlsr/config/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/xlsr/config/finetune.yaml (deflated 50%)\n",
            "updating: fairseq/examples/wav2vec/xlsr/README.md (deflated 58%)\n",
            "updating: fairseq/examples/wav2vec/wav2vec_manifest.py (deflated 61%)\n",
            "updating: fairseq/examples/wav2vec/config/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/config/pretraining/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox.yaml (deflated 51%)\n",
            "updating: fairseq/examples/wav2vec/config/pretraining/wav2vec2_base_librispeech.yaml (deflated 48%)\n",
            "updating: fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox_tpu-pod.yaml (deflated 51%)\n",
            "updating: fairseq/examples/wav2vec/config/pretraining/wav2vec2_conformer_base_librispeech.yaml (deflated 48%)\n",
            "updating: fairseq/examples/wav2vec/config/pretraining/wav2vec2_conformer_large_librivox.yaml (deflated 51%)\n",
            "updating: fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox_tpu.yaml (deflated 51%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/vox_10h.yaml (deflated 49%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/base_10h.yaml (deflated 49%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/base_960h.yaml (deflated 46%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/base_100h.yaml (deflated 46%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/vox_10m.yaml (deflated 49%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/vox_1h.yaml (deflated 49%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/vox_960h.yaml (deflated 46%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/vox_100h.yaml (deflated 46%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/base_1h.yaml (deflated 49%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/base_10m.yaml (deflated 49%)\n",
            "updating: fairseq/examples/wav2vec/scripts/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/scripts/binarize_manifest.sh (deflated 60%)\n",
            "updating: fairseq/examples/wav2vec/libri_labels.py (deflated 60%)\n",
            "updating: fairseq/examples/wav2vec/README.md (deflated 76%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/models/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/models/wav2vec_u.py (deflated 76%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/models/__init__.py (deflated 27%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/generate/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/generate/viterbi.yaml (deflated 33%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/gan/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/gan/w2vu.yaml (deflated 62%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/train.uid (deflated 72%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/valid.uid (deflated 64%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/test.uid (deflated 75%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/train_text.uid (deflated 67%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/finetuning/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/finetuning/w2v_finetune.yaml (deflated 47%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_matched/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_matched/train.uid (deflated 73%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_matched/valid.uid (deflated 75%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_matched/test.uid (deflated 75%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_matched/train_text.uid (deflated 73%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/data/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/data/random_input_dataset.py (deflated 66%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/data/extracted_features_dataset.py (deflated 66%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/data/__init__.py (deflated 42%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/w2vu_generate.py (deflated 74%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/ltr_to_wrd.py (deflated 32%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/filter_tsv.py (deflated 48%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/phonemize_with_sil.py (deflated 61%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/normalize_and_filter_text.py (deflated 56%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/wer.py (deflated 57%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/prepare_text.sh (deflated 71%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/copy_labels.py (deflated 26%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/mean_pool.py (deflated 63%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/g2p_wrd_to_phn.py (deflated 53%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/remove_silence.py (deflated 56%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_cluster_faiss.py (deflated 64%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/prepare_timit.sh (deflated 61%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_apply_cluster_faiss.py (deflated 64%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/prepare_audio.sh (deflated 67%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/apply_pca.py (deflated 60%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/merge_clusters.py (deflated 64%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/filter_lexicon.py (deflated 48%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/vads.py (deflated 55%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_extract_features.py (deflated 62%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/pca.py (deflated 53%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/normalize_text.py (deflated 38%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/wrd_to_ltr.py (deflated 30%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_lda_mllt.sh (deflated 63%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_deltas.sh (deflated 60%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_sat.sh (deflated 66%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/path.sh (deflated 42%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/cmd.sh (deflated 48%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_word_step2.sh (deflated 47%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select.py (deflated 66%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/score.sh (deflated 54%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lang.sh (deflated 60%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/copy_aligned_text.py (deflated 8%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lm.sh (deflated 51%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/decode.sh (deflated 48%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select_decode_word.sh (deflated 43%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lang_word.sh (deflated 56%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/show_wer.sh (deflated 62%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/train_subset_lgbeam.sh (deflated 74%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select_decode.sh (deflated 43%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_data_from_w2v.py (deflated 63%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/train.sh (deflated 57%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_word_step1.sh (deflated 57%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_phone.sh (deflated 47%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/README.md (deflated 57%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/README.md (deflated 58%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/tasks/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/tasks/__init__.py (deflated 30%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/tasks/unpaired_audio_text.py (deflated 76%)\n",
            "updating: fairseq/examples/wav2vec/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/wav2vec_featurize.py (deflated 68%)\n",
            "updating: fairseq/examples/wav2vec/vq-wav2vec_featurize.py (deflated 69%)\n",
            "updating: fairseq/examples/xglm/ (stored 0%)\n",
            "updating: fairseq/examples/xglm/model_card.md (deflated 58%)\n",
            "updating: fairseq/examples/xglm/README.md (deflated 63%)\n",
            "updating: fairseq/examples/multilingual/ (stored 0%)\n",
            "updating: fairseq/examples/multilingual/train_multilingual_model.sh (deflated 48%)\n",
            "updating: fairseq/examples/multilingual/finetune_multilingual_model.sh (deflated 49%)\n",
            "updating: fairseq/examples/multilingual/multilingual_fairseq_gen.sh (deflated 45%)\n",
            "updating: fairseq/examples/multilingual/README.md (deflated 69%)\n",
            "updating: fairseq/examples/multilingual/ML50_langs.txt (deflated 30%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/ (stored 0%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_ted_and_extract.py (deflated 72%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_flores_data.sh (deflated 73%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_ML50_v1.sh (deflated 47%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/requirement.txt (stored 0%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/check_valid_test_overlaps.py (deflated 68%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/binarize.py (deflated 70%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_wmt19_and_before.py (deflated 78%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_iitb.sh (deflated 55%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_iwslt_and_extract.sh (deflated 71%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/preprocess_ML50_v1.sh (deflated 47%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/check_self_overlaps.py (deflated 67%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/check_iswlt_test_data.py (deflated 60%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/dedup_all.py (deflated 60%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_wmt20.sh (deflated 79%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_af_xh.sh (deflated 69%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/utils/ (stored 0%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/utils/strip_sgm.sh (deflated 24%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/utils/fasttext_multi_filter.py (deflated 60%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/utils/dedup.py (deflated 63%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/README.md (deflated 49%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_lotus.sh (deflated 69%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_wat19_my.sh (deflated 54%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/remove_valid_test_in_train.py (deflated 76%)\n",
            "updating: fairseq/examples/speech_to_text/ (stored 0%)\n",
            "updating: fairseq/examples/speech_to_text/seg_mustc_data.py (deflated 56%)\n",
            "updating: fairseq/examples/speech_to_text/docs/ (stored 0%)\n",
            "updating: fairseq/examples/speech_to_text/docs/simulst_mustc_example.md (deflated 62%)\n",
            "updating: fairseq/examples/speech_to_text/docs/covost_example.md (deflated 81%)\n",
            "updating: fairseq/examples/speech_to_text/docs/mustc_example.md (deflated 78%)\n",
            "updating: fairseq/examples/speech_to_text/docs/mtedx_example.md (deflated 72%)\n",
            "updating: fairseq/examples/speech_to_text/docs/librispeech_example.md (deflated 55%)\n",
            "updating: fairseq/examples/speech_to_text/data_utils.py (deflated 70%)\n",
            "updating: fairseq/examples/speech_to_text/simultaneous_translation/ (stored 0%)\n",
            "updating: fairseq/examples/speech_to_text/simultaneous_translation/agents/ (stored 0%)\n",
            "updating: fairseq/examples/speech_to_text/simultaneous_translation/agents/fairseq_simul_st_agent.py (deflated 71%)\n",
            "updating: fairseq/examples/speech_to_text/prep_mustc_data.py (deflated 71%)\n",
            "updating: fairseq/examples/speech_to_text/README.md (deflated 56%)\n",
            "updating: fairseq/examples/speech_to_text/prep_covost_data.py (deflated 66%)\n",
            "updating: fairseq/examples/speech_to_text/prep_librispeech_data.py (deflated 62%)\n",
            "updating: fairseq/examples/speech_to_text/prep_mtedx_data.py (deflated 70%)\n",
            "updating: fairseq/examples/speech_to_speech/ (stored 0%)\n",
            "updating: fairseq/examples/speech_to_speech/preprocessing/ (stored 0%)\n",
            "updating: fairseq/examples/speech_to_speech/preprocessing/prep_s2ut_data.py (deflated 63%)\n",
            "updating: fairseq/examples/speech_to_speech/preprocessing/prep_s2spect_data.py (deflated 67%)\n",
            "updating: fairseq/examples/speech_to_speech/preprocessing/data_utils.py (deflated 69%)\n",
            "updating: fairseq/examples/speech_to_speech/preprocessing/__init__.py (deflated 25%)\n",
            "updating: fairseq/examples/speech_to_speech/generate_waveform_from_code.py (deflated 60%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/ (stored 0%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/configs/ (stored 0%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/configs/2StageS2ST.yaml (deflated 51%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/configs/3StageS2ST.yaml (deflated 61%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/configs/S2T.yaml (deflated 33%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/configs/DirectS2U.yaml (deflated 47%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/data_utils.py (deflated 70%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/core.py (deflated 77%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/README.md (deflated 52%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/get_metrics.py (deflated 67%)\n",
            "updating: fairseq/examples/speech_to_speech/README.md (deflated 67%)\n",
            "updating: fairseq/examples/speech_to_speech/__init__.py (deflated 25%)\n",
            "updating: fairseq/examples/byte_level_bpe/ (stored 0%)\n",
            "updating: fairseq/examples/byte_level_bpe/get_data.sh (deflated 66%)\n",
            "updating: fairseq/examples/byte_level_bpe/README.md (deflated 62%)\n",
            "updating: fairseq/examples/byte_level_bpe/gru_transformer.py (deflated 78%)\n",
            "updating: fairseq/examples/byte_level_bpe/get_bitext.py (deflated 78%)\n",
            "updating: fairseq/examples/gottbert/ (stored 0%)\n",
            "updating: fairseq/examples/gottbert/README.md (deflated 51%)\n",
            "updating: fairseq/examples/latent_depth/ (stored 0%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/ (stored 0%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/models/ (stored 0%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/models/latent_multilingual_transformer.py (deflated 72%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/models/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/models/latent_transformer.py (deflated 77%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/multilingual_translation_latent_depth.py (deflated 78%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/modules/ (stored 0%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/modules/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/modules/latent_layers.py (deflated 61%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/__init__.py (deflated 46%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/loss/ (stored 0%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/loss/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/loss/latent_depth.py (deflated 72%)\n",
            "updating: fairseq/examples/latent_depth/README.md (deflated 56%)\n",
            "updating: fairseq/examples/paraphraser/ (stored 0%)\n",
            "updating: fairseq/examples/paraphraser/README.md (deflated 75%)\n",
            "updating: fairseq/examples/paraphraser/paraphrase.py (deflated 63%)\n",
            "updating: fairseq/examples/xlmr/ (stored 0%)\n",
            "updating: fairseq/examples/xlmr/README.md (deflated 57%)\n",
            "updating: fairseq/examples/truncated_bptt/ (stored 0%)\n",
            "updating: fairseq/examples/truncated_bptt/truncated_bptt_lm_task.py (deflated 67%)\n",
            "updating: fairseq/examples/truncated_bptt/README.md (deflated 53%)\n",
            "updating: fairseq/examples/truncated_bptt/__init__.py (deflated 27%)\n",
            "updating: fairseq/examples/truncated_bptt/transformer_xl_model.py (deflated 67%)\n",
            "updating: fairseq/.gitmodules (deflated 31%)\n",
            "updating: fairseq/.github/ (stored 0%)\n",
            "updating: fairseq/.github/ISSUE_TEMPLATE/ (stored 0%)\n",
            "updating: fairseq/.github/ISSUE_TEMPLATE/documentation.md (deflated 30%)\n",
            "updating: fairseq/.github/ISSUE_TEMPLATE/how-to-question.md (deflated 44%)\n",
            "updating: fairseq/.github/ISSUE_TEMPLATE/feature_request.md (deflated 49%)\n",
            "updating: fairseq/.github/ISSUE_TEMPLATE/bug_report.md (deflated 46%)\n",
            "updating: fairseq/.github/workflows/ (stored 0%)\n",
            "updating: fairseq/.github/workflows/build_wheels.yml (deflated 54%)\n",
            "updating: fairseq/.github/workflows/build.yml (deflated 58%)\n",
            "updating: fairseq/.github/stale.yml (deflated 63%)\n",
            "updating: fairseq/.github/PULL_REQUEST_TEMPLATE.md (deflated 36%)\n",
            "updating: fairseq/.github/ISSUE_TEMPLATE.md (deflated 29%)\n",
            "updating: fairseq/build/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/examples/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/examples/operators/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/examples/operators/alignment_train_cpu.o (deflated 78%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/data/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.o (deflated 81%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/data/data_utils_fast.o (deflated 81%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/clib/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/clib/libbase/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/clib/libbase/balanced_assignment.o (deflated 78%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/libbleu.o (deflated 75%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/module.o (deflated 66%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/clib/libnat/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/clib/libnat/edit_dist.o (deflated 79%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/ (stored 0%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/alignment_train_cpu_binding.cpython-37m-x86_64-linux-gnu.so (deflated 73%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/fairseq/ (stored 0%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/fairseq/libbase.cpython-37m-x86_64-linux-gnu.so (deflated 73%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/fairseq/libbleu.cpython-37m-x86_64-linux-gnu.so (deflated 62%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/fairseq/data/ (stored 0%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.cpython-37m-x86_64-linux-gnu.so (deflated 69%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/fairseq/data/data_utils_fast.cpython-37m-x86_64-linux-gnu.so (deflated 69%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/fairseq/libnat.cpython-37m-x86_64-linux-gnu.so (deflated 73%)\n",
            "updating: fairseq/.git/ (stored 0%)\n",
            "updating: fairseq/.git/HEAD (stored 0%)\n",
            "updating: fairseq/.git/config (deflated 34%)\n",
            "updating: fairseq/.git/description (deflated 14%)\n",
            "updating: fairseq/.git/index (deflated 61%)\n",
            "updating: fairseq/.git/packed-refs (deflated 51%)\n",
            "updating: fairseq/.git/info/ (stored 0%)\n",
            "updating: fairseq/.git/info/exclude (deflated 28%)\n",
            "updating: fairseq/.git/logs/ (stored 0%)\n",
            "updating: fairseq/.git/logs/HEAD (deflated 29%)\n",
            "updating: fairseq/.git/logs/refs/ (stored 0%)\n",
            "updating: fairseq/.git/logs/refs/heads/ (stored 0%)\n",
            "updating: fairseq/.git/logs/refs/heads/main (deflated 29%)\n",
            "updating: fairseq/.git/logs/refs/remotes/ (stored 0%)\n",
            "updating: fairseq/.git/logs/refs/remotes/origin/ (stored 0%)\n",
            "updating: fairseq/.git/logs/refs/remotes/origin/HEAD (deflated 29%)\n",
            "updating: fairseq/.git/branches/ (stored 0%)\n",
            "updating: fairseq/.git/refs/ (stored 0%)\n",
            "updating: fairseq/.git/refs/tags/ (stored 0%)\n",
            "updating: fairseq/.git/refs/heads/ (stored 0%)\n",
            "updating: fairseq/.git/refs/heads/main (stored 0%)\n",
            "updating: fairseq/.git/refs/remotes/ (stored 0%)\n",
            "updating: fairseq/.git/refs/remotes/origin/ (stored 0%)\n",
            "updating: fairseq/.git/refs/remotes/origin/HEAD (stored 0%)\n",
            "updating: fairseq/.git/hooks/ (stored 0%)\n",
            "updating: fairseq/.git/hooks/fsmonitor-watchman.sample (deflated 53%)\n",
            "updating: fairseq/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "updating: fairseq/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "updating: fairseq/.git/hooks/post-update.sample (deflated 27%)\n",
            "updating: fairseq/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "updating: fairseq/.git/hooks/pre-commit.sample (deflated 43%)\n",
            "updating: fairseq/.git/hooks/update.sample (deflated 68%)\n",
            "updating: fairseq/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "updating: fairseq/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "updating: fairseq/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "updating: fairseq/.git/hooks/pre-push.sample (deflated 50%)\n",
            "updating: fairseq/.git/objects/ (stored 0%)\n",
            "updating: fairseq/.git/objects/pack/ (stored 0%)\n",
            "updating: fairseq/.git/objects/pack/pack-9d973bac802ceacf2550f45f3c8ca5df45db7466.idx (deflated 2%)\n",
            "updating: fairseq/.git/objects/pack/pack-9d973bac802ceacf2550f45f3c8ca5df45db7466.pack (deflated 2%)\n",
            "updating: fairseq/.git/objects/info/ (stored 0%)\n",
            "updating: fairseq/CODE_OF_CONDUCT.md (deflated 55%)\n",
            "updating: fairseq/.circleci/ (stored 0%)\n",
            "updating: fairseq/.circleci/config.yml (deflated 72%)\n",
            "updating: fairseq/scripts/ (stored 0%)\n",
            "updating: fairseq/scripts/test_fsdp.sh (deflated 64%)\n",
            "updating: fairseq/scripts/spm_decode.py (deflated 56%)\n",
            "updating: fairseq/scripts/convert_model.lua (deflated 71%)\n",
            "updating: fairseq/scripts/constraints/ (stored 0%)\n",
            "updating: fairseq/scripts/constraints/extract.py (deflated 67%)\n",
            "updating: fairseq/scripts/constraints/validate.py (deflated 49%)\n",
            "updating: fairseq/scripts/count_docs.py (deflated 61%)\n",
            "updating: fairseq/scripts/shard_docs.py (deflated 59%)\n",
            "updating: fairseq/scripts/average_checkpoints.py (deflated 68%)\n",
            "updating: fairseq/scripts/build_sym_alignment.py (deflated 67%)\n",
            "updating: fairseq/scripts/compound_split_bleu.sh (deflated 39%)\n",
            "updating: fairseq/scripts/compare_namespaces.py (deflated 60%)\n",
            "updating: fairseq/scripts/spm_train.py (deflated 34%)\n",
            "updating: fairseq/scripts/read_binarized.py (deflated 54%)\n",
            "updating: fairseq/scripts/__init__.py (stored 0%)\n",
            "updating: fairseq/scripts/convert_dictionary.lua (deflated 45%)\n",
            "updating: fairseq/scripts/sacrebleu.sh (deflated 38%)\n",
            "updating: fairseq/scripts/spm_encode.py (deflated 66%)\n",
            "updating: fairseq/scripts/split_train_valid_docs.py (deflated 66%)\n",
            "updating: fairseq/scripts/rm_pt.py (deflated 71%)\n",
            "updating: fairseq/setup.cfg (deflated 7%)\n",
            "updating: fairseq/LICENSE (deflated 41%)\n",
            "updating: fairseq/setup.py (deflated 70%)\n",
            "updating: fairseq/pyproject.toml (deflated 18%)\n",
            "updating: fairseq/tests/ (stored 0%)\n",
            "updating: fairseq/tests/test_multi_corpus_dataset.py (deflated 68%)\n",
            "updating: fairseq/tests/test_espnet_multihead_attention.py (deflated 82%)\n",
            "updating: fairseq/tests/test_metrics.py (deflated 79%)\n",
            "updating: fairseq/tests/test_reproducibility.py (deflated 77%)\n",
            "updating: fairseq/tests/test_file_chunker_utils.py (deflated 65%)\n",
            "updating: fairseq/tests/test_binarizer.py (deflated 73%)\n",
            "updating: fairseq/tests/test_positional_encoding.py (deflated 71%)\n",
            "updating: fairseq/tests/test_iterators.py (deflated 82%)\n",
            "updating: fairseq/tests/test_concat_dataset.py (deflated 72%)\n",
            "updating: fairseq/tests/test_constraints.py (deflated 82%)\n",
            "updating: fairseq/tests/test_sequence_scorer.py (deflated 72%)\n",
            "updating: fairseq/tests/utils.py (deflated 79%)\n",
            "updating: fairseq/tests/test_utils.py (deflated 75%)\n",
            "updating: fairseq/tests/test_noising.py (deflated 82%)\n",
            "updating: fairseq/tests/test_transformer.py (deflated 62%)\n",
            "updating: fairseq/tests/test_valid_subset_checks.py (deflated 73%)\n",
            "updating: fairseq/tests/test_online_backtranslation.py (deflated 70%)\n",
            "updating: fairseq/tests/test_token_block_dataset.py (deflated 76%)\n",
            "updating: fairseq/tests/test_multi_corpus_sampled_dataset.py (deflated 70%)\n",
            "updating: fairseq/tests/test_checkpoint_utils.py (deflated 71%)\n",
            "updating: fairseq/tests/speech_recognition/ (stored 0%)\n",
            "updating: fairseq/tests/speech_recognition/test_cross_entropy.py (deflated 68%)\n",
            "updating: fairseq/tests/speech_recognition/test_collaters.py (deflated 62%)\n",
            "updating: fairseq/tests/speech_recognition/asr_test_base.py (deflated 79%)\n",
            "updating: fairseq/tests/speech_recognition/__init__.py (stored 0%)\n",
            "updating: fairseq/tests/speech_recognition/test_vggtransformer.py (deflated 81%)\n",
            "updating: fairseq/tests/speech_recognition/test_data_utils.py (deflated 69%)\n",
            "updating: fairseq/tests/test_multihead_attention.py (deflated 71%)\n",
            "updating: fairseq/tests/test_activation_checkpointing.py (deflated 69%)\n",
            "updating: fairseq/tests/distributed/ (stored 0%)\n",
            "updating: fairseq/tests/distributed/test_module_proxy_wrapper.py (deflated 70%)\n",
            "updating: fairseq/tests/distributed/test_distributed_timeout_wrapper.py (deflated 63%)\n",
            "updating: fairseq/tests/distributed/utils.py (deflated 60%)\n",
            "updating: fairseq/tests/distributed/test_utils.py (deflated 77%)\n",
            "updating: fairseq/tests/distributed/test_bmuf.py (deflated 73%)\n",
            "updating: fairseq/tests/distributed/__init__.py (stored 0%)\n",
            "updating: fairseq/tests/test_dictionary.py (deflated 71%)\n",
            "updating: fairseq/tests/speech/ (stored 0%)\n",
            "updating: fairseq/tests/speech/test_wav2vec2.py (deflated 66%)\n",
            "updating: fairseq/tests/speech/test_fastspeech2.py (deflated 55%)\n",
            "updating: fairseq/tests/speech/test_xm_transformer.py (deflated 48%)\n",
            "updating: fairseq/tests/speech/test_tts_transformer.py (deflated 55%)\n",
            "updating: fairseq/tests/speech/test_s2s_transformer.py (deflated 57%)\n",
            "updating: fairseq/tests/speech/test_s2t_conformer.py (deflated 45%)\n",
            "updating: fairseq/tests/speech/test_dualinput_s2t_transformer.py (deflated 63%)\n",
            "updating: fairseq/tests/speech/test_convtransformer_simul_trans.py (deflated 48%)\n",
            "updating: fairseq/tests/speech/__init__.py (deflated 70%)\n",
            "updating: fairseq/tests/speech/test_s2t_transformer.py (deflated 46%)\n",
            "updating: fairseq/tests/test_dataclass_utils.py (deflated 74%)\n",
            "updating: fairseq/tests/test_dataset.py (deflated 72%)\n",
            "updating: fairseq/tests/test_sequence_generator.py (deflated 84%)\n",
            "updating: fairseq/tests/test_backtranslation_dataset.py (deflated 73%)\n",
            "updating: fairseq/tests/test_huffman.py (deflated 78%)\n",
            "updating: fairseq/tests/test_sparse_multihead_attention.py (deflated 86%)\n",
            "updating: fairseq/tests/test_inference_dropout.py (deflated 79%)\n",
            "updating: fairseq/tests/test_fp16_optimizer.py (deflated 69%)\n",
            "updating: fairseq/tests/gpu/ (stored 0%)\n",
            "updating: fairseq/tests/gpu/test_ema_gpu.py (deflated 78%)\n",
            "updating: fairseq/tests/gpu/test_binaries_gpu.py (deflated 83%)\n",
            "updating: fairseq/tests/gpu/transformer_quantization_config.yaml (deflated 48%)\n",
            "updating: fairseq/tests/gpu/__init__.py (stored 0%)\n",
            "updating: fairseq/tests/test_hf_hub.py (deflated 45%)\n",
            "updating: fairseq/tests/test_iopath.py (deflated 56%)\n",
            "updating: fairseq/tests/test_character_token_embedder.py (deflated 59%)\n",
            "updating: fairseq/tests/test_file_io.py (deflated 64%)\n",
            "updating: fairseq/tests/test_plasma_utils.py (deflated 73%)\n",
            "updating: fairseq/tests/test_convtbc.py (deflated 65%)\n",
            "updating: fairseq/tests/__init__.py (stored 0%)\n",
            "updating: fairseq/tests/test_binaries.py (deflated 90%)\n",
            "updating: fairseq/tests/test_export.py (deflated 69%)\n",
            "updating: fairseq/tests/test_rotary_positional_embedding.py (deflated 73%)\n",
            "updating: fairseq/tests/test_lstm_jitable.py (deflated 65%)\n",
            "updating: fairseq/tests/test_train.py (deflated 80%)\n",
            "updating: fairseq/tests/test_amp_optimizer.py (deflated 63%)\n",
            "updating: fairseq/tests/test_lm_context_window.py (deflated 65%)\n",
            "updating: fairseq/tests/test_roberta.py (deflated 75%)\n",
            "updating: fairseq/tests/test_label_smoothing.py (deflated 73%)\n",
            "updating: fairseq/tests/test_data_utils.py (deflated 73%)\n",
            "updating: fairseq/tests/test_resampling_dataset.py (deflated 70%)\n",
            "updating: fairseq/tests/test_average_checkpoints.py (deflated 71%)\n",
            "updating: fairseq/tests/test_ema.py (deflated 80%)\n",
            "updating: fairseq/tests/test_memory_efficient_fp16.py (deflated 64%)\n",
            "updating: fairseq/alignment_train_cpu_binding.cpython-37m-x86_64-linux-gnu.so (deflated 73%)\n",
            "updating: fairseq/train.py (deflated 34%)\n",
            "updating: fairseq/README.md (deflated 69%)\n",
            "updating: fairseq/.pre-commit-config.yaml (deflated 55%)\n",
            "updating: fairseq/fairseq_cli/ (stored 0%)\n",
            "updating: fairseq/fairseq_cli/preprocess.py (deflated 76%)\n",
            "updating: fairseq/fairseq_cli/generate.py (deflated 72%)\n",
            "updating: fairseq/fairseq_cli/eval_lm.py (deflated 68%)\n",
            "updating: fairseq/fairseq_cli/hydra_train.py (deflated 61%)\n",
            "updating: fairseq/fairseq_cli/score.py (deflated 68%)\n",
            "updating: fairseq/fairseq_cli/interactive.py (deflated 70%)\n",
            "updating: fairseq/fairseq_cli/train.py (deflated 72%)\n",
            "updating: fairseq/fairseq_cli/__init__.py (stored 0%)\n",
            "updating: fairseq/fairseq_cli/validate.py (deflated 64%)\n",
            "updating: fairseq/fairseq/ (stored 0%)\n",
            "updating: fairseq/fairseq/version.py (stored 0%)\n",
            "updating: fairseq/fairseq/logging/ (stored 0%)\n",
            "updating: fairseq/fairseq/logging/metrics.py (deflated 74%)\n",
            "updating: fairseq/fairseq/logging/progress_bar.py (deflated 79%)\n",
            "updating: fairseq/fairseq/logging/meters.py (deflated 76%)\n",
            "updating: fairseq/fairseq/logging/__init__.py (stored 0%)\n",
            "updating: fairseq/fairseq/libbase.cpython-37m-x86_64-linux-gnu.so (deflated 73%)\n",
            "updating: fairseq/fairseq/registry.py (deflated 70%)\n",
            "updating: fairseq/fairseq/nan_detector.py (deflated 67%)\n",
            "updating: fairseq/fairseq/pdb.py (deflated 55%)\n",
            "updating: fairseq/fairseq/utils.py (deflated 70%)\n",
            "updating: fairseq/fairseq/tokenizer.py (deflated 33%)\n",
            "updating: fairseq/fairseq/binarizer.py (deflated 76%)\n",
            "updating: fairseq/fairseq/models/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/distributed_fairseq_model.py (deflated 71%)\n",
            "updating: fairseq/fairseq/models/model_utils.py (deflated 65%)\n",
            "updating: fairseq/fairseq/models/fconv_lm.py (deflated 75%)\n",
            "updating: fairseq/fairseq/models/roberta/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/roberta/alignment_utils.py (deflated 65%)\n",
            "updating: fairseq/fairseq/models/roberta/model_camembert.py (deflated 69%)\n",
            "updating: fairseq/fairseq/models/roberta/model.py (deflated 77%)\n",
            "updating: fairseq/fairseq/models/roberta/model_xlmr.py (deflated 61%)\n",
            "updating: fairseq/fairseq/models/roberta/enc_dec.py (deflated 73%)\n",
            "updating: fairseq/fairseq/models/roberta/__init__.py (deflated 50%)\n",
            "updating: fairseq/fairseq/models/roberta/model_gottbert.py (deflated 58%)\n",
            "updating: fairseq/fairseq/models/roberta/hub_interface.py (deflated 69%)\n",
            "updating: fairseq/fairseq/models/huggingface/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/huggingface/hf_gpt2.py (deflated 72%)\n",
            "updating: fairseq/fairseq/models/huggingface/__init__.py (deflated 49%)\n",
            "updating: fairseq/fairseq/models/ema/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/ema/ema.py (deflated 67%)\n",
            "updating: fairseq/fairseq/models/ema/__init__.py (deflated 43%)\n",
            "updating: fairseq/fairseq/models/multilingual_transformer.py (deflated 78%)\n",
            "updating: fairseq/fairseq/models/lightconv.py (deflated 83%)\n",
            "updating: fairseq/fairseq/models/fairseq_decoder.py (deflated 66%)\n",
            "updating: fairseq/fairseq/models/lstm_lm.py (deflated 74%)\n",
            "updating: fairseq/fairseq/models/hubert/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/hubert/hubert.py (deflated 76%)\n",
            "updating: fairseq/fairseq/models/hubert/hubert_asr.py (deflated 75%)\n",
            "updating: fairseq/fairseq/models/hubert/__init__.py (deflated 34%)\n",
            "updating: fairseq/fairseq/models/lightconv_lm.py (deflated 80%)\n",
            "updating: fairseq/fairseq/models/bart/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/bart/model.py (deflated 77%)\n",
            "updating: fairseq/fairseq/models/bart/__init__.py (deflated 32%)\n",
            "updating: fairseq/fairseq/models/bart/hub_interface.py (deflated 68%)\n",
            "updating: fairseq/fairseq/models/fairseq_model.py (deflated 77%)\n",
            "updating: fairseq/fairseq/models/transformer_align.py (deflated 70%)\n",
            "updating: fairseq/fairseq/models/transformer_lm.py (deflated 84%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/tts_transformer.py (deflated 78%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/hifigan.py (deflated 81%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/fastspeech2.py (deflated 77%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/codehifigan.py (deflated 69%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/__init__.py (deflated 37%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/vocoder.py (deflated 72%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/tacotron2.py (deflated 78%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/hub_interface.py (deflated 68%)\n",
            "updating: fairseq/fairseq/models/fconv.py (deflated 78%)\n",
            "updating: fairseq/fairseq/models/transformer/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/transformer/transformer_base.py (deflated 68%)\n",
            "updating: fairseq/fairseq/models/transformer/transformer_encoder.py (deflated 75%)\n",
            "updating: fairseq/fairseq/models/transformer/transformer_decoder.py (deflated 76%)\n",
            "updating: fairseq/fairseq/models/transformer/__init__.py (deflated 69%)\n",
            "updating: fairseq/fairseq/models/transformer/transformer_config.py (deflated 72%)\n",
            "updating: fairseq/fairseq/models/transformer/transformer_legacy.py (deflated 82%)\n",
            "updating: fairseq/fairseq/models/transformer_ulm.py (deflated 77%)\n",
            "updating: fairseq/fairseq/models/lstm.py (deflated 80%)\n",
            "updating: fairseq/fairseq/models/transformer_from_pretrained_xlm.py (deflated 73%)\n",
            "updating: fairseq/fairseq/models/composite_encoder.py (deflated 66%)\n",
            "updating: fairseq/fairseq/models/__init__.py (deflated 70%)\n",
            "updating: fairseq/fairseq/models/wav2vec/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/wav2vec/wav2vec2.py (deflated 79%)\n",
            "updating: fairseq/fairseq/models/wav2vec/utils.py (deflated 43%)\n",
            "updating: fairseq/fairseq/models/wav2vec/wav2vec2_asr.py (deflated 76%)\n",
            "updating: fairseq/fairseq/models/wav2vec/__init__.py (deflated 40%)\n",
            "updating: fairseq/fairseq/models/wav2vec/wav2vec.py (deflated 76%)\n",
            "updating: fairseq/fairseq/models/fairseq_incremental_decoder.py (deflated 65%)\n",
            "updating: fairseq/fairseq/models/fairseq_encoder.py (deflated 62%)\n",
            "updating: fairseq/fairseq/models/nat/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/nat/levenshtein_utils.py (deflated 76%)\n",
            "updating: fairseq/fairseq/models/nat/levenshtein_transformer.py (deflated 79%)\n",
            "updating: fairseq/fairseq/models/nat/iterative_nonautoregressive_transformer.py (deflated 75%)\n",
            "updating: fairseq/fairseq/models/nat/cmlm_transformer.py (deflated 74%)\n",
            "updating: fairseq/fairseq/models/nat/nonautoregressive_transformer.py (deflated 77%)\n",
            "updating: fairseq/fairseq/models/nat/insertion_transformer.py (deflated 72%)\n",
            "updating: fairseq/fairseq/models/nat/nat_crf_transformer.py (deflated 71%)\n",
            "updating: fairseq/fairseq/models/nat/__init__.py (deflated 51%)\n",
            "updating: fairseq/fairseq/models/nat/fairseq_nat_model.py (deflated 74%)\n",
            "updating: fairseq/fairseq/models/nat/nonautoregressive_ensembles.py (deflated 79%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/s2t_transformer.py (deflated 78%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/convtransformer.py (deflated 78%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/s2t_conformer.py (deflated 73%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/utils.py (deflated 77%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/modules/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/modules/augmented_memory_attention.py (deflated 76%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/modules/emformer.py (deflated 81%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/berard.py (deflated 77%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/__init__.py (deflated 49%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/hub_interface.py (deflated 66%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/xm_transformer.py (deflated 78%)\n",
            "updating: fairseq/fairseq/models/speech_to_speech/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/speech_to_speech/s2s_transformer.py (deflated 83%)\n",
            "updating: fairseq/fairseq/models/speech_to_speech/s2s_conformer.py (deflated 66%)\n",
            "updating: fairseq/fairseq/models/speech_to_speech/__init__.py (deflated 39%)\n",
            "updating: fairseq/fairseq/models/speech_to_speech/modules.py (deflated 61%)\n",
            "updating: fairseq/fairseq/models/masked_lm.py (deflated 78%)\n",
            "updating: fairseq/fairseq/models/fconv_self_att.py (deflated 80%)\n",
            "updating: fairseq/fairseq/file_io.py (deflated 74%)\n",
            "updating: fairseq/fairseq/libbleu.cpython-37m-x86_64-linux-gnu.so (deflated 62%)\n",
            "updating: fairseq/fairseq/config/ (stored 0%)\n",
            "updating: fairseq/fairseq/config/config.yaml (deflated 49%)\n",
            "updating: fairseq/fairseq/config/__init__.py (deflated 25%)\n",
            "updating: fairseq/fairseq/config/model/ (stored 0%)\n",
            "updating: fairseq/fairseq/config/model/wav2vec2/ (stored 0%)\n",
            "updating: fairseq/fairseq/config/model/wav2vec2/wav2vec2_base.yaml (deflated 23%)\n",
            "updating: fairseq/fairseq/config/model/wav2vec2/wav2vec2_large.yaml (deflated 44%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/ (stored 0%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_gpt.yaml (deflated 60%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_baevski_wiki103.yaml (deflated 59%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_wiki103.yaml (deflated 59%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_gpt2_big.yaml (deflated 60%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_gpt2_medium.yaml (deflated 60%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_gpt2_small.yaml (deflated 60%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_gbw.yaml (deflated 60%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_baevski_gbw.yaml (deflated 60%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_big.yaml (deflated 60%)\n",
            "updating: fairseq/fairseq/config/model/wav2vec/ (stored 0%)\n",
            "updating: fairseq/fairseq/config/model/wav2vec/vq_wav2vec_gumbel.yaml (deflated 8%)\n",
            "updating: fairseq/fairseq/trainer.py (deflated 78%)\n",
            "updating: fairseq/fairseq/incremental_decoding_utils.py (deflated 67%)\n",
            "updating: fairseq/fairseq/distributed/ (stored 0%)\n",
            "updating: fairseq/fairseq/distributed/utils.py (deflated 76%)\n",
            "updating: fairseq/fairseq/distributed/tpu_distributed_data_parallel.py (deflated 58%)\n",
            "updating: fairseq/fairseq/distributed/module_proxy_wrapper.py (deflated 67%)\n",
            "updating: fairseq/fairseq/distributed/fully_sharded_data_parallel.py (deflated 67%)\n",
            "updating: fairseq/fairseq/distributed/__init__.py (deflated 59%)\n",
            "updating: fairseq/fairseq/distributed/distributed_timeout_wrapper.py (deflated 65%)\n",
            "updating: fairseq/fairseq/distributed/legacy_distributed_data_parallel.py (deflated 69%)\n",
            "updating: fairseq/fairseq/hub_utils.py (deflated 73%)\n",
            "updating: fairseq/fairseq/dataclass/ (stored 0%)\n",
            "updating: fairseq/fairseq/dataclass/configs.py (deflated 77%)\n",
            "updating: fairseq/fairseq/dataclass/utils.py (deflated 74%)\n",
            "updating: fairseq/fairseq/dataclass/__init__.py (deflated 34%)\n",
            "updating: fairseq/fairseq/dataclass/initialize.py (deflated 61%)\n",
            "updating: fairseq/fairseq/dataclass/constants.py (deflated 54%)\n",
            "updating: fairseq/fairseq/version.txt (stored 0%)\n",
            "updating: fairseq/fairseq/data/ (stored 0%)\n",
            "updating: fairseq/fairseq/data/data_utils_fast.cpp (deflated 87%)\n",
            "updating: fairseq/fairseq/data/transform_eos_dataset.py (deflated 74%)\n",
            "updating: fairseq/fairseq/data/audio/ (stored 0%)\n",
            "updating: fairseq/fairseq/data/audio/audio_utils.py (deflated 69%)\n",
            "updating: fairseq/fairseq/data/audio/frm_text_to_speech_dataset.py (deflated 72%)\n",
            "updating: fairseq/fairseq/data/audio/multi_modality_dataset.py (deflated 74%)\n",
            "updating: fairseq/fairseq/data/audio/speech_to_text_dataset.py (deflated 74%)\n",
            "updating: fairseq/fairseq/data/audio/text_to_speech_dataset.py (deflated 75%)\n",
            "updating: fairseq/fairseq/data/audio/speech_to_text_joint_dataset.py (deflated 76%)\n",
            "updating: fairseq/fairseq/data/audio/__init__.py (stored 0%)\n",
            "updating: fairseq/fairseq/data/audio/speech_to_speech_dataset.py (deflated 77%)\n",
            "updating: fairseq/fairseq/data/audio/feature_transforms/ (stored 0%)\n",
            "updating: fairseq/fairseq/data/audio/feature_transforms/utterance_cmvn.py (deflated 59%)\n",
            "updating: fairseq/fairseq/data/audio/feature_transforms/delta_deltas.py (deflated 58%)\n",
            "updating: fairseq/fairseq/data/audio/feature_transforms/global_cmvn.py (deflated 55%)\n",
            "updating: fairseq/fairseq/data/audio/feature_transforms/specaugment.py (deflated 72%)\n",
            "updating: fairseq/fairseq/data/audio/feature_transforms/__init__.py (deflated 68%)\n",
            "updating: fairseq/fairseq/data/audio/hubert_dataset.py (deflated 73%)\n",
            "updating: fairseq/fairseq/data/audio/data_cfg.py (deflated 72%)\n",
            "updating: fairseq/fairseq/data/audio/raw_audio_dataset.py (deflated 75%)\n",
            "updating: fairseq/fairseq/data/numel_dataset.py (deflated 55%)\n",
            "updating: fairseq/fairseq/data/monolingual_dataset.py (deflated 72%)\n",
            "updating: fairseq/fairseq/data/roll_dataset.py (deflated 44%)\n",
            "updating: fairseq/fairseq/data/text_compressor.py (deflated 69%)\n",
            "updating: fairseq/fairseq/data/encoders/ (stored 0%)\n",
            "updating: fairseq/fairseq/data/encoders/subword_nmt_bpe.py (deflated 63%)\n",
            "updating: fairseq/fairseq/data/encoders/byte_bpe.py (deflated 57%)\n",
            "updating: fairseq/fairseq/data/encoders/space_tokenizer.py (deflated 48%)\n",
            "updating: fairseq/fairseq/data/encoders/gpt2_bpe.py (deflated 57%)\n",
            "updating: fairseq/fairseq/data/encoders/fastbpe.py (deflated 54%)\n",
            "updating: fairseq/fairseq/data/encoders/utils.py (deflated 54%)\n",
            "updating: fairseq/fairseq/data/encoders/byte_utils.py (deflated 55%)\n",
            "updating: fairseq/fairseq/data/encoders/sentencepiece_bpe.py (deflated 60%)\n",
            "updating: fairseq/fairseq/data/encoders/characters.py (deflated 48%)\n",
            "updating: fairseq/fairseq/data/encoders/gpt2_bpe_utils.py (deflated 62%)\n",
            "updating: fairseq/fairseq/data/encoders/bytes.py (deflated 54%)\n",
            "updating: fairseq/fairseq/data/encoders/__init__.py (deflated 47%)\n",
            "updating: fairseq/fairseq/data/encoders/moses_tokenizer.py (deflated 61%)\n",
            "updating: fairseq/fairseq/data/encoders/hf_bert_bpe.py (deflated 60%)\n",
            "updating: fairseq/fairseq/data/encoders/hf_byte_bpe.py (deflated 59%)\n",
            "updating: fairseq/fairseq/data/encoders/nltk_tokenizer.py (deflated 52%)\n",
            "updating: fairseq/fairseq/data/dictionary.py (deflated 72%)\n",
            "updating: fairseq/fairseq/data/offset_tokens_dataset.py (deflated 43%)\n",
            "updating: fairseq/fairseq/data/data_utils_fast.pyx (deflated 73%)\n",
            "updating: fairseq/fairseq/data/add_target_dataset.py (deflated 69%)\n",
            "updating: fairseq/fairseq/data/iterators.py (deflated 78%)\n",
            "updating: fairseq/fairseq/data/mask_tokens_dataset.py (deflated 71%)\n",
            "updating: fairseq/fairseq/data/token_block_utils_fast.cpython-37m-x86_64-linux-gnu.so (deflated 69%)\n",
            "updating: fairseq/fairseq/data/num_samples_dataset.py (deflated 42%)\n",
            "updating: fairseq/fairseq/data/concat_sentences_dataset.py (deflated 66%)\n",
            "updating: fairseq/fairseq/data/shorten_dataset.py (deflated 67%)\n",
            "updating: fairseq/fairseq/data/concat_dataset.py (deflated 70%)\n",
            "updating: fairseq/fairseq/data/token_block_dataset.py (deflated 71%)\n",
            "updating: fairseq/fairseq/data/lru_cache_dataset.py (deflated 47%)\n",
            "updating: fairseq/fairseq/data/strip_token_dataset.py (deflated 52%)\n",
            "updating: fairseq/fairseq/data/fairseq_dataset.py (deflated 69%)\n",
            "updating: fairseq/fairseq/data/denoising_dataset.py (deflated 73%)\n",
            "updating: fairseq/fairseq/data/transform_eos_concat_langpair_dataset.py (deflated 75%)\n",
            "updating: fairseq/fairseq/data/replace_dataset.py (deflated 55%)\n",
            "updating: fairseq/fairseq/data/huffman/ (stored 0%)\n",
            "updating: fairseq/fairseq/data/huffman/huffman_mmap_indexed_dataset.py (deflated 72%)\n",
            "updating: fairseq/fairseq/data/huffman/__init__.py (deflated 55%)\n",
            "updating: fairseq/fairseq/data/huffman/huffman_coder.py (deflated 70%)\n",
            "updating: fairseq/fairseq/data/multi_corpus_dataset.py (deflated 71%)\n",
            "updating: fairseq/fairseq/data/append_token_dataset.py (deflated 61%)\n",
            "updating: fairseq/fairseq/data/token_block_utils_fast.pyx (deflated 75%)\n",
            "updating: fairseq/fairseq/data/prepend_dataset.py (deflated 56%)\n",
            "updating: fairseq/fairseq/data/data_utils.py (deflated 70%)\n",
            "updating: fairseq/fairseq/data/prepend_token_dataset.py (deflated 61%)\n",
            "updating: fairseq/fairseq/data/fasta_dataset.py (deflated 64%)\n",
            "updating: fairseq/fairseq/data/pad_dataset.py (deflated 61%)\n",
            "updating: fairseq/fairseq/data/base_wrapper_dataset.py (deflated 71%)\n",
            "updating: fairseq/fairseq/data/bucket_pad_length_dataset.py (deflated 64%)\n",
            "updating: fairseq/fairseq/data/indexed_dataset.py (deflated 77%)\n",
            "updating: fairseq/fairseq/data/noising.py (deflated 71%)\n",
            "updating: fairseq/fairseq/data/backtranslation_dataset.py (deflated 67%)\n",
            "updating: fairseq/fairseq/data/raw_label_dataset.py (deflated 48%)\n",
            "updating: fairseq/fairseq/data/round_robin_zip_datasets.py (deflated 70%)\n",
            "updating: fairseq/fairseq/data/resampling_dataset.py (deflated 65%)\n",
            "updating: fairseq/fairseq/data/codedataset.py (deflated 73%)\n",
            "updating: fairseq/fairseq/data/legacy/ (stored 0%)\n",
            "updating: fairseq/fairseq/data/legacy/masked_lm_dataset.py (deflated 71%)\n",
            "updating: fairseq/fairseq/data/legacy/masked_lm_dictionary.py (deflated 67%)\n",
            "updating: fairseq/fairseq/data/legacy/__init__.py (deflated 48%)\n",
            "updating: fairseq/fairseq/data/legacy/block_pair_dataset.py (deflated 72%)\n",
            "updating: fairseq/fairseq/data/data_utils_fast.cpython-37m-x86_64-linux-gnu.so (deflated 69%)\n",
            "updating: fairseq/fairseq/data/language_pair_dataset.py (deflated 75%)\n",
            "updating: fairseq/fairseq/data/__init__.py (deflated 75%)\n",
            "updating: fairseq/fairseq/data/subsample_dataset.py (deflated 62%)\n",
            "updating: fairseq/fairseq/data/lm_context_window_dataset.py (deflated 67%)\n",
            "updating: fairseq/fairseq/data/plasma_utils.py (deflated 68%)\n",
            "updating: fairseq/fairseq/data/nested_dictionary_dataset.py (deflated 66%)\n",
            "updating: fairseq/fairseq/data/transform_eos_lang_pair_dataset.py (deflated 71%)\n",
            "updating: fairseq/fairseq/data/colorize_dataset.py (deflated 50%)\n",
            "updating: fairseq/fairseq/data/sort_dataset.py (deflated 47%)\n",
            "updating: fairseq/fairseq/data/multilingual/ (stored 0%)\n",
            "updating: fairseq/fairseq/data/multilingual/sampled_multi_dataset.py (deflated 74%)\n",
            "updating: fairseq/fairseq/data/multilingual/sampled_multi_epoch_dataset.py (deflated 72%)\n",
            "updating: fairseq/fairseq/data/multilingual/sampling_method.py (deflated 65%)\n",
            "updating: fairseq/fairseq/data/multilingual/multilingual_data_manager.py (deflated 80%)\n",
            "updating: fairseq/fairseq/data/multilingual/__init__.py (deflated 25%)\n",
            "updating: fairseq/fairseq/data/multilingual/multilingual_utils.py (deflated 58%)\n",
            "updating: fairseq/fairseq/data/multi_corpus_sampled_dataset.py (deflated 69%)\n",
            "updating: fairseq/fairseq/data/token_block_utils_fast.cpp (deflated 87%)\n",
            "updating: fairseq/fairseq/data/id_dataset.py (deflated 43%)\n",
            "updating: fairseq/fairseq/data/list_dataset.py (deflated 54%)\n",
            "updating: fairseq/fairseq/token_generation_constraints.py (deflated 75%)\n",
            "updating: fairseq/fairseq/modules/ (stored 0%)\n",
            "updating: fairseq/fairseq/modules/lightconv_layer/ (stored 0%)\n",
            "updating: fairseq/fairseq/modules/lightconv_layer/lightconv_cuda.cpp (deflated 63%)\n",
            "updating: fairseq/fairseq/modules/lightconv_layer/lightconv_layer.py (deflated 69%)\n",
            "updating: fairseq/fairseq/modules/lightconv_layer/lightconv_cuda.cuh (deflated 77%)\n",
            "updating: fairseq/fairseq/modules/lightconv_layer/lightconv_cuda_kernel.cu (deflated 83%)\n",
            "updating: fairseq/fairseq/modules/lightconv_layer/setup.py (deflated 47%)\n",
            "updating: fairseq/fairseq/modules/lightconv_layer/__init__.py (deflated 30%)\n",
            "updating: fairseq/fairseq/modules/lightconv_layer/cuda_function_gen.py (deflated 82%)\n",
            "updating: fairseq/fairseq/modules/dynamic_convolution.py (deflated 75%)\n",
            "updating: fairseq/fairseq/modules/transformer_layer.py (deflated 81%)\n",
            "updating: fairseq/fairseq/modules/kmeans_attention.py (deflated 74%)\n",
            "updating: fairseq/fairseq/modules/conv_tbc.py (deflated 60%)\n",
            "updating: fairseq/fairseq/modules/lstm_cell_with_zoneout.py (deflated 49%)\n",
            "updating: fairseq/fairseq/modules/scalar_bias.py (deflated 49%)\n",
            "updating: fairseq/fairseq/modules/quantization/ (stored 0%)\n",
            "updating: fairseq/fairseq/modules/quantization/quantization_options.py (deflated 63%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/ (stored 0%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/utils.py (deflated 71%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/modules/ (stored 0%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/modules/qconv.py (deflated 66%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/modules/qlinear.py (deflated 63%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/modules/qemb.py (deflated 68%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/modules/__init__.py (deflated 36%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/__init__.py (deflated 27%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/pq.py (deflated 67%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/em.py (deflated 71%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/ (stored 0%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/utils.py (deflated 60%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/ops.py (deflated 71%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/modules/ (stored 0%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/modules/qconv.py (deflated 68%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/modules/qlinear.py (deflated 64%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/modules/qact.py (deflated 62%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/modules/qemb.py (deflated 68%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/modules/__init__.py (deflated 40%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/__init__.py (deflated 25%)\n",
            "updating: fairseq/fairseq/modules/quantization/__init__.py (stored 0%)\n",
            "updating: fairseq/fairseq/modules/beamable_mm.py (deflated 59%)\n",
            "updating: fairseq/fairseq/modules/linearized_convolution.py (deflated 69%)\n",
            "updating: fairseq/fairseq/modules/adaptive_softmax.py (deflated 73%)\n",
            "updating: fairseq/fairseq/modules/cuda_utils.cu (deflated 70%)\n",
            "updating: fairseq/fairseq/modules/conformer_layer.py (deflated 77%)\n",
            "updating: fairseq/fairseq/modules/espnet_multihead_attention.py (deflated 76%)\n",
            "updating: fairseq/fairseq/modules/checkpoint_activations.py (deflated 71%)\n",
            "updating: fairseq/fairseq/modules/sinusoidal_positional_embedding.py (deflated 66%)\n",
            "updating: fairseq/fairseq/modules/unfold.py (deflated 45%)\n",
            "updating: fairseq/fairseq/modules/fp32_group_norm.py (deflated 50%)\n",
            "updating: fairseq/fairseq/modules/fp32_instance_norm.py (deflated 60%)\n",
            "updating: fairseq/fairseq/modules/dynamic_crf_layer.py (deflated 72%)\n",
            "updating: fairseq/fairseq/modules/cross_entropy.py (deflated 65%)\n",
            "updating: fairseq/fairseq/modules/adaptive_input.py (deflated 64%)\n",
            "updating: fairseq/fairseq/modules/positional_encoding.py (deflated 74%)\n",
            "updating: fairseq/fairseq/modules/sparse_multihead_attention.py (deflated 70%)\n",
            "updating: fairseq/fairseq/modules/transformer_sentence_encoder_layer.py (deflated 74%)\n",
            "updating: fairseq/fairseq/modules/learned_positional_embedding.py (deflated 60%)\n",
            "updating: fairseq/fairseq/modules/transpose_last.py (deflated 46%)\n",
            "updating: fairseq/fairseq/modules/sparse_transformer_sentence_encoder.py (deflated 71%)\n",
            "updating: fairseq/fairseq/modules/character_token_embedder.py (deflated 70%)\n",
            "updating: fairseq/fairseq/modules/gumbel_vector_quantizer.py (deflated 69%)\n",
            "updating: fairseq/fairseq/modules/transformer_sentence_encoder.py (deflated 74%)\n",
            "updating: fairseq/fairseq/modules/rotary_positional_embedding.py (deflated 58%)\n",
            "updating: fairseq/fairseq/modules/lightweight_convolution.py (deflated 76%)\n",
            "updating: fairseq/fairseq/modules/downsampled_multihead_attention.py (deflated 78%)\n",
            "updating: fairseq/fairseq/modules/layer_drop.py (deflated 55%)\n",
            "updating: fairseq/fairseq/modules/sparse_transformer_sentence_encoder_layer.py (deflated 66%)\n",
            "updating: fairseq/fairseq/modules/positional_embedding.py (deflated 60%)\n",
            "updating: fairseq/fairseq/modules/kmeans_vector_quantizer.py (deflated 63%)\n",
            "updating: fairseq/fairseq/modules/grad_multiply.py (deflated 42%)\n",
            "updating: fairseq/fairseq/modules/fairseq_dropout.py (deflated 63%)\n",
            "updating: fairseq/fairseq/modules/multihead_attention.py (deflated 79%)\n",
            "updating: fairseq/fairseq/modules/__init__.py (deflated 71%)\n",
            "updating: fairseq/fairseq/modules/base_layer.py (deflated 68%)\n",
            "updating: fairseq/fairseq/modules/quant_noise.py (deflated 68%)\n",
            "updating: fairseq/fairseq/modules/layer_norm.py (deflated 61%)\n",
            "updating: fairseq/fairseq/modules/fp32_batch_norm.py (deflated 61%)\n",
            "updating: fairseq/fairseq/modules/vggblock.py (deflated 66%)\n",
            "updating: fairseq/fairseq/modules/location_attention.py (deflated 66%)\n",
            "updating: fairseq/fairseq/modules/gelu.py (deflated 41%)\n",
            "updating: fairseq/fairseq/modules/same_pad.py (deflated 45%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/ (stored 0%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/dynamicconv_cuda.cuh (deflated 61%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/dynamicconv_cuda_kernel.cu (deflated 74%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/dynamicconv_layer.py (deflated 75%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/setup.py (deflated 48%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/dynamiconv_cpu.cpp (deflated 65%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/__init__.py (deflated 29%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/cuda_function_gen.py (deflated 77%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/dynamicconv_cuda.cpp (deflated 64%)\n",
            "updating: fairseq/fairseq/modules/ema_module.py (deflated 67%)\n",
            "updating: fairseq/fairseq/sequence_scorer.py (deflated 70%)\n",
            "updating: fairseq/fairseq/model_parallel/ (stored 0%)\n",
            "updating: fairseq/fairseq/model_parallel/models/ (stored 0%)\n",
            "updating: fairseq/fairseq/model_parallel/models/transformer.py (deflated 68%)\n",
            "updating: fairseq/fairseq/model_parallel/models/roberta/ (stored 0%)\n",
            "updating: fairseq/fairseq/model_parallel/models/roberta/model.py (deflated 73%)\n",
            "updating: fairseq/fairseq/model_parallel/models/roberta/__init__.py (deflated 27%)\n",
            "updating: fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/ (stored 0%)\n",
            "updating: fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py (deflated 79%)\n",
            "updating: fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/__init__.py (deflated 27%)\n",
            "updating: fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/layers.py (deflated 81%)\n",
            "updating: fairseq/fairseq/model_parallel/models/transformer_lm.py (deflated 75%)\n",
            "updating: fairseq/fairseq/model_parallel/models/__init__.py (deflated 50%)\n",
            "updating: fairseq/fairseq/model_parallel/modules/ (stored 0%)\n",
            "updating: fairseq/fairseq/model_parallel/modules/transformer_layer.py (deflated 76%)\n",
            "updating: fairseq/fairseq/model_parallel/modules/multihead_attention.py (deflated 77%)\n",
            "updating: fairseq/fairseq/model_parallel/modules/__init__.py (deflated 51%)\n",
            "updating: fairseq/fairseq/model_parallel/__init__.py (deflated 29%)\n",
            "updating: fairseq/fairseq/model_parallel/megatron_trainer.py (deflated 66%)\n",
            "updating: fairseq/fairseq/model_parallel/megatron/ (stored 0%)\n",
            "updating: fairseq/fairseq/model_parallel/criterions/ (stored 0%)\n",
            "updating: fairseq/fairseq/model_parallel/criterions/vocab_parallel_cross_entropy.py (deflated 64%)\n",
            "updating: fairseq/fairseq/model_parallel/criterions/__init__.py (deflated 42%)\n",
            "updating: fairseq/fairseq/options.py (deflated 76%)\n",
            "updating: fairseq/fairseq/__init__.py (deflated 59%)\n",
            "updating: fairseq/fairseq/file_chunker_utils.py (deflated 62%)\n",
            "updating: fairseq/fairseq/benchmark/ (stored 0%)\n",
            "updating: fairseq/fairseq/benchmark/dummy_dataset.py (deflated 65%)\n",
            "updating: fairseq/fairseq/benchmark/dummy_masked_lm.py (deflated 63%)\n",
            "updating: fairseq/fairseq/benchmark/dummy_model.py (deflated 68%)\n",
            "updating: fairseq/fairseq/benchmark/dummy_lm.py (deflated 62%)\n",
            "updating: fairseq/fairseq/benchmark/dummy_mt.py (deflated 67%)\n",
            "updating: fairseq/fairseq/benchmark/__init__.py (deflated 36%)\n",
            "updating: fairseq/fairseq/clib/ (stored 0%)\n",
            "updating: fairseq/fairseq/clib/libbase/ (stored 0%)\n",
            "updating: fairseq/fairseq/clib/libbase/balanced_assignment.cpp (deflated 64%)\n",
            "updating: fairseq/fairseq/clib/libbleu/ (stored 0%)\n",
            "updating: fairseq/fairseq/clib/libbleu/module.cpp (deflated 42%)\n",
            "updating: fairseq/fairseq/clib/libbleu/libbleu.cpp (deflated 67%)\n",
            "updating: fairseq/fairseq/clib/cuda/ (stored 0%)\n",
            "updating: fairseq/fairseq/clib/cuda/ngram_repeat_block_cuda.cpp (deflated 59%)\n",
            "updating: fairseq/fairseq/clib/cuda/ngram_repeat_block_cuda_kernel.cu (deflated 60%)\n",
            "updating: fairseq/fairseq/clib/libnat/ (stored 0%)\n",
            "updating: fairseq/fairseq/clib/libnat/edit_dist.cpp (deflated 79%)\n",
            "updating: fairseq/fairseq/clib/libnat_cuda/ (stored 0%)\n",
            "updating: fairseq/fairseq/clib/libnat_cuda/edit_dist.h (deflated 55%)\n",
            "updating: fairseq/fairseq/clib/libnat_cuda/edit_dist.cu (deflated 83%)\n",
            "updating: fairseq/fairseq/clib/libnat_cuda/binding.cpp (deflated 64%)\n",
            "updating: fairseq/fairseq/speech_generator.py (deflated 77%)\n",
            "updating: fairseq/fairseq/quantization_utils.py (deflated 71%)\n",
            "updating: fairseq/fairseq/optim/ (stored 0%)\n",
            "updating: fairseq/fairseq/optim/adadelta.py (deflated 57%)\n",
            "updating: fairseq/fairseq/optim/fairseq_optimizer.py (deflated 72%)\n",
            "updating: fairseq/fairseq/optim/amp_optimizer.py (deflated 66%)\n",
            "updating: fairseq/fairseq/optim/adamax.py (deflated 68%)\n",
            "updating: fairseq/fairseq/optim/nag.py (deflated 65%)\n",
            "updating: fairseq/fairseq/optim/fused_lamb.py (deflated 58%)\n",
            "updating: fairseq/fairseq/optim/adafactor.py (deflated 72%)\n",
            "updating: fairseq/fairseq/optim/dynamic_loss_scaler.py (deflated 68%)\n",
            "updating: fairseq/fairseq/optim/shard.py (deflated 57%)\n",
            "updating: fairseq/fairseq/optim/composite.py (deflated 72%)\n",
            "updating: fairseq/fairseq/optim/__init__.py (deflated 56%)\n",
            "updating: fairseq/fairseq/optim/sgd.py (deflated 55%)\n",
            "updating: fairseq/fairseq/optim/fused_adam.py (deflated 75%)\n",
            "updating: fairseq/fairseq/optim/cpu_adam.py (deflated 70%)\n",
            "updating: fairseq/fairseq/optim/bmuf.py (deflated 71%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/ (stored 0%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/fairseq_lr_scheduler.py (deflated 66%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/manual_lr_scheduler.py (deflated 71%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/cosine_lr_scheduler.py (deflated 68%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/polynomial_decay_schedule.py (deflated 69%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/fixed_schedule.py (deflated 66%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/triangular_lr_scheduler.py (deflated 62%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/step_lr_scheduler.py (deflated 68%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/pass_through.py (deflated 62%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py (deflated 68%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/__init__.py (deflated 51%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/inverse_square_root_schedule.py (deflated 65%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/tri_stage_lr_scheduler.py (deflated 70%)\n",
            "updating: fairseq/fairseq/optim/fp16_optimizer.py (deflated 80%)\n",
            "updating: fairseq/fairseq/optim/adagrad.py (deflated 52%)\n",
            "updating: fairseq/fairseq/optim/adam.py (deflated 69%)\n",
            "updating: fairseq/fairseq/criterions/ (stored 0%)\n",
            "updating: fairseq/fairseq/criterions/label_smoothed_cross_entropy_with_alignment.py (deflated 68%)\n",
            "updating: fairseq/fairseq/criterions/hubert_criterion.py (deflated 72%)\n",
            "updating: fairseq/fairseq/criterions/model_criterion.py (deflated 68%)\n",
            "updating: fairseq/fairseq/criterions/sentence_prediction.py (deflated 70%)\n",
            "updating: fairseq/fairseq/criterions/sentence_ranking.py (deflated 66%)\n",
            "updating: fairseq/fairseq/criterions/label_smoothed_cross_entropy_latency_augmented.py (deflated 74%)\n",
            "updating: fairseq/fairseq/criterions/tacotron2_loss.py (deflated 71%)\n",
            "updating: fairseq/fairseq/criterions/cross_entropy.py (deflated 64%)\n",
            "updating: fairseq/fairseq/criterions/fairseq_criterion.py (deflated 65%)\n",
            "updating: fairseq/fairseq/criterions/ctc.py (deflated 75%)\n",
            "updating: fairseq/fairseq/criterions/composite_loss.py (deflated 70%)\n",
            "updating: fairseq/fairseq/criterions/speech_to_speech_criterion.py (deflated 79%)\n",
            "updating: fairseq/fairseq/criterions/__init__.py (deflated 50%)\n",
            "updating: fairseq/fairseq/criterions/nat_loss.py (deflated 69%)\n",
            "updating: fairseq/fairseq/criterions/legacy_masked_lm.py (deflated 68%)\n",
            "updating: fairseq/fairseq/criterions/wav2vec_criterion.py (deflated 71%)\n",
            "updating: fairseq/fairseq/criterions/fastspeech2_loss.py (deflated 70%)\n",
            "updating: fairseq/fairseq/criterions/masked_lm.py (deflated 61%)\n",
            "updating: fairseq/fairseq/criterions/label_smoothed_cross_entropy.py (deflated 70%)\n",
            "updating: fairseq/fairseq/criterions/adaptive_loss.py (deflated 64%)\n",
            "updating: fairseq/fairseq/criterions/speech_ulm_criterion.py (deflated 69%)\n",
            "updating: fairseq/fairseq/ngram_repeat_block.py (deflated 68%)\n",
            "updating: fairseq/fairseq/search.py (deflated 76%)\n",
            "updating: fairseq/fairseq/file_utils.py (deflated 68%)\n",
            "updating: fairseq/fairseq/scoring/ (stored 0%)\n",
            "updating: fairseq/fairseq/scoring/tokenizer.py (deflated 63%)\n",
            "updating: fairseq/fairseq/scoring/wer.py (deflated 63%)\n",
            "updating: fairseq/fairseq/scoring/meteor.py (deflated 56%)\n",
            "updating: fairseq/fairseq/scoring/chrf.py (deflated 55%)\n",
            "updating: fairseq/fairseq/scoring/bertscore.py (deflated 58%)\n",
            "updating: fairseq/fairseq/scoring/__init__.py (deflated 53%)\n",
            "updating: fairseq/fairseq/scoring/bleu.py (deflated 69%)\n",
            "updating: fairseq/fairseq/checkpoint_utils.py (deflated 74%)\n",
            "updating: fairseq/fairseq/sequence_generator.py (deflated 76%)\n",
            "updating: fairseq/fairseq/libnat.cpython-37m-x86_64-linux-gnu.so (deflated 73%)\n",
            "updating: fairseq/fairseq/iterative_refinement_generator.py (deflated 75%)\n",
            "updating: fairseq/fairseq/tasks/ (stored 0%)\n",
            "updating: fairseq/fairseq/tasks/audio_finetuning.py (deflated 74%)\n",
            "updating: fairseq/fairseq/tasks/fairseq_task.py (deflated 75%)\n",
            "updating: fairseq/fairseq/tasks/speech_ulm_task.py (deflated 72%)\n",
            "updating: fairseq/fairseq/tasks/multilingual_translation.py (deflated 75%)\n",
            "updating: fairseq/fairseq/tasks/denoising.py (deflated 73%)\n",
            "updating: fairseq/fairseq/tasks/sentence_prediction.py (deflated 72%)\n",
            "updating: fairseq/fairseq/tasks/multilingual_language_modeling.py (deflated 75%)\n",
            "updating: fairseq/fairseq/tasks/sentence_ranking.py (deflated 70%)\n",
            "updating: fairseq/fairseq/tasks/multilingual_denoising.py (deflated 72%)\n",
            "updating: fairseq/fairseq/tasks/translation_lev.py (deflated 72%)\n",
            "updating: fairseq/fairseq/tasks/audio_pretraining.py (deflated 71%)\n",
            "updating: fairseq/fairseq/tasks/semisupervised_translation.py (deflated 80%)\n",
            "updating: fairseq/fairseq/tasks/speech_to_text.py (deflated 70%)\n",
            "updating: fairseq/fairseq/tasks/language_modeling.py (deflated 72%)\n",
            "updating: fairseq/fairseq/tasks/simultaneous_translation.py (deflated 58%)\n",
            "updating: fairseq/fairseq/tasks/cross_lingual_lm.py (deflated 67%)\n",
            "updating: fairseq/fairseq/tasks/frm_text_to_speech.py (deflated 65%)\n",
            "updating: fairseq/fairseq/tasks/translation.py (deflated 73%)\n",
            "updating: fairseq/fairseq/tasks/speech_to_speech.py (deflated 74%)\n",
            "updating: fairseq/fairseq/tasks/multilingual_masked_lm.py (deflated 73%)\n",
            "updating: fairseq/fairseq/tasks/__init__.py (deflated 66%)\n",
            "updating: fairseq/fairseq/tasks/online_backtranslation.py (deflated 74%)\n",
            "updating: fairseq/fairseq/tasks/hubert_pretraining.py (deflated 70%)\n",
            "updating: fairseq/fairseq/tasks/legacy_masked_lm.py (deflated 67%)\n",
            "updating: fairseq/fairseq/tasks/masked_lm.py (deflated 72%)\n",
            "updating: fairseq/fairseq/tasks/translation_from_pretrained_bart.py (deflated 67%)\n",
            "updating: fairseq/fairseq/tasks/text_to_speech.py (deflated 70%)\n",
            "updating: fairseq/fairseq/tasks/translation_multi_simple_epoch.py (deflated 75%)\n",
            "updating: fairseq/fairseq/tasks/translation_from_pretrained_xlm.py (deflated 56%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/checkpoints/checkpoint60.pt /content/drive/MyDrive/SuperAI2/MachineTranslation/"
      ],
      "metadata": {
        "id": "KXpXn1wuAsNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58c4fbae-d99b-40bb-e686-b2028c730ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/content/drive/MyDrive/SuperAI2/MachineTranslation/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/checkpoints/checkpoint_best.pt /content/drive/MyDrive/SuperAI2/MachineTranslation/\n",
        "!cp /content/checkpoints/checkpoint_last.pt /content/drive/MyDrive/SuperAI2/MachineTranslation/"
      ],
      "metadata": {
        "id": "hdUmwdjABJY4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4b19d24-e65b-4118-b4b1-8bb6dbba1e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/content/drive/MyDrive/SuperAI2/MachineTranslation/': No such file or directory\n",
            "cp: cannot create regular file '/content/drive/MyDrive/SuperAI2/MachineTranslation/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://object.pouta.csc.fi/Tatoeba-Challenge-v2021-08-07/eng-tha.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju_CEFYGjvsK",
        "outputId": "b8e32fa5-4ec8-4831-a260-958c55209257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-08 05:31:29--  https://object.pouta.csc.fi/Tatoeba-Challenge-v2021-08-07/eng-tha.tar\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvf /content/eng-tha.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZB0EiOHj6RU",
        "outputId": "ccfd6746-1a38-4f52-a21a-dc45d7b34f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/release/v2021-08-07/eng-tha/\n",
            "data/release/v2021-08-07/eng-tha/train.src.gz\n",
            "data/release/v2021-08-07/eng-tha/dev.trg\n",
            "data/release/v2021-08-07/eng-tha/train.id.gz\n",
            "data/release/v2021-08-07/eng-tha/test.trg\n",
            "data/release/v2021-08-07/eng-tha/test.id\n",
            "data/release/v2021-08-07/eng-tha/dev.src\n",
            "data/release/v2021-08-07/eng-tha/dev.id\n",
            "data/release/v2021-08-07/eng-tha/README.md\n",
            "data/release/v2021-08-07/eng-tha/test.src\n",
            "data/release/v2021-08-07/eng-tha/train.trg.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip /content/data/release/v2021-08-07/eng-tha/train.id.gz"
      ],
      "metadata": {
        "id": "CsKwaTNxkFG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f34dfec-196b-4c62-b4b7-a3bd4975a465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gzip: /content/data/release/v2021-08-07/eng-tha/train.id already exists; do you wish to overwrite (y or n)? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail /content/data/release/v2021-08-07/eng-tha/train.id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMdUpsUokVIU",
        "outputId": "f4b7563b-d916-462b-fa5d-144609d0588f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CCAligned-v1\teng\ttha\n",
            "CCAligned-v1\teng\ttha\n",
            "CCAligned-v1\teng\ttha\n",
            "CCAligned-v1\teng\ttha\n",
            "CCAligned-v1\teng\ttha\n",
            "OpenSubtitles-v2018\teng\ttha\n",
            "CCAligned-v1\teng\ttha\n",
            "OpenSubtitles-v2018\teng\ttha\n",
            "OpenSubtitles-v2018\teng\ttha\n",
            "OpenSubtitles-v2018\teng\ttha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip /content/data/release/v2021-08-07/eng-tha/train.src.gz"
      ],
      "metadata": {
        "id": "fg62n-S_khcz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d382a06e-2388-4331-f3a5-810897ec84c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gzip: /content/data/release/v2021-08-07/eng-tha/train.src already exists; do you wish to overwrite (y or n)? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail /content/data/release/v2021-08-07/eng-tha/train.src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT5MP54ukqy5",
        "outputId": "36df2a16-7eb6-4995-dab5-057175abfeeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ShemaleMia \n",
            "Pro-environment Long Lifetime Flue Gas Cooler for Drying or Cooling usage for Various Equipments General Introduction of Product Flue gas coolers are special heat recovery units where sensible heat contained in ... Read More \n",
            "Model No.: AT-15W \n",
            "Nanpi Jiantong Hardware Manufacturing Co., Ltd is a designer and manufacturer for Custom Sheet Metal Stamping Partsand Custom deep drawn stamping.Laser Cutting Service. Whether you require metal stampings, metal forming and sheet metal fabrications, tooling and die programming or Custom Cnc Parts and other services we provide, the expert team will ensure first-class service and high-grade quality, backed by our ISO 9001:2008 and TS16949 Quality Assurance guarantee. Please send your Enquiries here and Contact us for considerate services. \n",
            "Are always used for 330 When we work with RPI, or it may vary? \n",
            "George's already here. Why didn't you come with him?\n",
            "Follow us on Twitter \n",
            "Glove? I don't own shorts.\n",
            "I need to ask you something. Get out of here.\n",
            "- I'm glad we've got that on the record.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip /content/data/release/v2021-08-07/eng-tha/train.trg.gz"
      ],
      "metadata": {
        "id": "p3uTa4Jtk6bE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca4202fa-4b70-476c-ee6a-e5e6711e7e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gzip: /content/data/release/v2021-08-07/eng-tha/train.trg already exists; do you wish to overwrite (y or n)? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail /content/data/release/v2021-08-07/eng-tha/train.trg"
      ],
      "metadata": {
        "id": "XY0xlfrhk-Nv",
        "outputId": "281ad305-3912-4534-aaef-d2b574c89ad3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "กระเทย\n",
            "เครื่องทำความเย็นแก๊สไอเสียสำหรับใช้งานในสภาพแวดล้อมที่ยาวนานสำหรับการทำให้แห้งหรือทำความเย็นสำหรับอุปกรณ์ต่าง ๆ บทนำทั่วไปของผลิตภัณฑ์ เครื่องทำความเย็นก๊าซปล่องเป็นหน่วยกู้คืนความร้อนพิเศษที่ความร้อนที่เหมาะส... Read More\n",
            "หมายเลขรุ่น: AT-15W\n",
            "Nanpi Jiantong Hardware Manufacturing Co. , Ltd เป็นผู้ออกแบบและผู้ผลิต ชิ้นส่วนปั๊มโลหะแผ่นแบบกำหนดเองและปั๊มขึ้นรูป ลึกแบบกำหนดเอง บริการตัดด้วยเลเซอร์ ไม่ว่าคุณจะต้องการการประทับตราโลหะการขึ้นรูปโลหะและการประดิษฐ์แผ่นโลหะเครื่องมือและแม่พิมพ์หรือ ชิ้นส่วน CNC แบบกำหนดเอง และบริการอื่น ๆ ที่เราให้บริการทีมผู้เชี่ยวชาญจะรับประกันบริการชั้นหนึ่งและคุณภาพสูงซึ่งได้รับการสนับสนุนจาก ISO 9001: 2008 TS16949 รับประกันคุณภาพรับประกัน กรุณาส่งคำถามของคุณที่นี่และ ติดต่อเรา สำหรับบริการที่นึกถึง\n",
            "จะใช้สำหรับ 330 เมื่อเราทำงานกับ RPI, หรืออาจแตกต่างกัน?\n",
            "จอร์จมานี่ก่อนแล้ว ทำไมเธอไม่มาพร้อมเขาล่ะ\n",
            "ติดตามเราบน อินสตาแกรม\n",
            "ถุงมือเหรอ ผมไม่ได้เตรียมมาเล่นนะ\n",
            "ฉันมีเรื่องจะถามคุณ\n",
            "-ดีที่เราบันทึกไว้\n"
          ]
        }
      ]
    }
  ]
}