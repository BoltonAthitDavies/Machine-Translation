{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPU_p'man+p'pongV4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7c7cb67453754937b5b7d9ee28011147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ffe150a6b24547c4a420193f0ba71bb9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_98edfa7c17914381a8f18bf8814630b8",
              "IPY_MODEL_f8500f4348c14d308ae842b8a8382931",
              "IPY_MODEL_3167a300e17a45fc887ac5c6ed9e1437"
            ]
          }
        },
        "ffe150a6b24547c4a420193f0ba71bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98edfa7c17914381a8f18bf8814630b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ece7e46f004643d1871ead91f2d507c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14893ab166054c72b67e120555137349"
          }
        },
        "f8500f4348c14d308ae842b8a8382931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4b161da59ad642a084b77474a569e6c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd12e1957a5943c094f0f6ab708332a3"
          }
        },
        "3167a300e17a45fc887ac5c6ed9e1437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_399537f954054ff2b5a7eb165fdb5f8c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1520/1520 [12:56&lt;00:00,  1.09it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc5032420262426096eeebf6c25d1593"
          }
        },
        "ece7e46f004643d1871ead91f2d507c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14893ab166054c72b67e120555137349": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b161da59ad642a084b77474a569e6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd12e1957a5943c094f0f6ab708332a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "399537f954054ff2b5a7eb165fdb5f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc5032420262426096eeebf6c25d1593": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1c4VRvOzPkFKsbavjgxaX59SKG6CZzxpQ"
      ],
      "metadata": {
        "id": "NhEyvROsFv9Q",
        "outputId": "e78be996-3ef7-42b4-ed6c-b514a7ccdcbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1c4VRvOzPkFKsbavjgxaX59SKG6CZzxpQ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "sYv87Ie6bNxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYHoPbm9P8fR",
        "outputId": "226cd20a-b183-4033-d540-2421d1db2b73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar 10 05:50:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!gdown --id 1Viv8ilV6vCDIUPlHw3Wf5z4dnQh8mSRe # 15m data"
      ],
      "metadata": {
        "id": "u0OieXen7GPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!gdown --id 1wKpWqYL45HBe9t5Edk3n1KvEHl_BnVO_ # p'namwan dataset"
      ],
      "metadata": {
        "id": "v9RaLDOGwq6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kexbwe_CuWGb",
        "outputId": "e28ce089-d2bc-45a0-cfc7-37f415d9c915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp /content/drive/MyDrive/en-th.zip ."
      ],
      "metadata": {
        "id": "YAjkKm_-kbBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip en-th.zip"
      ],
      "metadata": {
        "id": "aE-jfjrQv-Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip scb-mt-en-th-2020.zip"
      ],
      "metadata": {
        "id": "NNTobO2Zk52j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install git+git://github.com/rkcosmos/deepcut.git #deepcut"
      ],
      "metadata": {
        "id": "XgPNtIwqmQMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import deepcut\n",
        "#def deepCut(df):\n",
        "   \n",
        "   #AG = []\n",
        "   #i = 0\n",
        "   \n",
        "   #for i in range(0,222733):\n",
        "      #j = deepcut.tokenize(df['th_text'][i])\n",
        "      #AG.append(j)\n",
        "      #i += 1\n",
        "   #return AG"
      ],
      "metadata": {
        "id": "KLetYyzDmJtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TM1 = deepCut(task_master_1)\n",
        "#TM1"
      ],
      "metadata": {
        "id": "K0WVpmuQpSAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TM1"
      ],
      "metadata": {
        "id": "ptk0bfh_XWoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TM1[0]"
      ],
      "metadata": {
        "id": "2YX9r5IF8l4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a = pd.DataFrame([TM1])\n",
        "#b = a.transpose()\n",
        "#b[0]"
      ],
      "metadata": {
        "id": "DvR_IgzQHdY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b[0][0]"
      ],
      "metadata": {
        "id": "9zMGzMppSswG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#c = pd.read_csv(\"/content/22k_remove.csv\")"
      ],
      "metadata": {
        "id": "frnjHpp6SHuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#c"
      ],
      "metadata": {
        "id": "0-QRjKNETXff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#d = c.drop(['Unnamed: 0'], axis=1)"
      ],
      "metadata": {
        "id": "xJl3GluVTGu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#d"
      ],
      "metadata": {
        "id": "5f8Z6FO5ThwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e['0'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8X8gQG6Na2V4",
        "outputId": "15008fc5-d580-43be-d2f5-a2282c0c22ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"'ได้', 'เลย', 'ค่ะ', ' ', 'แถว', 'ไหน', 'ดี', 'คะ', '?''\""
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e['0'][1].replace(',', '').replace(\"'\", '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_gZrcBkGcxto",
        "outputId": "0b000c4f-0bff-4849-91c4-664260c69c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ได้ เลย ค่ะ   แถว ไหน ดี คะ ?'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e['0'][0].replace(',', '')#.replace(\"'\", '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jbprO0agn1Vk",
        "outputId": "17f5280d-3b0d-42f6-9a47-302373add53c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"'สวัสดี' 'ค่ะ' ' ' 'ช่วย' 'จอง' 'ร้าน' 'อาหาร' 'เกาหลี' 'ให้' 'หน่อย' 'ได้' 'มั้ย' 'คะ' '?''\""
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e['0'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qQoQiUxVoxkb",
        "outputId": "8fd10bb6-fa01-4363-981c-9a5653df967d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"'สวัสดี', 'ค่ะ', ' ', 'ช่วย', 'จอง', 'ร้าน', 'อาหาร', 'เกาหลี', 'ให้', 'หน่อย', 'ได้', 'มั้ย', 'คะ', '?''\""
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "e['0'] = e['0'].apply(lambda x:re.sub(r\"(')\",'',x))\n",
        "e['0'] = e['0'].apply(lambda x:re.sub(r\"(,)\",'',x))\n",
        "e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "yZyYvHrNoQ_W",
        "outputId": "c45f2cbf-f69f-4144-e0f5-bb1257037d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8c53c8a0-1b9e-49c5-a71e-97a03a554b7d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>สวัสดี ค่ะ   ช่วย จอง ร้าน อาหาร เกาหลี ให้ หน...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ได้ เลย ค่ะ   แถว ไหน ดี คะ ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>แถว   ๆ   นิวยอร์ค ทาง ใต้ ก็ ได้ ค่ะ   แถว อี...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>โอเค ค่ะ   ดี เลย   มี ร้านเธอร์เดย์ คิท เช่น ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>เยี่ยม ค่ะ   อยาก ได้ โต๊ะ แปด คน ตอน ทุ่มนึง ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222728</th>\n",
              "      <td>ขอบ หนา ทั้ง   3   ถาด เลย มั้ย คะ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222729</th>\n",
              "      <td>สรุป เป็น พิซซ่าไซส์ ใหญ่ สาม ถาด นะ คะ   ทุก ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222730</th>\n",
              "      <td>ราคา ทั้งหมด   56 . 44   เหรียญ ค่ะ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222731</th>\n",
              "      <td>ค่ะ   เป็น ออเดอร์ สำหรับ ไป รับ ที่ ร้าน นะ คะ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222732</th>\n",
              "      <td>โอเค ค่ะ   ส่ง ออเดอร์ สำหรับ รับ ที่ ร้าน เรี...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>222733 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c53c8a0-1b9e-49c5-a71e-97a03a554b7d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c53c8a0-1b9e-49c5-a71e-97a03a554b7d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c53c8a0-1b9e-49c5-a71e-97a03a554b7d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                        0\n",
              "0       สวัสดี ค่ะ   ช่วย จอง ร้าน อาหาร เกาหลี ให้ หน...\n",
              "1                           ได้ เลย ค่ะ   แถว ไหน ดี คะ ?\n",
              "2       แถว   ๆ   นิวยอร์ค ทาง ใต้ ก็ ได้ ค่ะ   แถว อี...\n",
              "3       โอเค ค่ะ   ดี เลย   มี ร้านเธอร์เดย์ คิท เช่น ...\n",
              "4       เยี่ยม ค่ะ   อยาก ได้ โต๊ะ แปด คน ตอน ทุ่มนึง ...\n",
              "...                                                   ...\n",
              "222728                 ขอบ หนา ทั้ง   3   ถาด เลย มั้ย คะ\n",
              "222729  สรุป เป็น พิซซ่าไซส์ ใหญ่ สาม ถาด นะ คะ   ทุก ...\n",
              "222730                ราคา ทั้งหมด   56 . 44   เหรียญ ค่ะ\n",
              "222731    ค่ะ   เป็น ออเดอร์ สำหรับ ไป รับ ที่ ร้าน นะ คะ\n",
              "222732  โอเค ค่ะ   ส่ง ออเดอร์ สำหรับ รับ ที่ ร้าน เรี...\n",
              "\n",
              "[222733 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e['0']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfbtepDZrBCM",
        "outputId": "ac21cc9b-6b80-4fc9-a128-3a1bd1a50d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         สวัสดี ค่ะ   ช่วย จอง ร้าน อาหาร เกาหลี ให้ หน...\n",
              "1                             ได้ เลย ค่ะ   แถว ไหน ดี คะ ?\n",
              "2         แถว   ๆ   นิวยอร์ค ทาง ใต้ ก็ ได้ ค่ะ   แถว อี...\n",
              "3         โอเค ค่ะ   ดี เลย   มี ร้านเธอร์เดย์ คิท เช่น ...\n",
              "4         เยี่ยม ค่ะ   อยาก ได้ โต๊ะ แปด คน ตอน ทุ่มนึง ...\n",
              "                                ...                        \n",
              "222728                   ขอบ หนา ทั้ง   3   ถาด เลย มั้ย คะ\n",
              "222729    สรุป เป็น พิซซ่าไซส์ ใหญ่ สาม ถาด นะ คะ   ทุก ...\n",
              "222730                  ราคา ทั้งหมด   56 . 44   เหรียญ ค่ะ\n",
              "222731      ค่ะ   เป็น ออเดอร์ สำหรับ ไป รับ ที่ ร้าน นะ คะ\n",
              "222732    โอเค ค่ะ   ส่ง ออเดอร์ สำหรับ รับ ที่ ร้าน เรี...\n",
              "Name: 0, Length: 222733, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#transactions = e.iloc[:222732, :1].astype(str).values.tolist()\n",
        "#transactions"
      ],
      "metadata": {
        "id": "YY9OJZWarn8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.DataFrame([\"STD, City    State\",\n",
        "#\"33, Kolkata    West Bengal\",\n",
        "#\"44, Chennai    Tamil Nadu\",\n",
        "#\"40, Hyderabad    Telengana\",\n",
        "#\"80, Bangalore    Karnataka\"], columns=['row'])\n",
        "\n",
        "#out = pd.DataFrame(df.row.str.split(' ',2).tolist(),columns=['STD','City','State'])\n",
        "#out.drop(index=0,inplace=True)"
      ],
      "metadata": {
        "id": "IdTlE7ddyTG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e = pd.read_csv(\"/content/LST_Ver2 (1).csv\")\n",
        "e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2xtR23CyVWBv",
        "outputId": "d8f60c65-d0d5-4e58-be3e-fea04ba13680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2dabf168-98c5-4cb4-9be4-d0c064fbd9a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>en_text</th>\n",
              "      <th>th_text</th>\n",
              "      <th>th_Sep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you but i don't have enough time .</td>\n",
              "      <td>ขอบคุณแต่ฉันไม่มีเวลาพอ</td>\n",
              "      <td>ขอบคุณ แต่ ฉัน ไม่ มี เวลา พอ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>oh, you know, when i get up i usually do my st...</td>\n",
              "      <td>โอ้,คุณรู้,เมื่อฉันตื่นฉันจะออกไปเดินเล่นยืดเส...</td>\n",
              "      <td>โอ้ , คุณ รู้ , เมื่อ ฉัน ตื่น ฉัน จะ ออกไป เด...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>the duty of a policeman is to safeguard people .</td>\n",
              "      <td>หน้าที่ของตำรวจคือการปกป้องประชาชน</td>\n",
              "      <td>หน้าที่ ของ ตำรวจ คือ การ ปกป้อง ประชาชน</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>it's female vanity .</td>\n",
              "      <td>มันเป็นความโอหังของเพศหญิง</td>\n",
              "      <td>มัน เป็นความ โอหัง ของ เพศ หญิง</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>please keep a sharp lookout .</td>\n",
              "      <td>โปรดคอยดูอย่าเผลอ</td>\n",
              "      <td>โปรด คอย ดู อย่า เผลอ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681427</th>\n",
              "      <td>681427</td>\n",
              "      <td>when wijai talked to me on the phone , his voi...</td>\n",
              "      <td>ตอนวิจัยพูดโทรศัพท์กับดิฉันเสียงเขาแตกพร่าเพรา...</td>\n",
              "      <td>ตอน วิจัย พูด โทรศัพท์ กับ ดิฉัน เสียง เขา แตก...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681428</th>\n",
              "      <td>681428</td>\n",
              "      <td>the bus terminal is on the west side of the ci...</td>\n",
              "      <td>สถานีรถโดยสารทางตะวันตกของเมือง</td>\n",
              "      <td>สถานี รถ โดยสาร ทาง ตะวันตก ของ เมือง</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681429</th>\n",
              "      <td>681429</td>\n",
              "      <td>encapsulate .</td>\n",
              "      <td>ลักษณะภายนอก</td>\n",
              "      <td>ลักษณะ ภาย นอก</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681430</th>\n",
              "      <td>681430</td>\n",
              "      <td>death frightens me , specifically my own death .</td>\n",
              "      <td>ความตายทำให้ผมกลัวโดยเฉพาะอย่างยิ่งการตายของผมเอง</td>\n",
              "      <td>ความ ตาย ทำ ให้ ผม กลัว โดย เฉพาะอย่างยิ่ง การ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681431</th>\n",
              "      <td>681431</td>\n",
              "      <td>i weigh sixty kilograms .</td>\n",
              "      <td>ฉันหนักหกสิบกิโลกรัม</td>\n",
              "      <td>ฉัน หนัก หก สิบ กิโลกรัม</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>681432 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2dabf168-98c5-4cb4-9be4-d0c064fbd9a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2dabf168-98c5-4cb4-9be4-d0c064fbd9a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2dabf168-98c5-4cb4-9be4-d0c064fbd9a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Unnamed: 0                                            en_text  \\\n",
              "0                0           thank you but i don't have enough time .   \n",
              "1                1  oh, you know, when i get up i usually do my st...   \n",
              "2                2   the duty of a policeman is to safeguard people .   \n",
              "3                3                               it's female vanity .   \n",
              "4                4                      please keep a sharp lookout .   \n",
              "...            ...                                                ...   \n",
              "681427      681427  when wijai talked to me on the phone , his voi...   \n",
              "681428      681428  the bus terminal is on the west side of the ci...   \n",
              "681429      681429                                      encapsulate .   \n",
              "681430      681430   death frightens me , specifically my own death .   \n",
              "681431      681431                          i weigh sixty kilograms .   \n",
              "\n",
              "                                                  th_text  \\\n",
              "0                                 ขอบคุณแต่ฉันไม่มีเวลาพอ   \n",
              "1       โอ้,คุณรู้,เมื่อฉันตื่นฉันจะออกไปเดินเล่นยืดเส...   \n",
              "2                      หน้าที่ของตำรวจคือการปกป้องประชาชน   \n",
              "3                              มันเป็นความโอหังของเพศหญิง   \n",
              "4                                       โปรดคอยดูอย่าเผลอ   \n",
              "...                                                   ...   \n",
              "681427  ตอนวิจัยพูดโทรศัพท์กับดิฉันเสียงเขาแตกพร่าเพรา...   \n",
              "681428                    สถานีรถโดยสารทางตะวันตกของเมือง   \n",
              "681429                                       ลักษณะภายนอก   \n",
              "681430  ความตายทำให้ผมกลัวโดยเฉพาะอย่างยิ่งการตายของผมเอง   \n",
              "681431                               ฉันหนักหกสิบกิโลกรัม   \n",
              "\n",
              "                                                   th_Sep  \n",
              "0                           ขอบคุณ แต่ ฉัน ไม่ มี เวลา พอ  \n",
              "1       โอ้ , คุณ รู้ , เมื่อ ฉัน ตื่น ฉัน จะ ออกไป เด...  \n",
              "2                หน้าที่ ของ ตำรวจ คือ การ ปกป้อง ประชาชน  \n",
              "3                        มัน เป็นความ โอหัง ของ เพศ หญิง   \n",
              "4                                   โปรด คอย ดู อย่า เผลอ  \n",
              "...                                                   ...  \n",
              "681427  ตอน วิจัย พูด โทรศัพท์ กับ ดิฉัน เสียง เขา แตก...  \n",
              "681428              สถานี รถ โดยสาร ทาง ตะวันตก ของ เมือง  \n",
              "681429                                     ลักษณะ ภาย นอก  \n",
              "681430  ความ ตาย ทำ ให้ ผม กลัว โดย เฉพาะอย่างยิ่ง การ...  \n",
              "681431                          ฉัน หนัก หก สิบ กิโลกรัม   \n",
              "\n",
              "[681432 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e = e.drop(['th_text'], axis=1)\n",
        "e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "BCr_99SUZI7S",
        "outputId": "039f8cc4-1012-4cbf-ba42-365a5618d3ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dc5d70ca-a67c-4cfa-a464-37b0c3c8949c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>en_text</th>\n",
              "      <th>th_Sep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you but i don't have enough time .</td>\n",
              "      <td>ขอบคุณ แต่ ฉัน ไม่ มี เวลา พอ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>oh, you know, when i get up i usually do my st...</td>\n",
              "      <td>โอ้ , คุณ รู้ , เมื่อ ฉัน ตื่น ฉัน จะ ออกไป เด...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>the duty of a policeman is to safeguard people .</td>\n",
              "      <td>หน้าที่ ของ ตำรวจ คือ การ ปกป้อง ประชาชน</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>it's female vanity .</td>\n",
              "      <td>มัน เป็นความ โอหัง ของ เพศ หญิง</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>please keep a sharp lookout .</td>\n",
              "      <td>โปรด คอย ดู อย่า เผลอ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681427</th>\n",
              "      <td>681427</td>\n",
              "      <td>when wijai talked to me on the phone , his voi...</td>\n",
              "      <td>ตอน วิจัย พูด โทรศัพท์ กับ ดิฉัน เสียง เขา แตก...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681428</th>\n",
              "      <td>681428</td>\n",
              "      <td>the bus terminal is on the west side of the ci...</td>\n",
              "      <td>สถานี รถ โดยสาร ทาง ตะวันตก ของ เมือง</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681429</th>\n",
              "      <td>681429</td>\n",
              "      <td>encapsulate .</td>\n",
              "      <td>ลักษณะ ภาย นอก</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681430</th>\n",
              "      <td>681430</td>\n",
              "      <td>death frightens me , specifically my own death .</td>\n",
              "      <td>ความ ตาย ทำ ให้ ผม กลัว โดย เฉพาะอย่างยิ่ง การ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681431</th>\n",
              "      <td>681431</td>\n",
              "      <td>i weigh sixty kilograms .</td>\n",
              "      <td>ฉัน หนัก หก สิบ กิโลกรัม</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>681432 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc5d70ca-a67c-4cfa-a464-37b0c3c8949c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc5d70ca-a67c-4cfa-a464-37b0c3c8949c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc5d70ca-a67c-4cfa-a464-37b0c3c8949c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Unnamed: 0                                            en_text  \\\n",
              "0                0           thank you but i don't have enough time .   \n",
              "1                1  oh, you know, when i get up i usually do my st...   \n",
              "2                2   the duty of a policeman is to safeguard people .   \n",
              "3                3                               it's female vanity .   \n",
              "4                4                      please keep a sharp lookout .   \n",
              "...            ...                                                ...   \n",
              "681427      681427  when wijai talked to me on the phone , his voi...   \n",
              "681428      681428  the bus terminal is on the west side of the ci...   \n",
              "681429      681429                                      encapsulate .   \n",
              "681430      681430   death frightens me , specifically my own death .   \n",
              "681431      681431                          i weigh sixty kilograms .   \n",
              "\n",
              "                                                   th_Sep  \n",
              "0                           ขอบคุณ แต่ ฉัน ไม่ มี เวลา พอ  \n",
              "1       โอ้ , คุณ รู้ , เมื่อ ฉัน ตื่น ฉัน จะ ออกไป เด...  \n",
              "2                หน้าที่ ของ ตำรวจ คือ การ ปกป้อง ประชาชน  \n",
              "3                        มัน เป็นความ โอหัง ของ เพศ หญิง   \n",
              "4                                   โปรด คอย ดู อย่า เผลอ  \n",
              "...                                                   ...  \n",
              "681427  ตอน วิจัย พูด โทรศัพท์ กับ ดิฉัน เสียง เขา แตก...  \n",
              "681428              สถานี รถ โดยสาร ทาง ตะวันตก ของ เมือง  \n",
              "681429                                     ลักษณะ ภาย นอก  \n",
              "681430  ความ ตาย ทำ ให้ ผม กลัว โดย เฉพาะอย่างยิ่ง การ...  \n",
              "681431                          ฉัน หนัก หก สิบ กิโลกรัม   \n",
              "\n",
              "[681432 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hopethai(df):\n",
        "  \n",
        "  athit = []\n",
        "  i = 0\n",
        "  \n",
        "  for i in range(0, 681431):\n",
        "     j = df['th_Sep'][i].replace(',', '').replace(\"'\", '')\n",
        "     athit.append(j)\n",
        "     i += 1\n",
        "  return athit\n",
        "#print(hope(e)[0:6])"
      ],
      "metadata": {
        "id": "HbsfPA0ZZCT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hopefulthai = hopethai(e)\n",
        "hopefulthai[0:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgM57v_1zk4",
        "outputId": "92cdaf10-06e8-4e53-9d1a-9a539bca2bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ขอบคุณ แต่ ฉัน ไม่ มี เวลา พอ',\n",
              " 'โอ้  คุณ รู้  เมื่อ ฉัน ตื่น ฉัน จะ ออกไป เดินเล่น ยืด เส้น ยืด สาย กับ สุนัข ของ ฉัน เสมอ ',\n",
              " 'หน้าที่ ของ ตำรวจ คือ การ ปกป้อง ประชาชน',\n",
              " 'มัน เป็นความ โอหัง ของ เพศ หญิง ',\n",
              " 'โปรด คอย ดู อย่า เผลอ',\n",
              " 'ขอร้อง ให้ some body ทำ บางอย่าง',\n",
              " 'ใช้ ความ รุนแรง',\n",
              " 'ฉัน เกรง ว่า ฉัน ไม่ สามารถ มา ได้ ใน วัน นั้น',\n",
              " 'ในที่สุด ฉัน ก็มี โอกาส ได้ พบ เชอร์ เล่ย ์ เมื่อวาน นี้ เธอ และ ฉัน ทำได้ ดี ตั้งแต่ เริ่มต้น เธอ เป็น คน ตลก จริง ๆ',\n",
              " 'ไม่เป็นไร ขอบคุณ',\n",
              " 'การ ให้ ความ ยุติธรรม',\n",
              " 'การ จำ ผิด',\n",
              " 'ช่วง ต่าง สี่ หรือ ห้า โน้ต ของ เสียง ดนตรี',\n",
              " 'กระดาษ อิง ค ์ เจต H P ชั้น ยอด',\n",
              " 'เหตุการณ์ ที่ ไม่ คาดคิด มา ก่อน',\n",
              " 'กำจัด',\n",
              " 'การ กิน สินบน โดย ผู้ พิพากษา นั้น อาจ ถือ ได้ ว่า เป็นการ ทำลาย ความ ยุติธรรม',\n",
              " 'คำ ที่ มี 6 ตัว อักษร',\n",
              " 'ฉัน ปวด ฟัน และ อื่นๆ',\n",
              " 'ครึ่ง โหล']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(hopefulthai)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7rBQUpLUJB4",
        "outputId": "ff0331a6-5737-4546-cae4-3fcb83dfe9f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "681431"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hopeeng(df):\n",
        "  \n",
        "  athit = []\n",
        "  i = 0\n",
        "  \n",
        "  for i in range(0, 681431):\n",
        "     j = df['en_text'][i].replace(',', '').replace(\"'\", '')\n",
        "     athit.append(j)\n",
        "     i += 1\n",
        "  return athit\n",
        "#print(hope(e)[0:6])"
      ],
      "metadata": {
        "id": "dUg0Xv9_TVoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hopefuleng = hopeeng(e)\n",
        "hopefuleng[0:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCC_tuWYTXW3",
        "outputId": "5350f289-a1d3-4808-de89-b4d3f6cf94ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['thank you but i dont have enough time .',\n",
              " 'oh you know when i get up i usually do my stretching and walk my dog .',\n",
              " 'the duty of a policeman is to safeguard people .',\n",
              " 'its female vanity .',\n",
              " 'please keep a sharp lookout .',\n",
              " 'ask somebody to do something .',\n",
              " 'get physical .',\n",
              " 'i m afraid i can t come that day .',\n",
              " 'finally i had a chance to meet shirley yesterday she and i hit it off well from the start she is real fun .',\n",
              " 'thanks anyway .',\n",
              " 'administration of justice .',\n",
              " 'a slip of memory .',\n",
              " 'perfect interval .',\n",
              " 'hp premium inkjet paper .',\n",
              " 'an unforeseen occurrence .',\n",
              " 'do away with .',\n",
              " 'corruption among judges can be regarded as a rape of justice .',\n",
              " 'a word of six letters .',\n",
              " 'i got a toothache etc .',\n",
              " 'half a dozen .']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(hopefuleng)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ajn-ogO8T6QQ",
        "outputId": "bf5c14a9-6fc0-4f2b-df60-b26596e83c56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "681431"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#b.to_csv(\"22k.csv\")"
      ],
      "metadata": {
        "id": "wwYBL5inIvAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a = np.array(TM1)\n",
        "#a"
      ],
      "metadata": {
        "id": "MuW9UbOz3D45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#i = 0\n",
        "#a_list = TM1\n",
        "#textfile = open(\"TM1_file.txt\", \"w\")\n",
        "#for element in a_list[i]:\n",
        "    #textfile.write(element)\n",
        "    #i += 1\n",
        "#textfile.close()\n"
      ],
      "metadata": {
        "id": "k2TK1cCI5sM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "#np.savetxt(\"HOPE.csv\", \n",
        "           #a,\n",
        "           #delimiter =\"]\", \n",
        "           #fmt ='% s', encoding='utf8')"
      ],
      "metadata": {
        "id": "DEZ7DMX4wkAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GF = pd.read_csv(\"/content/HOPE.csv\", on_bad_lines = 'skip')\n",
        "#GF"
      ],
      "metadata": {
        "id": "nULP6ufI07-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b"
      ],
      "metadata": {
        "id": "zhFdzMl9JIT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#c = pd.read_csv(\"/content/22k_remove.csv\")\n",
        "#c"
      ],
      "metadata": {
        "id": "nmBYN_-7Qdyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def listToString(s): \n",
        "    \n",
        "    # initialize an empty string\n",
        "    #str1 = \" \" \n",
        "    \n",
        "    # return string  \n",
        "    #return (str1.join(s))\n",
        "        \n",
        "        \n",
        "# Driver code    \n",
        "#s = ['Geeks', 'for', 'Geeks']\n",
        "#print(listToString(s)) "
      ],
      "metadata": {
        "id": "OSy7MQ_GJ3Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#myList = TM1[0:3]\n",
        "#result = ' '.join([item for sub_list in myList for item in sub_list])"
      ],
      "metadata": {
        "id": "3JyCptlOXKNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#result"
      ],
      "metadata": {
        "id": "uHxxlyoMYIrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#assorted_government = pd.read_csv(\"/content/scb-mt-en-th-2020/assorted_government.csv\")\n",
        "#assorted_government"
      ],
      "metadata": {
        "id": "WclQa23Nmppl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#msr_paraphrase = pd.read_csv(\"/content/scb-mt-en-th-2020/msr_paraphrase.csv\")\n",
        "#msr_paraphrase"
      ],
      "metadata": {
        "id": "JAZi8aKPh-wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_master_1 = pd.read_csv(\"/content/task_master_1.csv\")\n",
        "task_master_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "dUGz2jCWbDZR",
        "outputId": "7284a219-19c4-4dc1-f9a8-85a66e94c58c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f370988f-e820-4284-ab9a-93b48423df9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en_text</th>\n",
              "      <th>th_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, I'm looking to book a table for Korean fod.</td>\n",
              "      <td>สวัสดีค่ะ ช่วยจองร้านอาหารเกาหลีให้หน่อยได้มั้...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok, what area are you thinking about?</td>\n",
              "      <td>ได้เลยค่ะ แถวไหนดีคะ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Somewhere in Southern NYC, maybe the East Vill...</td>\n",
              "      <td>แถว ๆ นิวยอร์คทางใต้ก็ได้ค่ะ แถวอีสต์วิลเลจอะไ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ok, great. There's Thursday Kitchen, it has gr...</td>\n",
              "      <td>โอเคค่ะ ดีเลย มีร้านเธอร์เดย์คิทเช่นอยู่ รีวิว...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>That's great. So I need a table for tonight at...</td>\n",
              "      <td>เยี่ยมค่ะ อยากได้โต๊ะแปดคนตอนทุ่มนึงค่ะ นั่งตร...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222728</th>\n",
              "      <td>did you want thick crust for all 3 pizzas?</td>\n",
              "      <td>ขอบหนาทั้ง 3 ถาดเลยมั้ยคะ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222729</th>\n",
              "      <td>you said you want to order 3 large pizzas, all...</td>\n",
              "      <td>สรุปเป็นพิซซ่าไซส์ใหญ่สามถาดนะคะ ทุกถาดพิเศษชี...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222730</th>\n",
              "      <td>the total for your order is $56.44.</td>\n",
              "      <td>ราคาทั้งหมด 56.44 เหรียญค่ะ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222731</th>\n",
              "      <td>Yes, can you make that for pickup, please?</td>\n",
              "      <td>ค่ะ เป็นออเดอร์สำหรับไปรับที่ร้านนะคะ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222732</th>\n",
              "      <td>great, i've submitted your order for pick up. ...</td>\n",
              "      <td>โอเคค่ะ ส่งออเดอร์สำหรับรับที่ร้านเรียบร้อยแล้...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>222733 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f370988f-e820-4284-ab9a-93b48423df9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f370988f-e820-4284-ab9a-93b48423df9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f370988f-e820-4284-ab9a-93b48423df9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  en_text  \\\n",
              "0         Hi, I'm looking to book a table for Korean fod.   \n",
              "1                   Ok, what area are you thinking about?   \n",
              "2       Somewhere in Southern NYC, maybe the East Vill...   \n",
              "3       Ok, great. There's Thursday Kitchen, it has gr...   \n",
              "4       That's great. So I need a table for tonight at...   \n",
              "...                                                   ...   \n",
              "222728         did you want thick crust for all 3 pizzas?   \n",
              "222729  you said you want to order 3 large pizzas, all...   \n",
              "222730                the total for your order is $56.44.   \n",
              "222731         Yes, can you make that for pickup, please?   \n",
              "222732  great, i've submitted your order for pick up. ...   \n",
              "\n",
              "                                                  th_text  \n",
              "0       สวัสดีค่ะ ช่วยจองร้านอาหารเกาหลีให้หน่อยได้มั้...  \n",
              "1                                   ได้เลยค่ะ แถวไหนดีคะ?  \n",
              "2       แถว ๆ นิวยอร์คทางใต้ก็ได้ค่ะ แถวอีสต์วิลเลจอะไ...  \n",
              "3       โอเคค่ะ ดีเลย มีร้านเธอร์เดย์คิทเช่นอยู่ รีวิว...  \n",
              "4       เยี่ยมค่ะ อยากได้โต๊ะแปดคนตอนทุ่มนึงค่ะ นั่งตร...  \n",
              "...                                                   ...  \n",
              "222728                          ขอบหนาทั้ง 3 ถาดเลยมั้ยคะ  \n",
              "222729  สรุปเป็นพิซซ่าไซส์ใหญ่สามถาดนะคะ ทุกถาดพิเศษชี...  \n",
              "222730                        ราคาทั้งหมด 56.44 เหรียญค่ะ  \n",
              "222731              ค่ะ เป็นออเดอร์สำหรับไปรับที่ร้านนะคะ  \n",
              "222732  โอเคค่ะ ส่งออเดอร์สำหรับรับที่ร้านเรียบร้อยแล้...  \n",
              "\n",
              "[222733 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hopeeng(df):\n",
        "  \n",
        "  athit = []\n",
        "  i = 0\n",
        "  \n",
        "  for i in range(0, 222732):\n",
        "     j = df['en_text'][i].replace(',', '').replace(\".\", '').replace(\"?\", '').replace('\"', \"\").replace(\"'\", \"\")\n",
        "     athit.append(j)\n",
        "     i += 1\n",
        "  return athit\n",
        "#print(hope(task_master_1)[0:6])"
      ],
      "metadata": {
        "id": "CmZw87VG3RgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hopefuleng = hopeeng(task_master_1)\n",
        "hopefuleng[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FZuswn54H0f",
        "outputId": "bcc3887e-6d53-480b-c75a-404554d73e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi Im looking to book a table for Korean fod',\n",
              " 'Ok what area are you thinking about',\n",
              " 'Somewhere in Southern NYC maybe the East Village',\n",
              " 'Ok great Theres Thursday Kitchen it has great reviews',\n",
              " 'Thats great So I need a table for tonight at 7 pm for 8 people We dont want to sit at the bar but anywhere else is fine',\n",
              " 'They dont have any availability for 7 pm',\n",
              " 'What times are available',\n",
              " '5 or 8',\n",
              " 'Ok do you have a second choice',\n",
              " 'Let me check',\n",
              " 'Lets try Boka are they free for 8 people at 7',\n",
              " 'Great lets book that',\n",
              " 'Ok great are there any other requests',\n",
              " 'No thats it just book',\n",
              " 'Great should I use your account you have open with them',\n",
              " 'Great You will get a confirmation to your phone soon',\n",
              " 'Hi I would like to see if the Movie What Men Want is playing here',\n",
              " 'Yes its showing here would you like to purchase a ticket',\n",
              " 'Yes for me and a friend so two tickets please',\n",
              " 'What time is that moving playing today']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(task_master_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DegqlJ98Bvc8",
        "outputId": "8be99c4a-3c1c-4f2d-85d7-b93f24df34ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "222733"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sum = pd.concat([msr_paraphrase[\"th_text\"], task_master_1[\"th_text\"],assorted_government[\"th_text\"]], axis=0)\n",
        "#sum"
      ],
      "metadata": {
        "id": "lMFWnGZVwPF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fifteenM = pd.read_csv(\"/content/drive/MyDrive/15M/15M_tatoe.csv\")\n",
        "#fifteenM"
      ],
      "metadata": {
        "id": "HwazJzc0-PuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fifteenM['source_en'].array"
      ],
      "metadata": {
        "id": "uoQu_5DV_Exs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!gdown --id 1l-LJgsqOWYzA8E1v4wjGPGfTiXWNO94v"
      ],
      "metadata": {
        "id": "Ce3A46oBj0Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATbzWIL4D28W"
      },
      "outputs": [],
      "source": [
        "#!unzip drive/MyDrive/Fairseq_Tutorial/en-th.zip -d drive/MyDrive/Fairseq_Tutorial/Copy/data/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hopefuleng[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnXcECeS5SKf",
        "outputId": "344afd15-e7fc-4bcb-e76f-205745fb3185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi Im looking to book a table for Korean fod',\n",
              " 'Ok what area are you thinking about',\n",
              " 'Somewhere in Southern NYC maybe the East Village',\n",
              " 'Ok great Theres Thursday Kitchen it has great reviews',\n",
              " 'Thats great So I need a table for tonight at 7 pm for 8 people We dont want to sit at the bar but anywhere else is fine']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hopefulthai[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx844rs_5Wdv",
        "outputId": "abd57f27-2478-4013-e20f-dd580dae7ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['สวัสดี ค่ะ   ช่วย จอง ร้าน อาหาร เกาหลี ให้ หน่อย ได้ มั้ย คะ ?',\n",
              " 'ได้ เลย ค่ะ   แถว ไหน ดี คะ ?',\n",
              " 'แถว   ๆ   นิวยอร์ค ทาง ใต้ ก็ ได้ ค่ะ   แถว อีสต์วิลเลจ อะไร งี้',\n",
              " 'โอเค ค่ะ   ดี เลย   มี ร้านเธอร์เดย์ คิท เช่น อยู่   รี วิว ดี ด้วย นะ คะ',\n",
              " 'เยี่ยม ค่ะ   อยาก ได้ โต๊ะ แปด คน ตอน ทุ่มนึง ค่ะ   นั่ง ตรง ไหน ก็ ได้ แต่ ไม่ เอา ตรง บาร์ นะ คะ']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation"
      ],
      "metadata": {
        "id": "h-IR8t5ANOth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#path = \"drive/MyDrive/Fairseq_Tutorial/Copy/data/\"\n",
        "path = \"/content/\"\n",
        "#en = open(path+\"en_translated\").read().translate(str.maketrans(\"\",\"\",punctuation.replace(\"'\",\"\"))).split(\"\\n\")\n",
        "#th = open(path+\"th_translated_neu\").read().translate(str.maketrans(\"\",\"\",punctuation.replace(\"'\",\"\"))).split(\"\\n\")"
      ],
      "metadata": {
        "id": "BY60Y3WyInfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#th"
      ],
      "metadata": {
        "id": "a9Fj5seJu_K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(en[:5])"
      ],
      "metadata": {
        "id": "-VOsPcCsL54h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(th[:5])"
      ],
      "metadata": {
        "id": "Ts_XkQ2dL-SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sel_hopefuleng, sel_hopefulthai = [],[]\n",
        "for z,t in zip(hopefuleng,hopefulthai):\n",
        "  if z.count(' ') >= 10:\n",
        "    sel_hopefuleng.append(z)\n",
        "    sel_hopefulthai.append(t.strip())"
      ],
      "metadata": {
        "id": "zgzFY1GDL_Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sel_hopefuleng)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jUibnOYt3u7",
        "outputId": "76ea4720-5937-4e94-f253-3154484f0ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71333"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sel_hopefuleng[100000:100001]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaSR3yZety2r",
        "outputId": "0c991960-cb5a-49c3-a376-00226bf96513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(hopefulthai)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbIAahTxuFRj",
        "outputId": "4f17d9c9-f7db-43ea-cd93-53cef2eee8e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "222732"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(hopefuleng)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRKXPs00uHqS",
        "outputId": "215ecd42-487c-4dee-d5dc-96f718813cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "681431"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hopefulthai[222009:222011]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yknD_okGNAht",
        "outputId": "45279fbd-9164-4384-d1f9-403e1c6c8d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ร้าน แรก ชื่อ บอมเบย์บาร์ แอนด์ กริลล์   ร้าน อาหาร อินเดีย มี สไตล์   และ มี บรรยากาศ ที่ อบอุ่น   มี ฟูลบาร์   และ อาหาร จาน พิเศษ มากมาย ค่ะ',\n",
              " 'ร้าน ที่ สอง คือ   อินเดีย   โอเว่น   ร้าน อาหาร อินเดีย บรรยากาศ สบาย ๆ   ด้วย การ ตกแต่ง ที่ แปลก ใหม่   เสิร์ฟ อาหาร แบบ ดั้งเดิม   และ มี บุฟเฟ่ต์ อาหาร กลาง วัน ค่ะ']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_en_100k = sel_en[:100000]\n",
        "# test_en_100k = sel_en[100000:110000]\n",
        "# val_en_100k = sel_en[110000:111000]\n",
        "# train_th_100k = sel_th[:100000]\n",
        "# test_th_100k = sel_th[100000:110000]\n",
        "# val_th_100k = sel_th[110000:111000]\n",
        "\n",
        "# train_en_50k = sel_en[:50000]\n",
        "# test_en_50k = sel_en[50000:55000]\n",
        "# val_en_50k = sel_en[55000:55500]\n",
        "# train_th_50k = sel_th[:50000]\n",
        "# test_th_50k = sel_th[50000:55000]\n",
        "# val_th_50k = sel_th[55000:55500]\n",
        "\n",
        "\n",
        "train_en_220k = hopefuleng[:600000]\n",
        "test_en_220k = hopefuleng[600000:680000]\n",
        "val_en_220k = hopefuleng[680000:681000]\n",
        "train_th_220k = hopefulthai[:600000]\n",
        "test_th_220k = hopefulthai[600000:680000]\n",
        "val_th_220k = hopefulthai[680000:681000]"
      ],
      "metadata": {
        "id": "EkaZdlpRPtH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open(path+\"train_en_100k\",'w').write(\"\\n\".join(train_en_100k))\n",
        "# open(path+\"test_en_100k\",'w').write(\"\\n\".join(test_en_100k))\n",
        "# open(path+\"val_en_100k\",'w').write(\"\\n\".join(val_en_100k))\n",
        "# open(path+\"train_th_100k\",'w').write(\"\\n\".join(train_th_100k))\n",
        "# open(path+\"test_th_100k\",'w').write(\"\\n\".join(test_th_100k))\n",
        "# open(path+\"val_th_100k\",'w').write(\"\\n\".join(val_th_100k))\n",
        "\n",
        "# open(path+\"train_en_50k\",'w').write(\"\\n\".join(train_en_50k))\n",
        "# open(path+\"test_en_50k\",'w').write(\"\\n\".join(test_en_50k))\n",
        "# open(path+\"val_en_50k\",'w').write(\"\\n\".join(val_en_50k))\n",
        "# open(path+\"train_th_50k\",'w').write(\"\\n\".join(train_th_50k))\n",
        "# open(path+\"test_th_50k\",'w').write(\"\\n\".join(test_th_50k))\n",
        "# open(path+\"val_th_50k\",'w').write(\"\\n\".join(val_th_50k))\n",
        "\n",
        "open(path+\"train_en_220k\",'w').write(\"\\n\".join(train_en_220k))\n",
        "open(path+\"test_en_220k\",'w').write(\"\\n\".join(test_en_220k))\n",
        "open(path+\"val_en_220k\",'w').write(\"\\n\".join(val_en_220k))\n",
        "open(path+\"train_th_220k\",'w').write(\"\\n\".join(train_th_220k))\n",
        "open(path+\"test_th_220k\",'w').write(\"\\n\".join(test_th_220k))\n",
        "open(path+\"val_th_220k\",'w').write(\"\\n\".join(val_th_220k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVmnuaZTNDmm",
        "outputId": "e94aa145-8eb2-409c-e17a-1151abe1ef5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38604"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sIkOw23ltzV",
        "outputId": "9c5b86d5-b4bb-478c-f7ee-7f8e3ed99dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install subword-nmt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX0wVCOQwvcN",
        "outputId": "b02e04c3-b80d-463f-812e-cff6b3a7d128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting subword-nmt\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from subword-nmt) (4.63.0)\n",
            "Installing collected packages: mock, subword-nmt\n",
            "Successfully installed mock-4.0.3 subword-nmt-0.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!mkdir drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe"
      ],
      "metadata": {
        "id": "gejcIYA9ww98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETGobF-09WPh",
        "outputId": "05de58e1-cf3f-4faa-f9e0-f244cad3163f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir bpe"
      ],
      "metadata": {
        "id": "-ijkwVj-lUeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!subword-nmt learn-bpe -s 200000 \\\n",
        "< train_en_220k > bpe/src.bpe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9DUlKwalaVZ",
        "outputId": "40d8bfa7-7e3c-4312-82d6-44f102a67d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 29% 57924/200000 [01:52<01:25, 1668.09it/s]no pair has frequency >= 2. Stopping\n",
            " 29% 58086/200000 [01:53<04:36, 514.01it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!subword-nmt learn-bpe -s 200000 \\\n",
        "< train_th_220k > bpe/trg.bpe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2cyhv5wlh1w",
        "outputId": "2845de34-0823-4d9a-f117-1c303ae6516d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 14% 27955/200000 [00:28<01:31, 1872.55it/s]no pair has frequency >= 2. Stopping\n",
            " 14% 28207/200000 [00:28<02:55, 979.14it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!subword-nmt apply-bpe -c bpe/src.bpe \\\n",
        "< train_en_220k > bpe/train.bpe.src\n",
        "\n",
        "!subword-nmt apply-bpe -c bpe/src.bpe \\\n",
        "< test_en_220k > bpe/test.bpe.src\n",
        "\n",
        "!subword-nmt apply-bpe -c bpe/src.bpe \\\n",
        "< val_en_220k > bpe/val.bpe.src"
      ],
      "metadata": {
        "id": "jicMYdfMlqpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!subword-nmt apply-bpe -c bpe/trg.bpe \\\n",
        "< train_th_220k > bpe/train.bpe.trg\n",
        "\n",
        "!subword-nmt apply-bpe -c bpe/trg.bpe \\\n",
        "< test_th_220k > bpe/test.bpe.trg\n",
        "\n",
        "!subword-nmt apply-bpe -c bpe/trg.bpe \\\n",
        "< val_th_220k > bpe/val.bpe.trg"
      ],
      "metadata": {
        "id": "5CXn0-gllquw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l bpe/*bpe*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYB85Sgrlqx-",
        "outputId": "bef1df95-6f4b-4fa2-9d5a-45fb32dc7fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   58087 bpe/src.bpe\n",
            "   79999 bpe/test.bpe.src\n",
            "   79999 bpe/test.bpe.trg\n",
            "  599999 bpe/train.bpe.src\n",
            "  599999 bpe/train.bpe.trg\n",
            "   28208 bpe/trg.bpe\n",
            "     999 bpe/val.bpe.src\n",
            "     999 bpe/val.bpe.trg\n",
            " 1448289 total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_gj0XdEJlq0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!subword-nmt learn-bpe -s 15000 \\\n",
        "#< drive/MyDrive/Fairseq_Tutorial/Copy/data/train_en_10k > drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/src.bpe"
      ],
      "metadata": {
        "id": "jHm0Rp0VPWyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!subword-nmt learn-bpe -s 15000 \\\n",
        "#< drive/MyDrive/Fairseq_Tutorial/Copy/data/train_th_10k > drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/trg.bpe"
      ],
      "metadata": {
        "id": "ItMf2xY1WyhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!subword-nmt apply-bpe -c drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/src.bpe \\\n",
        "#< drive/MyDrive/Fairseq_Tutorial/Copy/data/train_en_10k > drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/train.bpe.src\n",
        "\n",
        "#!subword-nmt apply-bpe -c drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/src.bpe \\\n",
        "#< drive/MyDrive/Fairseq_Tutorial/Copy/data/test_en_10k > drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/test.bpe.src\n",
        "\n",
        "#!subword-nmt apply-bpe -c drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/src.bpe \\\n",
        "#< drive/MyDrive/Fairseq_Tutorial/Copy/data/val_en_10k > drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/val.bpe.src"
      ],
      "metadata": {
        "id": "rAs_dJhDXQI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!subword-nmt apply-bpe -c drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/trg.bpe \\\n",
        "#< drive/MyDrive/Fairseq_Tutorial/Copy/data/train_th_10k > drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/train.bpe.trg\n",
        "\n",
        "#!subword-nmt apply-bpe -c drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/trg.bpe \\\n",
        "#< drive/MyDrive/Fairseq_Tutorial/Copy/data/test_th_10k > drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/test.bpe.trg\n",
        "\n",
        "#!subword-nmt apply-bpe -c drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/trg.bpe \\\n",
        "#< drive/MyDrive/Fairseq_Tutorial/Copy/data/val_th_10k > drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/val.bpe.trg"
      ],
      "metadata": {
        "id": "Pb0VfcmWY2Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!ls drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/"
      ],
      "metadata": {
        "id": "6knOdcMpZHgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!wc -l drive/MyDrive/Fairseq_Tutorial/Copy/data/bpe/*bpe*"
      ],
      "metadata": {
        "id": "spCL2Q0dZ5mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tDYBhfDPK8a",
        "outputId": "21dce5b9-c21f-49cf-8d58-9e4d17da185a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##rm -r fairseq"
      ],
      "metadata": {
        "id": "eECJOQWEPCTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pytorch/fairseq.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f13yHk60aHr_",
        "outputId": "d118ae7f-f2ce-46ee-bd8d-6a62f3503ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 31005, done.\u001b[K\n",
            "remote: Counting objects: 100% (636/636), done.\u001b[K\n",
            "remote: Compressing objects: 100% (372/372), done.\u001b[K\n",
            "remote: Total 31005 (delta 297), reused 506 (delta 254), pack-reused 30369\u001b[K\n",
            "Receiving objects: 100% (31005/31005), 21.29 MiB | 22.90 MiB/s, done.\n",
            "Resolving deltas: 100% (22996/22996), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fairseq"
      ],
      "metadata": {
        "id": "6FtOhajSepFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/fairseq/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIsg4Xi1hpk4",
        "outputId": "e74253f3-4a4a-4809-db00-8fb2823a4a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fairseq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git checkout v0.9.0\n",
        "!git checkout"
      ],
      "metadata": {
        "id": "2PPQ2jz2bYFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d39662d-816c-4171-cf00-264453193e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your branch is up to date with 'origin/main'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##%cd /content/\n",
        "##!rm -rf fairseq"
      ],
      "metadata": {
        "id": "IQ9kKVV302kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##!wget -c https://github.com/pytorch/fairseq/archive/refs/tags/v0.9.0.zip"
      ],
      "metadata": {
        "id": "bET24S4i0z_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##!unzip v0.9.0.zip"
      ],
      "metadata": {
        "id": "g51wnO580-Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##!mv fairseq-0.9.0 fairseq"
      ],
      "metadata": {
        "id": "bLo8_Ogp1GXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##%cd /content/fairseq/"
      ],
      "metadata": {
        "id": "mUfIg1XS1OmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --editable ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juv6yWiXhrUZ",
        "outputId": "f06ef301-0b0e-4a9d-d316-48bc2eef47ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting bitarray\n",
            "  Downloading bitarray-2.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (221 kB)\n",
            "\u001b[K     |████████████████████████████████| 221 kB 44.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (4.63.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (0.10.0+cu111)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (0.29.28)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (1.21.5)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (1.15.0)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (2019.12.20)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+0f078de) (5.4.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 65.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+0f078de) (3.10.0.2)\n",
            "Collecting PyYAML>=5.1.*\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 39.6 MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+0f078de) (0.8.9)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+0f078de) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+0f078de) (3.7.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=43bab234a6474fadf1b3b5e7197300cc2cb3528be28f4dcfa748faac1e07b987\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, portalocker, omegaconf, colorama, antlr4-python3-runtime, sacrebleu, hydra-core, bitarray, fairseq\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.8 bitarray-2.4.0 colorama-0.4.4 fairseq hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.4.0 sacrebleu-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-aOV5tBbdng",
        "outputId": "9908c475-e00e-46b8-b56e-a317805cc1f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade ./fairseq/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "BsuFv3sM2M3D",
        "outputId": "dd559b79-9ded-42fc-ddc7-bb44c2393074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./fairseq\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (1.21.5)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (1.15.0)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (0.10.0+cu111)\n",
            "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (1.0.7)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (2.0.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (0.29.28)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (4.63.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (1.10.0+cu111)\n",
            "Requirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (2.0.6)\n",
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (2.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+0f078de) (2019.12.20)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+0f078de) (4.8)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+0f078de) (5.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+0f078de) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+0f078de) (3.10.0.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+0f078de) (2.4.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+0f078de) (0.4.4)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+0f078de) (0.8.9)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+0f078de) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+0f078de) (3.7.0)\n",
            "Building wheels for collected packages: fairseq\n",
            "  Building wheel for fairseq (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-1.0.0a0+0f078de-cp37-cp37m-linux_x86_64.whl size=16134892 sha256=7c2430ac774334fb543f983bfcc0594f5672fd06d8273408ce38a56ceea32f28\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xb7jrob3/wheels/7c/35/80/edbd520a1a7e615df007002aeea9f6bf5f3c8f9243e072f6ce\n",
            "Successfully built fairseq\n",
            "Installing collected packages: fairseq\n",
            "Successfully installed fairseq-1.0.0a0+0f078de\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "fairseq"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd /content/fairseq/"
      ],
      "metadata": {
        "id": "jPSnOPj7m-y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/fairseq/fairseq_cli/preprocess.py \\\n",
        "--trainpref ./bpe/train.bpe -s src -t trg \\\n",
        "--testpref ./bpe/test.bpe \\\n",
        "--validpref ./bpe/val.bpe \\\n",
        "--destdir ./data_enth_bin/ \\\n",
        "--workers 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL9crnZHbm5h",
        "outputId": "81c0931a-0e01-4409-822d-89452434362b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-10 05:58:37 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2022-03-10 05:58:37 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='./data_enth_bin/', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='src', srcdict=None, suppress_crashes=False, target_lang='trg', task='translation', tensorboard_logdir=None, testpref='./bpe/test.bpe', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='./bpe/train.bpe', use_plasma_view=False, user_dir=None, validpref='./bpe/val.bpe', wandb_project=None, workers=8)\n",
            "2022-03-10 05:59:06 | INFO | fairseq_cli.preprocess | [src] Dictionary: 52656 types\n",
            "2022-03-10 05:59:33 | INFO | fairseq_cli.preprocess | [src] ./bpe/train.bpe.src: 600000 sents, 5184985 tokens, 0.0% replaced (by <unk>)\n",
            "2022-03-10 05:59:33 | INFO | fairseq_cli.preprocess | [src] Dictionary: 52656 types\n",
            "2022-03-10 05:59:34 | INFO | fairseq_cli.preprocess | [src] ./bpe/val.bpe.src: 1000 sents, 8790 tokens, 0.0683% replaced (by <unk>)\n",
            "2022-03-10 05:59:34 | INFO | fairseq_cli.preprocess | [src] Dictionary: 52656 types\n",
            "2022-03-10 05:59:38 | INFO | fairseq_cli.preprocess | [src] ./bpe/test.bpe.src: 80000 sents, 693500 tokens, 0.0495% replaced (by <unk>)\n",
            "2022-03-10 05:59:38 | INFO | fairseq_cli.preprocess | [trg] Dictionary: 21680 types\n",
            "2022-03-10 06:00:19 | INFO | fairseq_cli.preprocess | [trg] ./bpe/train.bpe.trg: 600000 sents, 5236815 tokens, 0.0% replaced (by <unk>)\n",
            "2022-03-10 06:00:19 | INFO | fairseq_cli.preprocess | [trg] Dictionary: 21680 types\n",
            "2022-03-10 06:00:19 | INFO | fairseq_cli.preprocess | [trg] ./bpe/val.bpe.trg: 1000 sents, 8803 tokens, 0.0454% replaced (by <unk>)\n",
            "2022-03-10 06:00:19 | INFO | fairseq_cli.preprocess | [trg] Dictionary: 21680 types\n",
            "2022-03-10 06:00:25 | INFO | fairseq_cli.preprocess | [trg] ./bpe/test.bpe.trg: 80000 sents, 697677 tokens, 0.0324% replaced (by <unk>)\n",
            "2022-03-10 06:00:25 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ./data_enth_bin/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/fairseq/fairseq_cli/train.py ./data_enth_bin --arch transformer_wmt_en_de \\\n",
        "--optimizer adam --clip-norm 0.0 \\\n",
        "--lr-scheduler inverse_sqrt --warmup-init-lr 1e-07 \\\n",
        "--lr 0.0007 \\\n",
        "--criterion label_smoothed_cross_entropy \\\n",
        "--label-smoothing 0.1 --max-tokens 14000 --update-freq 3 \\\n",
        "--save-interval 5 --save-interval-updates 10000 \\\n",
        "--keep-interval-updates 5 --keep-last-epochs 2 --max-update 150000 \\\n",
        "--dropout 0.1 "
      ],
      "metadata": {
        "id": "t8kqVkbReIvr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4dab4cf-1ad9-4b81-820d-b86ede339d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-10 18:44:47 | INFO | numexpr.utils | NumExpr defaulting to 4 threads.\n",
            "2022-03-10 18:44:48 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2022-03-10 18:44:51 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 14000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 14000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 150000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [3], 'lr': [0.0007], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 10000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_wmt_en_de', activation_dropout=0.0, activation_fn='relu', adam_betas=(0.9, 0.999), adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_wmt_en_de', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='./data_enth_bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0007], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=14000, max_tokens_valid=14000, max_update=150000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=5, save_interval_updates=10000, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[3], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': './data_enth_bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0007]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2022-03-10 18:44:51 | INFO | fairseq.tasks.translation | [src] dictionary: 52656 types\n",
            "2022-03-10 18:44:51 | INFO | fairseq.tasks.translation | [trg] dictionary: 21680 types\n",
            "2022-03-10 18:44:52 | INFO | fairseq_cli.train | TransformerModel(\n",
            "  (encoder): TransformerEncoderBase(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(52656, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): TransformerDecoderBase(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(21680, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (output_projection): Linear(in_features=512, out_features=21680, bias=False)\n",
            "  )\n",
            ")\n",
            "2022-03-10 18:44:53 | INFO | fairseq_cli.train | task: TranslationTask\n",
            "2022-03-10 18:44:53 | INFO | fairseq_cli.train | model: TransformerModel\n",
            "2022-03-10 18:44:53 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2022-03-10 18:44:53 | INFO | fairseq_cli.train | num. shared model params: 93,298,688 (num. trained: 93,298,688)\n",
            "2022-03-10 18:44:53 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2022-03-10 18:44:53 | INFO | fairseq.data.data_utils | loaded 1,000 examples from: ./data_enth_bin/valid.src-trg.src\n",
            "2022-03-10 18:44:53 | INFO | fairseq.data.data_utils | loaded 1,000 examples from: ./data_enth_bin/valid.src-trg.trg\n",
            "2022-03-10 18:44:53 | INFO | fairseq.tasks.translation | ./data_enth_bin valid src-trg 1000 examples\n",
            "2022-03-10 18:44:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-03-10 18:44:56 | INFO | fairseq.utils | rank   0: capabilities =  6.0  ; total memory = 15.899 GB ; name = Tesla P100-PCIE-16GB                    \n",
            "2022-03-10 18:44:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-03-10 18:44:56 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2022-03-10 18:44:56 | INFO | fairseq_cli.train | max tokens per device = 14000 and max sentences per device = None\n",
            "2022-03-10 18:44:56 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2022-03-10 18:44:57 | INFO | fairseq.trainer | Loaded checkpoint checkpoints/checkpoint_last.pt (epoch 121 @ 17880 updates)\n",
            "2022-03-10 18:44:58 | INFO | fairseq.trainer | loading train data for epoch 121\n",
            "2022-03-10 18:44:58 | INFO | fairseq.data.data_utils | loaded 600,000 examples from: ./data_enth_bin/train.src-trg.src\n",
            "2022-03-10 18:44:58 | INFO | fairseq.data.data_utils | loaded 600,000 examples from: ./data_enth_bin/train.src-trg.trg\n",
            "2022-03-10 18:44:58 | INFO | fairseq.tasks.translation | ./data_enth_bin train src-trg 600000 examples\n",
            "2022-03-10 18:44:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 121:   0% 0/149 [00:00<?, ?it/s]2022-03-10 18:44:58 | INFO | fairseq.trainer | begin training epoch 121\n",
            "2022-03-10 18:44:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/usr/local/lib/python3.7/dist-packages/fairseq/utils.py:375: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
            "epoch 121:  99% 148/149 [05:34<00:02,  2.27s/it, loss=2.124, nll_loss=0.298, ppl=1.23, wps=15596, ups=0.44, wpb=35380.3, bsz=4133.4, num_updates=18000, lr=0.000329983, gnorm=0.246, train_wall=226, gb_free=4.7, wall=275]2022-03-10 18:50:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 121 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 121 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.94it/s]\u001b[A\n",
            "epoch 121 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.95it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 18:50:34 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 4.876 | nll_loss 3.381 | ppl 10.42 | wps 12693.5 | wpb 2934.3 | bsz 333.3 | num_updates 18029 | best_loss 4.47\n",
            "2022-03-10 18:50:34 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)\n",
            "2022-03-10 18:50:34 | INFO | train | epoch 121 | loss 2.127 | nll_loss 0.3 | ppl 1.23 | wps 15598.5 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 18029 | lr 0.000329718 | gnorm 0.251 | train_wall 335 | gb_free 5.2 | wall 339\n",
            "2022-03-10 18:50:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 122:   0% 0/149 [00:00<?, ?it/s]2022-03-10 18:50:35 | INFO | fairseq.trainer | begin training epoch 122\n",
            "2022-03-10 18:50:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 122:  99% 148/149 [05:34<00:02,  2.20s/it, loss=2.126, nll_loss=0.298, ppl=1.23, wps=15383.3, ups=0.45, wpb=34555.1, bsz=3904, num_updates=18100, lr=0.00032907, gnorm=0.26, train_wall=223, gb_free=4.9, wall=500]2022-03-10 18:56:10 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 122 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 122 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  3.02it/s]\u001b[A\n",
            "epoch 122 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  4.02it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 18:56:11 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 4.9 | nll_loss 3.416 | ppl 10.67 | wps 12786 | wpb 2934.3 | bsz 333.3 | num_updates 18178 | best_loss 4.47\n",
            "2022-03-10 18:56:11 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)\n",
            "2022-03-10 18:56:11 | INFO | train | epoch 122 | loss 2.128 | nll_loss 0.301 | ppl 1.23 | wps 15575.6 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 18178 | lr 0.000328364 | gnorm 0.256 | train_wall 334 | gb_free 5.3 | wall 675\n",
            "2022-03-10 18:56:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 123:   0% 0/149 [00:00<?, ?it/s]2022-03-10 18:56:11 | INFO | fairseq.trainer | begin training epoch 123\n",
            "2022-03-10 18:56:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 123:  99% 148/149 [05:34<00:02,  2.24s/it, loss=2.125, nll_loss=0.298, ppl=1.23, wps=15829.7, ups=0.44, wpb=35777.4, bsz=4001.4, num_updates=18300, lr=0.000327267, gnorm=0.249, train_wall=226, gb_free=5.5, wall=951]2022-03-10 19:01:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 123 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 123 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  3.00it/s]\u001b[A\n",
            "epoch 123 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  4.00it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 19:01:47 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 4.867 | nll_loss 3.369 | ppl 10.33 | wps 12783.1 | wpb 2934.3 | bsz 333.3 | num_updates 18327 | best_loss 4.47\n",
            "2022-03-10 19:01:47 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)\n",
            "2022-03-10 19:01:47 | INFO | train | epoch 123 | loss 2.126 | nll_loss 0.299 | ppl 1.23 | wps 15572.2 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 18327 | lr 0.000327026 | gnorm 0.254 | train_wall 334 | gb_free 5 | wall 1011\n",
            "2022-03-10 19:01:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 124:   0% 0/149 [00:00<?, ?it/s]2022-03-10 19:01:47 | INFO | fairseq.trainer | begin training epoch 124\n",
            "2022-03-10 19:01:47 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 124:  99% 148/149 [05:34<00:02,  2.23s/it, loss=2.122, nll_loss=0.296, ppl=1.23, wps=15488.8, ups=0.44, wpb=34913.3, bsz=4150.1, num_updates=18400, lr=0.000326377, gnorm=0.244, train_wall=224, gb_free=6.3, wall=1177]2022-03-10 19:07:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 124 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 124 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.95it/s]\u001b[A\n",
            "epoch 124 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.97it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 19:07:23 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 4.859 | nll_loss 3.361 | ppl 10.28 | wps 12890.1 | wpb 2934.3 | bsz 333.3 | num_updates 18476 | best_loss 4.47\n",
            "2022-03-10 19:07:23 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)\n",
            "2022-03-10 19:07:23 | INFO | train | epoch 124 | loss 2.122 | nll_loss 0.295 | ppl 1.23 | wps 15579.3 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 18476 | lr 0.000325705 | gnorm 0.242 | train_wall 334 | gb_free 5 | wall 1347\n",
            "2022-03-10 19:07:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 125:   0% 0/149 [00:00<?, ?it/s]2022-03-10 19:07:23 | INFO | fairseq.trainer | begin training epoch 125\n",
            "2022-03-10 19:07:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 125:  99% 148/149 [05:34<00:02,  2.33s/it, loss=2.122, nll_loss=0.296, ppl=1.23, wps=15617.5, ups=0.44, wpb=35269.4, bsz=4074.6, num_updates=18600, lr=0.000324617, gnorm=0.247, train_wall=225, gb_free=4.7, wall=1627]2022-03-10 19:12:58 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 125 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 125 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.94it/s]\u001b[A\n",
            "epoch 125 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.95it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 19:12:59 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 4.871 | nll_loss 3.379 | ppl 10.4 | wps 12707.1 | wpb 2934.3 | bsz 333.3 | num_updates 18625 | best_loss 4.47\n",
            "2022-03-10 19:12:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 18625 updates\n",
            "2022-03-10 19:12:59 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/checkpoint125.pt\n",
            "2022-03-10 19:13:03 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/checkpoint125.pt\n",
            "2022-03-10 19:13:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint125.pt (epoch 125 @ 18625 updates, score 4.871) (writing took 8.905510602002323 seconds)\n",
            "2022-03-10 19:13:08 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)\n",
            "2022-03-10 19:13:08 | INFO | train | epoch 125 | loss 2.122 | nll_loss 0.296 | ppl 1.23 | wps 15179.8 | ups 0.43 | wpb 35146.4 | bsz 4026.8 | num_updates 18625 | lr 0.000324399 | gnorm 0.247 | train_wall 334 | gb_free 6.9 | wall 1692\n",
            "2022-03-10 19:13:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 126:   0% 0/149 [00:00<?, ?it/s]2022-03-10 19:13:08 | INFO | fairseq.trainer | begin training epoch 126\n",
            "2022-03-10 19:13:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 126:  99% 148/149 [05:34<00:02,  2.25s/it, loss=2.117, nll_loss=0.293, ppl=1.23, wps=15097.4, ups=0.42, wpb=35544.2, bsz=4152.9, num_updates=18700, lr=0.000323748, gnorm=0.242, train_wall=225, gb_free=5, wall=1863]2022-03-10 19:18:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 126 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 126 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.89it/s]\u001b[A\n",
            "epoch 126 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.92it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 19:18:44 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 4.867 | nll_loss 3.375 | ppl 10.38 | wps 12939.7 | wpb 2934.3 | bsz 333.3 | num_updates 18774 | best_loss 4.47\n",
            "2022-03-10 19:18:44 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)\n",
            "2022-03-10 19:18:44 | INFO | train | epoch 126 | loss 2.12 | nll_loss 0.295 | ppl 1.23 | wps 15573.1 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 18774 | lr 0.000323109 | gnorm 0.247 | train_wall 334 | gb_free 5 | wall 2029\n",
            "2022-03-10 19:18:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 127:   0% 0/149 [00:00<?, ?it/s]2022-03-10 19:18:45 | INFO | fairseq.trainer | begin training epoch 127\n",
            "2022-03-10 19:18:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 127:  99% 148/149 [05:34<00:02,  2.32s/it, loss=2.117, nll_loss=0.292, ppl=1.22, wps=15605.9, ups=0.44, wpb=35166, bsz=3950.3, num_updates=18900, lr=0.000322031, gnorm=0.244, train_wall=225, gb_free=5.5, wall=2313]2022-03-10 19:24:20 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 127 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 127 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.97it/s]\u001b[A\n",
            "epoch 127 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.98it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 19:24:21 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 4.866 | nll_loss 3.369 | ppl 10.33 | wps 12755 | wpb 2934.3 | bsz 333.3 | num_updates 18923 | best_loss 4.47\n",
            "2022-03-10 19:24:21 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)\n",
            "2022-03-10 19:24:21 | INFO | train | epoch 127 | loss 2.119 | nll_loss 0.294 | ppl 1.23 | wps 15557.7 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 18923 | lr 0.000321835 | gnorm 0.244 | train_wall 334 | gb_free 5.2 | wall 2365\n",
            "2022-03-10 19:24:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 128:   0% 0/149 [00:00<?, ?it/s]2022-03-10 19:24:21 | INFO | fairseq.trainer | begin training epoch 128\n",
            "2022-03-10 19:24:21 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 128:  99% 148/149 [05:34<00:02,  2.28s/it, loss=2.122, nll_loss=0.297, ppl=1.23, wps=15570.1, ups=0.44, wpb=35215.7, bsz=4229.4, num_updates=19000, lr=0.000321182, gnorm=0.253, train_wall=225, gb_free=4.7, wall=2539]2022-03-10 19:29:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 128 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 128 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.33it/s]\u001b[A\n",
            "epoch 128 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.46it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 19:29:57 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 4.856 | nll_loss 3.359 | ppl 10.26 | wps 12778 | wpb 2934.3 | bsz 333.3 | num_updates 19072 | best_loss 4.47\n",
            "2022-03-10 19:29:57 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)\n",
            "2022-03-10 19:29:57 | INFO | train | epoch 128 | loss 2.119 | nll_loss 0.294 | ppl 1.23 | wps 15582.4 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 19072 | lr 0.000320575 | gnorm 0.252 | train_wall 334 | gb_free 7.1 | wall 2701\n",
            "2022-03-10 19:29:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 129:   0% 0/149 [00:00<?, ?it/s]2022-03-10 19:29:57 | INFO | fairseq.trainer | begin training epoch 129\n",
            "2022-03-10 19:29:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 129:  99% 148/149 [05:34<00:02,  2.35s/it, loss=2.117, nll_loss=0.292, ppl=1.22, wps=15642.4, ups=0.44, wpb=35222.8, bsz=3987.1, num_updates=19200, lr=0.000319505, gnorm=0.239, train_wall=225, gb_free=5.7, wall=2991]2022-03-10 19:35:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 129 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 129 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.97it/s]\u001b[A\n",
            "epoch 129 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.97it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 19:35:33 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 4.865 | nll_loss 3.381 | ppl 10.42 | wps 12899.9 | wpb 2934.3 | bsz 333.3 | num_updates 19221 | best_loss 4.47\n",
            "2022-03-10 19:35:33 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)\n",
            "2022-03-10 19:35:33 | INFO | train | epoch 129 | loss 2.117 | nll_loss 0.292 | ppl 1.22 | wps 15572.8 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 19221 | lr 0.00031933 | gnorm 0.243 | train_wall 334 | gb_free 6.6 | wall 3038\n",
            "2022-03-10 19:35:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 130:   0% 0/149 [00:00<?, ?it/s]2022-03-10 19:35:34 | INFO | fairseq.trainer | begin training epoch 130\n",
            "2022-03-10 19:35:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 130:  99% 148/149 [05:34<00:02,  2.21s/it, loss=2.112, nll_loss=0.287, ppl=1.22, wps=15468.7, ups=0.44, wpb=35097.4, bsz=4005.7, num_updates=19300, lr=0.000318676, gnorm=0.245, train_wall=225, gb_free=5.3, wall=3218]2022-03-10 19:41:09 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 130 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 130 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.91it/s]\u001b[A\n",
            "epoch 130 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.93it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 19:41:10 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 4.885 | nll_loss 3.4 | ppl 10.56 | wps 12760 | wpb 2934.3 | bsz 333.3 | num_updates 19370 | best_loss 4.47\n",
            "2022-03-10 19:41:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 19370 updates\n",
            "2022-03-10 19:41:10 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/checkpoint130.pt\n",
            "2022-03-10 19:41:13 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/checkpoint130.pt\n",
            "2022-03-10 19:41:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint130.pt (epoch 130 @ 19370 updates, score 4.885) (writing took 9.054816544005007 seconds)\n",
            "2022-03-10 19:41:19 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)\n",
            "2022-03-10 19:41:19 | INFO | train | epoch 130 | loss 2.117 | nll_loss 0.293 | ppl 1.22 | wps 15161 | ups 0.43 | wpb 35146.4 | bsz 4026.8 | num_updates 19370 | lr 0.0003181 | gnorm 0.247 | train_wall 334 | gb_free 6.5 | wall 3383\n",
            "2022-03-10 19:41:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 131:   0% 0/149 [00:00<?, ?it/s]2022-03-10 19:41:19 | INFO | fairseq.trainer | begin training epoch 131\n",
            "2022-03-10 19:41:19 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 131:  99% 148/149 [05:34<00:02,  2.26s/it, loss=2.118, nll_loss=0.295, ppl=1.23, wps=15641.3, ups=0.44, wpb=35419, bsz=4106.2, num_updates=19500, lr=0.000317038, gnorm=0.243, train_wall=226, gb_free=5.2, wall=3678]2022-03-10 19:46:54 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 131 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 131 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.95it/s]\u001b[A\n",
            "epoch 131 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.96it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 19:46:55 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 4.87 | nll_loss 3.373 | ppl 10.36 | wps 12739 | wpb 2934.3 | bsz 333.3 | num_updates 19519 | best_loss 4.47\n",
            "2022-03-10 19:46:55 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)\n",
            "2022-03-10 19:46:55 | INFO | train | epoch 131 | loss 2.118 | nll_loss 0.294 | ppl 1.23 | wps 15577.4 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 19519 | lr 0.000316883 | gnorm 0.246 | train_wall 334 | gb_free 5.4 | wall 3719\n",
            "2022-03-10 19:46:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 132:   0% 0/149 [00:00<?, ?it/s]2022-03-10 19:46:55 | INFO | fairseq.trainer | begin training epoch 132\n",
            "2022-03-10 19:46:55 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 132:  99% 148/149 [05:34<00:02,  2.23s/it, loss=2.115, nll_loss=0.291, ppl=1.22, wps=15553.9, ups=0.44, wpb=35004, bsz=4153.8, num_updates=19600, lr=0.000316228, gnorm=0.243, train_wall=223, gb_free=5.1, wall=3903]2022-03-10 19:52:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 132 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 132 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.95it/s]\u001b[A\n",
            "epoch 132 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.97it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 19:52:31 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 4.843 | nll_loss 3.359 | ppl 10.26 | wps 12788.9 | wpb 2934.3 | bsz 333.3 | num_updates 19668 | best_loss 4.47\n",
            "2022-03-10 19:52:31 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)\n",
            "2022-03-10 19:52:31 | INFO | train | epoch 132 | loss 2.114 | nll_loss 0.29 | ppl 1.22 | wps 15570.1 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 19668 | lr 0.000315681 | gnorm 0.241 | train_wall 334 | gb_free 5.3 | wall 4055\n",
            "2022-03-10 19:52:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 133:   0% 0/149 [00:00<?, ?it/s]2022-03-10 19:52:32 | INFO | fairseq.trainer | begin training epoch 133\n",
            "2022-03-10 19:52:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 133:  99% 148/149 [05:34<00:02,  2.29s/it, loss=2.108, nll_loss=0.285, ppl=1.22, wps=15678.3, ups=0.44, wpb=35277.5, bsz=3877.1, num_updates=19800, lr=0.000314627, gnorm=0.235, train_wall=225, gb_free=4.7, wall=4354]2022-03-10 19:58:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 133 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 133 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.93it/s]\u001b[A\n",
            "epoch 133 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.95it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 19:58:08 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 4.889 | nll_loss 3.402 | ppl 10.57 | wps 12799.9 | wpb 2934.3 | bsz 333.3 | num_updates 19817 | best_loss 4.47\n",
            "2022-03-10 19:58:08 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)\n",
            "2022-03-10 19:58:08 | INFO | train | epoch 133 | loss 2.112 | nll_loss 0.289 | ppl 1.22 | wps 15565.1 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 19817 | lr 0.000314492 | gnorm 0.237 | train_wall 334 | gb_free 5 | wall 4392\n",
            "2022-03-10 19:58:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 134:   0% 0/149 [00:00<?, ?it/s]2022-03-10 19:58:08 | INFO | fairseq.trainer | begin training epoch 134\n",
            "2022-03-10 19:58:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 134:  99% 148/149 [05:34<00:02,  2.17s/it, loss=2.109, nll_loss=0.287, ppl=1.22, wps=15548.5, ups=0.44, wpb=35308.8, bsz=4139.1, num_updates=19900, lr=0.000313835, gnorm=0.235, train_wall=225, gb_free=5, wall=4581]2022-03-10 20:03:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 134 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 134 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.95it/s]\u001b[A\n",
            "epoch 134 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.96it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 20:03:44 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 4.874 | nll_loss 3.385 | ppl 10.44 | wps 12699.8 | wpb 2934.3 | bsz 333.3 | num_updates 19966 | best_loss 4.47\n",
            "2022-03-10 20:03:44 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)\n",
            "2022-03-10 20:03:44 | INFO | train | epoch 134 | loss 2.112 | nll_loss 0.288 | ppl 1.22 | wps 15567.1 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 19966 | lr 0.000313316 | gnorm 0.244 | train_wall 335 | gb_free 5 | wall 4728\n",
            "2022-03-10 20:03:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 135:   0% 0/149 [00:00<?, ?it/s]2022-03-10 20:03:44 | INFO | fairseq.trainer | begin training epoch 135\n",
            "2022-03-10 20:03:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 135:  22% 33/149 [01:14<04:21,  2.26s/it]2022-03-10 20:05:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 135 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 135 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.95it/s]\u001b[A\n",
            "epoch 135 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.96it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 20:05:02 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 4.881 | nll_loss 3.401 | ppl 10.56 | wps 12754.2 | wpb 2934.3 | bsz 333.3 | num_updates 20000 | best_loss 4.47\n",
            "2022-03-10 20:05:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 20000 updates\n",
            "2022-03-10 20:05:02 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/checkpoint_135_20000.pt\n",
            "2022-03-10 20:05:06 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/checkpoint_135_20000.pt\n",
            "2022-03-10 20:05:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint_135_20000.pt (epoch 135 @ 20000 updates, score 4.881) (writing took 9.26854302999709 seconds)\n",
            "epoch 135:  99% 148/149 [05:44<00:02,  2.27s/it, loss=2.109, nll_loss=0.286, ppl=1.22, wps=15018.7, ups=0.42, wpb=35451.9, bsz=4046, num_updates=20100, lr=0.00031227, gnorm=0.235, train_wall=226, gb_free=5.5, wall=5041]2022-03-10 20:09:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 135 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 135 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.90it/s]\u001b[A\n",
            "epoch 135 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.92it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 20:09:31 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 4.897 | nll_loss 3.411 | ppl 10.64 | wps 12758.7 | wpb 2934.3 | bsz 333.3 | num_updates 20115 | best_loss 4.47\n",
            "2022-03-10 20:09:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 20115 updates\n",
            "2022-03-10 20:09:31 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/checkpoint135.pt\n",
            "2022-03-10 20:09:34 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/checkpoint135.pt\n",
            "2022-03-10 20:09:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint135.pt (epoch 135 @ 20115 updates, score 4.897) (writing took 8.257221054002002 seconds)\n",
            "2022-03-10 20:09:39 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)\n",
            "2022-03-10 20:09:39 | INFO | train | epoch 135 | loss 2.11 | nll_loss 0.287 | ppl 1.22 | wps 14759.7 | ups 0.42 | wpb 35146.4 | bsz 4026.8 | num_updates 20115 | lr 0.000312153 | gnorm 0.241 | train_wall 334 | gb_free 6.6 | wall 5083\n",
            "2022-03-10 20:09:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 136:   0% 0/149 [00:00<?, ?it/s]2022-03-10 20:09:39 | INFO | fairseq.trainer | begin training epoch 136\n",
            "2022-03-10 20:09:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 136:  99% 148/149 [05:34<00:02,  2.32s/it, loss=2.115, nll_loss=0.292, ppl=1.22, wps=14881, ups=0.43, wpb=34944.3, bsz=4101, num_updates=20200, lr=0.000311496, gnorm=0.262, train_wall=225, gb_free=5.7, wall=5276]2022-03-10 20:15:15 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 136 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 136 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.90it/s]\u001b[A\n",
            "epoch 136 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.93it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 20:15:15 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 4.904 | nll_loss 3.416 | ppl 10.67 | wps 12812.9 | wpb 2934.3 | bsz 333.3 | num_updates 20264 | best_loss 4.47\n",
            "2022-03-10 20:15:15 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)\n",
            "2022-03-10 20:15:15 | INFO | train | epoch 136 | loss 2.117 | nll_loss 0.294 | ppl 1.23 | wps 15565.4 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 20264 | lr 0.000311004 | gnorm 0.253 | train_wall 334 | gb_free 6.8 | wall 5420\n",
            "2022-03-10 20:15:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 137:   0% 0/149 [00:00<?, ?it/s]2022-03-10 20:15:16 | INFO | fairseq.trainer | begin training epoch 137\n",
            "2022-03-10 20:15:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 137:  99% 148/149 [05:34<00:02,  2.33s/it, loss=2.114, nll_loss=0.291, ppl=1.22, wps=15536.1, ups=0.44, wpb=34956, bsz=4004.3, num_updates=20400, lr=0.000309965, gnorm=0.255, train_wall=225, gb_free=5, wall=5727]2022-03-10 20:20:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 137 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 137 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  3.00it/s]\u001b[A\n",
            "epoch 137 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  4.00it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 20:20:52 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 4.855 | nll_loss 3.368 | ppl 10.33 | wps 12655.1 | wpb 2934.3 | bsz 333.3 | num_updates 20413 | best_loss 4.47\n",
            "2022-03-10 20:20:52 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)\n",
            "2022-03-10 20:20:52 | INFO | train | epoch 137 | loss 2.111 | nll_loss 0.288 | ppl 1.22 | wps 15553 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 20413 | lr 0.000309866 | gnorm 0.248 | train_wall 334 | gb_free 5.2 | wall 5756\n",
            "2022-03-10 20:20:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 138:   0% 0/149 [00:00<?, ?it/s]2022-03-10 20:20:52 | INFO | fairseq.trainer | begin training epoch 138\n",
            "2022-03-10 20:20:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 138:  99% 148/149 [05:35<00:02,  2.26s/it, loss=2.107, nll_loss=0.283, ppl=1.22, wps=15516.3, ups=0.44, wpb=35046.7, bsz=3925.4, num_updates=20500, lr=0.000309208, gnorm=0.238, train_wall=224, gb_free=5.3, wall=5953]2022-03-10 20:26:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 138 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 138 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.95it/s]\u001b[A\n",
            "epoch 138 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.97it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 20:26:28 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 4.924 | nll_loss 3.436 | ppl 10.82 | wps 12893.3 | wpb 2934.3 | bsz 333.3 | num_updates 20562 | best_loss 4.47\n",
            "2022-03-10 20:26:28 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)\n",
            "2022-03-10 20:26:28 | INFO | train | epoch 138 | loss 2.109 | nll_loss 0.286 | ppl 1.22 | wps 15568.1 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 20562 | lr 0.000308742 | gnorm 0.241 | train_wall 334 | gb_free 10.2 | wall 6093\n",
            "2022-03-10 20:26:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 139:   0% 0/149 [00:00<?, ?it/s]2022-03-10 20:26:29 | INFO | fairseq.trainer | begin training epoch 139\n",
            "2022-03-10 20:26:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 139:  99% 148/149 [05:34<00:02,  2.31s/it, loss=2.109, nll_loss=0.287, ppl=1.22, wps=15671.4, ups=0.44, wpb=35518.5, bsz=4056.9, num_updates=20700, lr=0.000307711, gnorm=0.235, train_wall=226, gb_free=5.2, wall=6405]2022-03-10 20:32:04 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 139 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 139 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.99it/s]\u001b[A\n",
            "epoch 139 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.99it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 20:32:05 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 4.879 | nll_loss 3.393 | ppl 10.5 | wps 12784.8 | wpb 2934.3 | bsz 333.3 | num_updates 20711 | best_loss 4.47\n",
            "2022-03-10 20:32:05 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)\n",
            "2022-03-10 20:32:05 | INFO | train | epoch 139 | loss 2.11 | nll_loss 0.288 | ppl 1.22 | wps 15559.8 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 20711 | lr 0.000307629 | gnorm 0.246 | train_wall 334 | gb_free 6.1 | wall 6429\n",
            "2022-03-10 20:32:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 140:   0% 0/149 [00:00<?, ?it/s]2022-03-10 20:32:05 | INFO | fairseq.trainer | begin training epoch 140\n",
            "2022-03-10 20:32:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 140:  99% 148/149 [05:34<00:02,  2.17s/it, loss=2.104, nll_loss=0.282, ppl=1.22, wps=15576.4, ups=0.44, wpb=35358.6, bsz=4055.2, num_updates=20800, lr=0.00030697, gnorm=0.234, train_wall=225, gb_free=4.9, wall=6632]2022-03-10 20:37:41 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 140 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 140 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.90it/s]\u001b[A\n",
            "epoch 140 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.92it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 20:37:42 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 4.893 | nll_loss 3.407 | ppl 10.6 | wps 12676 | wpb 2934.3 | bsz 333.3 | num_updates 20860 | best_loss 4.47\n",
            "2022-03-10 20:37:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 20860 updates\n",
            "2022-03-10 20:37:42 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/checkpoint140.pt\n",
            "2022-03-10 20:37:45 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/checkpoint140.pt\n",
            "2022-03-10 20:37:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint140.pt (epoch 140 @ 20860 updates, score 4.893) (writing took 8.382130785998015 seconds)\n",
            "2022-03-10 20:37:50 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)\n",
            "2022-03-10 20:37:50 | INFO | train | epoch 140 | loss 2.105 | nll_loss 0.283 | ppl 1.22 | wps 15167.3 | ups 0.43 | wpb 35146.4 | bsz 4026.8 | num_updates 20860 | lr 0.000306529 | gnorm 0.232 | train_wall 334 | gb_free 5.4 | wall 6774\n",
            "2022-03-10 20:37:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 141:   0% 0/149 [00:00<?, ?it/s]2022-03-10 20:37:51 | INFO | fairseq.trainer | begin training epoch 141\n",
            "2022-03-10 20:37:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 141:  99% 148/149 [05:34<00:02,  2.29s/it, loss=2.106, nll_loss=0.284, ppl=1.22, wps=15612.9, ups=0.44, wpb=35106.4, bsz=3941.8, num_updates=21000, lr=0.000305505, gnorm=0.239, train_wall=224, gb_free=5, wall=7091]2022-03-10 20:43:26 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 141 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 141 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  3.00it/s]\u001b[A\n",
            "epoch 141 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  4.00it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 20:43:27 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 4.901 | nll_loss 3.418 | ppl 10.69 | wps 12743.8 | wpb 2934.3 | bsz 333.3 | num_updates 21009 | best_loss 4.47\n",
            "2022-03-10 20:43:27 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)\n",
            "2022-03-10 20:43:27 | INFO | train | epoch 141 | loss 2.103 | nll_loss 0.282 | ppl 1.22 | wps 15567.6 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 21009 | lr 0.00030544 | gnorm 0.233 | train_wall 334 | gb_free 4.9 | wall 7111\n",
            "2022-03-10 20:43:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 142:   0% 0/149 [00:00<?, ?it/s]2022-03-10 20:43:27 | INFO | fairseq.trainer | begin training epoch 142\n",
            "2022-03-10 20:43:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 142:  99% 148/149 [05:34<00:02,  2.29s/it, loss=2.098, nll_loss=0.276, ppl=1.21, wps=15605.5, ups=0.44, wpb=35427.3, bsz=4007.9, num_updates=21100, lr=0.00030478, gnorm=0.225, train_wall=225, gb_free=4.7, wall=7318]2022-03-10 20:49:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 142 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 142 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.90it/s]\u001b[A\n",
            "epoch 142 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.92it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 20:49:03 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 4.878 | nll_loss 3.392 | ppl 10.5 | wps 12830.4 | wpb 2934.3 | bsz 333.3 | num_updates 21158 | best_loss 4.47\n",
            "2022-03-10 20:49:03 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)\n",
            "2022-03-10 20:49:03 | INFO | train | epoch 142 | loss 2.102 | nll_loss 0.281 | ppl 1.21 | wps 15568.9 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 21158 | lr 0.000304362 | gnorm 0.23 | train_wall 334 | gb_free 5.7 | wall 7447\n",
            "2022-03-10 20:49:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 143:   0% 0/149 [00:00<?, ?it/s]2022-03-10 20:49:03 | INFO | fairseq.trainer | begin training epoch 143\n",
            "2022-03-10 20:49:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 143:  99% 148/149 [05:34<00:02,  2.25s/it, loss=2.107, nll_loss=0.286, ppl=1.22, wps=15731, ups=0.44, wpb=35602.7, bsz=4078.8, num_updates=21300, lr=0.000303346, gnorm=0.239, train_wall=226, gb_free=4.6, wall=7769]2022-03-10 20:54:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 143 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 143 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.94it/s]\u001b[A\n",
            "epoch 143 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.95it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 20:54:40 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 4.882 | nll_loss 3.393 | ppl 10.5 | wps 12831.7 | wpb 2934.3 | bsz 333.3 | num_updates 21307 | best_loss 4.47\n",
            "2022-03-10 20:54:40 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)\n",
            "2022-03-10 20:54:40 | INFO | train | epoch 143 | loss 2.103 | nll_loss 0.282 | ppl 1.22 | wps 15562.2 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 21307 | lr 0.000303296 | gnorm 0.238 | train_wall 334 | gb_free 6.4 | wall 7784\n",
            "2022-03-10 20:54:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 144:   0% 0/149 [00:00<?, ?it/s]2022-03-10 20:54:40 | INFO | fairseq.trainer | begin training epoch 144\n",
            "2022-03-10 20:54:40 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 144:  99% 148/149 [05:34<00:02,  2.35s/it, loss=2.105, nll_loss=0.284, ppl=1.22, wps=15290.6, ups=0.45, wpb=34175.2, bsz=3979.5, num_updates=21400, lr=0.000302636, gnorm=0.258, train_wall=222, gb_free=4.7, wall=7992]2022-03-10 21:00:15 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 144 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 144 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.87it/s]\u001b[A\n",
            "epoch 144 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.90it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 21:00:16 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 4.922 | nll_loss 3.442 | ppl 10.87 | wps 12710.3 | wpb 2934.3 | bsz 333.3 | num_updates 21456 | best_loss 4.47\n",
            "2022-03-10 21:00:16 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)\n",
            "2022-03-10 21:00:16 | INFO | train | epoch 144 | loss 2.104 | nll_loss 0.283 | ppl 1.22 | wps 15571.7 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 21456 | lr 0.000302241 | gnorm 0.246 | train_wall 334 | gb_free 5 | wall 8120\n",
            "2022-03-10 21:00:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 145:   0% 0/149 [00:00<?, ?it/s]2022-03-10 21:00:16 | INFO | fairseq.trainer | begin training epoch 145\n",
            "2022-03-10 21:00:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 145:  99% 148/149 [05:34<00:02,  2.26s/it, loss=2.107, nll_loss=0.287, ppl=1.22, wps=15770.3, ups=0.44, wpb=35560.4, bsz=4130.3, num_updates=21600, lr=0.000301232, gnorm=0.237, train_wall=225, gb_free=4.9, wall=8446]2022-03-10 21:05:52 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 145 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 145 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.93it/s]\u001b[A\n",
            "epoch 145 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.95it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 21:05:52 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 4.919 | nll_loss 3.441 | ppl 10.86 | wps 12775.1 | wpb 2934.3 | bsz 333.3 | num_updates 21605 | best_loss 4.47\n",
            "2022-03-10 21:05:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 21605 updates\n",
            "2022-03-10 21:05:52 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/checkpoint145.pt\n",
            "2022-03-10 21:05:56 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/checkpoint145.pt\n",
            "2022-03-10 21:06:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint145.pt (epoch 145 @ 21605 updates, score 4.919) (writing took 8.163377134005714 seconds)\n",
            "2022-03-10 21:06:01 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)\n",
            "2022-03-10 21:06:01 | INFO | train | epoch 145 | loss 2.101 | nll_loss 0.28 | ppl 1.21 | wps 15191.9 | ups 0.43 | wpb 35146.4 | bsz 4026.8 | num_updates 21605 | lr 0.000301197 | gnorm 0.234 | train_wall 334 | gb_free 5 | wall 8465\n",
            "2022-03-10 21:06:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 146:   0% 0/149 [00:00<?, ?it/s]2022-03-10 21:06:01 | INFO | fairseq.trainer | begin training epoch 146\n",
            "2022-03-10 21:06:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 146:  99% 148/149 [05:34<00:02,  2.35s/it, loss=2.091, nll_loss=0.27, ppl=1.21, wps=15149.4, ups=0.42, wpb=35649.7, bsz=4046.9, num_updates=21700, lr=0.000300537, gnorm=0.221, train_wall=225, gb_free=5, wall=8681]2022-03-10 21:11:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 146 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 146 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.98it/s]\u001b[A\n",
            "epoch 146 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.98it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 21:11:37 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 4.903 | nll_loss 3.425 | ppl 10.74 | wps 12759.6 | wpb 2934.3 | bsz 333.3 | num_updates 21754 | best_loss 4.47\n",
            "2022-03-10 21:11:37 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)\n",
            "2022-03-10 21:11:37 | INFO | train | epoch 146 | loss 2.1 | nll_loss 0.279 | ppl 1.21 | wps 15569.2 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 21754 | lr 0.000300164 | gnorm 0.232 | train_wall 334 | gb_free 5.4 | wall 8801\n",
            "2022-03-10 21:11:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 147:   0% 0/149 [00:00<?, ?it/s]2022-03-10 21:11:37 | INFO | fairseq.trainer | begin training epoch 147\n",
            "2022-03-10 21:11:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 147:  99% 148/149 [05:34<00:02,  2.23s/it, loss=2.101, nll_loss=0.281, ppl=1.21, wps=15714.4, ups=0.44, wpb=35354.9, bsz=3975.7, num_updates=21900, lr=0.000299162, gnorm=0.233, train_wall=225, gb_free=4.7, wall=9132]2022-03-10 21:17:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 147 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 147 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.99it/s]\u001b[A\n",
            "epoch 147 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.99it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 21:17:13 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 4.904 | nll_loss 3.42 | ppl 10.7 | wps 12671.1 | wpb 2934.3 | bsz 333.3 | num_updates 21903 | best_loss 4.47\n",
            "2022-03-10 21:17:13 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)\n",
            "2022-03-10 21:17:13 | INFO | train | epoch 147 | loss 2.099 | nll_loss 0.279 | ppl 1.21 | wps 15568.7 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 21903 | lr 0.000299141 | gnorm 0.232 | train_wall 334 | gb_free 6 | wall 9137\n",
            "2022-03-10 21:17:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 148:   0% 0/149 [00:00<?, ?it/s]2022-03-10 21:17:14 | INFO | fairseq.trainer | begin training epoch 148\n",
            "2022-03-10 21:17:14 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 148:  99% 148/149 [05:34<00:02,  2.23s/it, loss=2.095, nll_loss=0.275, ppl=1.21, wps=15512.3, ups=0.44, wpb=35105.9, bsz=4016, num_updates=22000, lr=0.000298481, gnorm=0.242, train_wall=225, gb_free=5.2, wall=9358]2022-03-10 21:22:49 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 148 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 148 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.95it/s]\u001b[A\n",
            "epoch 148 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.96it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 21:22:50 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 4.882 | nll_loss 3.398 | ppl 10.54 | wps 12807.3 | wpb 2934.3 | bsz 333.3 | num_updates 22052 | best_loss 4.47\n",
            "2022-03-10 21:22:50 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)\n",
            "2022-03-10 21:22:50 | INFO | train | epoch 148 | loss 2.099 | nll_loss 0.279 | ppl 1.21 | wps 15571.3 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 22052 | lr 0.000298129 | gnorm 0.241 | train_wall 334 | gb_free 5 | wall 9474\n",
            "2022-03-10 21:22:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 149:   0% 0/149 [00:00<?, ?it/s]2022-03-10 21:22:50 | INFO | fairseq.trainer | begin training epoch 149\n",
            "2022-03-10 21:22:50 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 149:  99% 148/149 [05:34<00:02,  2.20s/it, loss=2.101, nll_loss=0.281, ppl=1.22, wps=15655.3, ups=0.44, wpb=35207, bsz=3994.6, num_updates=22200, lr=0.000297133, gnorm=0.235, train_wall=225, gb_free=5, wall=9809]    2022-03-10 21:28:26 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 149 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 149 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  3.00it/s]\u001b[A\n",
            "epoch 149 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  4.00it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 21:28:26 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 4.912 | nll_loss 3.431 | ppl 10.78 | wps 12712.3 | wpb 2934.3 | bsz 333.3 | num_updates 22201 | best_loss 4.47\n",
            "2022-03-10 21:28:26 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)\n",
            "2022-03-10 21:28:26 | INFO | train | epoch 149 | loss 2.097 | nll_loss 0.278 | ppl 1.21 | wps 15559 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 22201 | lr 0.000297127 | gnorm 0.23 | train_wall 334 | gb_free 7.2 | wall 9810\n",
            "2022-03-10 21:28:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 150:   0% 0/149 [00:00<?, ?it/s]2022-03-10 21:28:27 | INFO | fairseq.trainer | begin training epoch 150\n",
            "2022-03-10 21:28:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 150:  99% 148/149 [05:34<00:02,  2.27s/it, loss=2.092, nll_loss=0.272, ppl=1.21, wps=15328.9, ups=0.44, wpb=34719.9, bsz=3976.3, num_updates=22300, lr=0.000296466, gnorm=0.227, train_wall=225, gb_free=5, wall=10036]2022-03-10 21:34:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 150 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 150 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.96it/s]\u001b[A\n",
            "epoch 150 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.97it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 21:34:03 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 4.907 | nll_loss 3.426 | ppl 10.75 | wps 12771.4 | wpb 2934.3 | bsz 333.3 | num_updates 22350 | best_loss 4.47\n",
            "2022-03-10 21:34:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 22350 updates\n",
            "2022-03-10 21:34:03 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/checkpoint150.pt\n",
            "2022-03-10 21:34:06 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/checkpoint150.pt\n",
            "2022-03-10 21:34:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint150.pt (epoch 150 @ 22350 updates, score 4.907) (writing took 8.314731400998426 seconds)\n",
            "2022-03-10 21:34:11 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)\n",
            "2022-03-10 21:34:11 | INFO | train | epoch 150 | loss 2.096 | nll_loss 0.277 | ppl 1.21 | wps 15182.6 | ups 0.43 | wpb 35146.4 | bsz 4026.8 | num_updates 22350 | lr 0.000296135 | gnorm 0.229 | train_wall 334 | gb_free 5.6 | wall 10155\n",
            "2022-03-10 21:34:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 151:   0% 0/149 [00:00<?, ?it/s]2022-03-10 21:34:12 | INFO | fairseq.trainer | begin training epoch 151\n",
            "2022-03-10 21:34:12 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 151:  99% 148/149 [05:34<00:02,  2.29s/it, loss=2.097, nll_loss=0.278, ppl=1.21, wps=15118.9, ups=0.43, wpb=35273.4, bsz=4161, num_updates=22400, lr=0.000295804, gnorm=0.229, train_wall=223, gb_free=4.6, wall=10269]2022-03-10 21:39:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 151 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 151 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  3.00it/s]\u001b[A\n",
            "epoch 151 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  4.00it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 21:39:48 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 4.884 | nll_loss 3.405 | ppl 10.59 | wps 12728.1 | wpb 2934.3 | bsz 333.3 | num_updates 22499 | best_loss 4.47\n",
            "2022-03-10 21:39:48 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)\n",
            "2022-03-10 21:39:48 | INFO | train | epoch 151 | loss 2.096 | nll_loss 0.276 | ppl 1.21 | wps 15563.3 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 22499 | lr 0.000295152 | gnorm 0.234 | train_wall 334 | gb_free 5.8 | wall 10492\n",
            "2022-03-10 21:39:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 152:   0% 0/149 [00:00<?, ?it/s]2022-03-10 21:39:48 | INFO | fairseq.trainer | begin training epoch 152\n",
            "2022-03-10 21:39:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 152:  99% 148/149 [05:34<00:02,  2.29s/it, loss=2.092, nll_loss=0.272, ppl=1.21, wps=15771.9, ups=0.44, wpb=35822.2, bsz=4070.6, num_updates=22600, lr=0.000294492, gnorm=0.227, train_wall=227, gb_free=4.6, wall=10722]2022-03-10 21:45:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 152 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 152 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.90it/s]\u001b[A\n",
            "epoch 152 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.93it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 21:45:24 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 4.916 | nll_loss 3.436 | ppl 10.82 | wps 12719.7 | wpb 2934.3 | bsz 333.3 | num_updates 22648 | best_loss 4.47\n",
            "2022-03-10 21:45:24 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)\n",
            "2022-03-10 21:45:24 | INFO | train | epoch 152 | loss 2.094 | nll_loss 0.275 | ppl 1.21 | wps 15559.7 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 22648 | lr 0.00029418 | gnorm 0.23 | train_wall 334 | gb_free 7.1 | wall 10828\n",
            "2022-03-10 21:45:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 153:   0% 0/149 [00:00<?, ?it/s]2022-03-10 21:45:24 | INFO | fairseq.trainer | begin training epoch 153\n",
            "2022-03-10 21:45:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 153:  99% 148/149 [05:34<00:02,  2.22s/it, loss=2.093, nll_loss=0.274, ppl=1.21, wps=15349.4, ups=0.45, wpb=34347.2, bsz=3974.2, num_updates=22700, lr=0.000293843, gnorm=0.227, train_wall=222, gb_free=4.9, wall=10946]2022-03-10 21:51:00 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 153 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 153 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.94it/s]\u001b[A\n",
            "epoch 153 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.95it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 21:51:01 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 4.892 | nll_loss 3.409 | ppl 10.62 | wps 12710.7 | wpb 2934.3 | bsz 333.3 | num_updates 22797 | best_loss 4.47\n",
            "2022-03-10 21:51:01 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)\n",
            "2022-03-10 21:51:01 | INFO | train | epoch 153 | loss 2.093 | nll_loss 0.275 | ppl 1.21 | wps 15561.2 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 22797 | lr 0.000293217 | gnorm 0.225 | train_wall 334 | gb_free 5 | wall 11165\n",
            "2022-03-10 21:51:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 154:   0% 0/149 [00:00<?, ?it/s]2022-03-10 21:51:01 | INFO | fairseq.trainer | begin training epoch 154\n",
            "2022-03-10 21:51:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 154:  99% 148/149 [05:34<00:02,  2.29s/it, loss=2.09, nll_loss=0.272, ppl=1.21, wps=15656.4, ups=0.44, wpb=35265.3, bsz=4059.1, num_updates=22900, lr=0.000292557, gnorm=0.226, train_wall=225, gb_free=4.6, wall=11398]2022-03-10 21:56:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 154 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 154 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.97it/s]\u001b[A\n",
            "epoch 154 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.98it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 21:56:37 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 4.9 | nll_loss 3.422 | ppl 10.72 | wps 12726.6 | wpb 2934.3 | bsz 333.3 | num_updates 22946 | best_loss 4.47\n",
            "2022-03-10 21:56:37 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)\n",
            "2022-03-10 21:56:37 | INFO | train | epoch 154 | loss 2.092 | nll_loss 0.273 | ppl 1.21 | wps 15568.7 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 22946 | lr 0.000292263 | gnorm 0.228 | train_wall 334 | gb_free 6.2 | wall 11501\n",
            "2022-03-10 21:56:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 155:   0% 0/149 [00:00<?, ?it/s]2022-03-10 21:56:37 | INFO | fairseq.trainer | begin training epoch 155\n",
            "2022-03-10 21:56:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 155:  99% 148/149 [05:34<00:02,  2.26s/it, loss=2.093, nll_loss=0.274, ppl=1.21, wps=15403.9, ups=0.44, wpb=34813.8, bsz=4028.7, num_updates=23000, lr=0.00029192, gnorm=0.229, train_wall=224, gb_free=4.7, wall=11624]2022-03-10 22:02:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 155 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 155 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.93it/s]\u001b[A\n",
            "epoch 155 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.95it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 22:02:14 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 4.898 | nll_loss 3.421 | ppl 10.71 | wps 12754.3 | wpb 2934.3 | bsz 333.3 | num_updates 23095 | best_loss 4.47\n",
            "2022-03-10 22:02:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 23095 updates\n",
            "2022-03-10 22:02:14 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/checkpoint155.pt\n",
            "2022-03-10 22:02:17 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/checkpoint155.pt\n",
            "2022-03-10 22:02:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint155.pt (epoch 155 @ 23095 updates, score 4.898) (writing took 8.267921785998624 seconds)\n",
            "2022-03-10 22:02:22 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)\n",
            "2022-03-10 22:02:22 | INFO | train | epoch 155 | loss 2.092 | nll_loss 0.274 | ppl 1.21 | wps 15184 | ups 0.43 | wpb 35146.4 | bsz 4026.8 | num_updates 23095 | lr 0.000291319 | gnorm 0.227 | train_wall 334 | gb_free 5.7 | wall 11846\n",
            "2022-03-10 22:02:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 156:   0% 0/149 [00:00<?, ?it/s]2022-03-10 22:02:22 | INFO | fairseq.trainer | begin training epoch 156\n",
            "2022-03-10 22:02:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 156:  99% 148/149 [05:34<00:02,  2.21s/it, loss=2.087, nll_loss=0.269, ppl=1.21, wps=15512.8, ups=0.44, wpb=35104.5, bsz=4011, num_updates=23200, lr=0.000290659, gnorm=0.223, train_wall=226, gb_free=5, wall=12084]2022-03-10 22:07:58 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 156 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 156 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.98it/s]\u001b[A\n",
            "epoch 156 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.99it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 22:07:58 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 4.904 | nll_loss 3.425 | ppl 10.74 | wps 12781.5 | wpb 2934.3 | bsz 333.3 | num_updates 23244 | best_loss 4.47\n",
            "2022-03-10 22:07:58 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)\n",
            "2022-03-10 22:07:58 | INFO | train | epoch 156 | loss 2.091 | nll_loss 0.273 | ppl 1.21 | wps 15575.7 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 23244 | lr 0.000290384 | gnorm 0.224 | train_wall 334 | gb_free 5.5 | wall 12182\n",
            "2022-03-10 22:07:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 157:   0% 0/149 [00:00<?, ?it/s]2022-03-10 22:07:59 | INFO | fairseq.trainer | begin training epoch 157\n",
            "2022-03-10 22:07:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 157:  99% 148/149 [05:34<00:02,  2.33s/it, loss=2.091, nll_loss=0.273, ppl=1.21, wps=15623.1, ups=0.44, wpb=35170.9, bsz=4049.4, num_updates=23300, lr=0.000290035, gnorm=0.223, train_wall=223, gb_free=5.1, wall=12309]2022-03-10 22:13:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 157 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 157 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.96it/s]\u001b[A\n",
            "epoch 157 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.97it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 22:13:35 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 4.898 | nll_loss 3.423 | ppl 10.72 | wps 12741 | wpb 2934.3 | bsz 333.3 | num_updates 23393 | best_loss 4.47\n",
            "2022-03-10 22:13:35 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)\n",
            "2022-03-10 22:13:35 | INFO | train | epoch 157 | loss 2.09 | nll_loss 0.273 | ppl 1.21 | wps 15563.9 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 23393 | lr 0.000289458 | gnorm 0.225 | train_wall 334 | gb_free 6.8 | wall 12519\n",
            "2022-03-10 22:13:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 158:   0% 0/149 [00:00<?, ?it/s]2022-03-10 22:13:35 | INFO | fairseq.trainer | begin training epoch 158\n",
            "2022-03-10 22:13:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 158:  99% 148/149 [05:34<00:02,  2.25s/it, loss=2.088, nll_loss=0.27, ppl=1.21, wps=15692.3, ups=0.44, wpb=35439.1, bsz=4071.3, num_updates=23500, lr=0.000288798, gnorm=0.221, train_wall=225, gb_free=4.6, wall=12761]2022-03-10 22:19:10 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 158 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 158 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  3.00it/s]\u001b[A\n",
            "epoch 158 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.97it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 22:19:11 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 4.941 | nll_loss 3.468 | ppl 11.07 | wps 12626.6 | wpb 2934.3 | bsz 333.3 | num_updates 23542 | best_loss 4.47\n",
            "2022-03-10 22:19:11 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)\n",
            "2022-03-10 22:19:11 | INFO | train | epoch 158 | loss 2.09 | nll_loss 0.272 | ppl 1.21 | wps 15579.1 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 23542 | lr 0.00028854 | gnorm 0.225 | train_wall 334 | gb_free 5.1 | wall 12855\n",
            "2022-03-10 22:19:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 159:   0% 0/149 [00:00<?, ?it/s]2022-03-10 22:19:11 | INFO | fairseq.trainer | begin training epoch 159\n",
            "2022-03-10 22:19:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 159:  99% 148/149 [05:34<00:02,  2.28s/it, loss=2.086, nll_loss=0.269, ppl=1.2, wps=15532.2, ups=0.44, wpb=35180.6, bsz=4040.3, num_updates=23600, lr=0.000288185, gnorm=0.224, train_wall=225, gb_free=4.7, wall=12988]2022-03-10 22:24:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 159 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 159 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.97it/s]\u001b[A\n",
            "epoch 159 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.98it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 22:24:47 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 4.933 | nll_loss 3.456 | ppl 10.97 | wps 12697.9 | wpb 2934.3 | bsz 333.3 | num_updates 23691 | best_loss 4.47\n",
            "2022-03-10 22:24:47 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)\n",
            "2022-03-10 22:24:47 | INFO | train | epoch 159 | loss 2.089 | nll_loss 0.272 | ppl 1.21 | wps 15575 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 23691 | lr 0.000287631 | gnorm 0.228 | train_wall 334 | gb_free 5.9 | wall 13191\n",
            "2022-03-10 22:24:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 160:   0% 0/149 [00:00<?, ?it/s]2022-03-10 22:24:47 | INFO | fairseq.trainer | begin training epoch 160\n",
            "2022-03-10 22:24:47 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 160:  99% 148/149 [05:34<00:02,  2.25s/it, loss=2.084, nll_loss=0.267, ppl=1.2, wps=15746, ups=0.44, wpb=35798.6, bsz=4108, num_updates=23800, lr=0.000286972, gnorm=0.221, train_wall=227, gb_free=5.5, wall=13440]2022-03-10 22:30:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 160 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 160 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.97it/s]\u001b[A\n",
            "epoch 160 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.98it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 22:30:23 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 4.932 | nll_loss 3.453 | ppl 10.95 | wps 12823.6 | wpb 2934.3 | bsz 333.3 | num_updates 23840 | best_loss 4.47\n",
            "2022-03-10 22:30:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 23840 updates\n",
            "2022-03-10 22:30:23 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/checkpoint160.pt\n",
            "2022-03-10 22:30:27 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/checkpoint160.pt\n",
            "2022-03-10 22:30:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint160.pt (epoch 160 @ 23840 updates, score 4.932) (writing took 8.184263686998747 seconds)\n",
            "2022-03-10 22:30:32 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)\n",
            "2022-03-10 22:30:32 | INFO | train | epoch 160 | loss 2.088 | nll_loss 0.271 | ppl 1.21 | wps 15198.9 | ups 0.43 | wpb 35146.4 | bsz 4026.8 | num_updates 23840 | lr 0.000286731 | gnorm 0.226 | train_wall 334 | gb_free 5.7 | wall 13536\n",
            "2022-03-10 22:30:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 161:   0% 0/149 [00:00<?, ?it/s]2022-03-10 22:30:32 | INFO | fairseq.trainer | begin training epoch 161\n",
            "2022-03-10 22:30:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 161:  99% 148/149 [05:34<00:02,  2.27s/it, loss=2.088, nll_loss=0.271, ppl=1.21, wps=14975.5, ups=0.43, wpb=34851.1, bsz=4027.5, num_updates=23900, lr=0.000286371, gnorm=0.226, train_wall=223, gb_free=4.6, wall=13672]2022-03-10 22:36:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 161 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 161 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.95it/s]\u001b[A\n",
            "epoch 161 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.96it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 22:36:08 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 4.943 | nll_loss 3.469 | ppl 11.07 | wps 12750.3 | wpb 2934.3 | bsz 333.3 | num_updates 23989 | best_loss 4.47\n",
            "2022-03-10 22:36:08 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)\n",
            "2022-03-10 22:36:08 | INFO | train | epoch 161 | loss 2.087 | nll_loss 0.27 | ppl 1.21 | wps 15567.3 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 23989 | lr 0.000285839 | gnorm 0.224 | train_wall 334 | gb_free 5.9 | wall 13872\n",
            "2022-03-10 22:36:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 162:   0% 0/149 [00:00<?, ?it/s]2022-03-10 22:36:08 | INFO | fairseq.trainer | begin training epoch 162\n",
            "2022-03-10 22:36:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 162:  99% 148/149 [05:34<00:02,  2.26s/it, loss=2.092, nll_loss=0.276, ppl=1.21, wps=15539.3, ups=0.45, wpb=34913.2, bsz=4186.6, num_updates=24100, lr=0.00028518, gnorm=0.226, train_wall=224, gb_free=4.6, wall=14123]2022-03-10 22:41:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 162 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 162 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.94it/s]\u001b[A\n",
            "epoch 162 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.95it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 22:41:45 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 4.936 | nll_loss 3.464 | ppl 11.04 | wps 12727.9 | wpb 2934.3 | bsz 333.3 | num_updates 24138 | best_loss 4.47\n",
            "2022-03-10 22:41:45 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)\n",
            "2022-03-10 22:41:45 | INFO | train | epoch 162 | loss 2.089 | nll_loss 0.272 | ppl 1.21 | wps 15559.8 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 24138 | lr 0.000284956 | gnorm 0.225 | train_wall 334 | gb_free 5.4 | wall 14209\n",
            "2022-03-10 22:41:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 163:   0% 0/149 [00:00<?, ?it/s]2022-03-10 22:41:45 | INFO | fairseq.trainer | begin training epoch 163\n",
            "2022-03-10 22:41:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 163:  99% 148/149 [05:34<00:02,  2.32s/it, loss=2.08, nll_loss=0.263, ppl=1.2, wps=15552, ups=0.44, wpb=35215.8, bsz=3890.4, num_updates=24200, lr=0.00028459, gnorm=0.217, train_wall=225, gb_free=5.1, wall=14349]2022-03-10 22:47:20 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 163 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 163 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.92it/s]\u001b[A\n",
            "epoch 163 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.94it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 22:47:21 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 4.926 | nll_loss 3.452 | ppl 10.95 | wps 12885.9 | wpb 2934.3 | bsz 333.3 | num_updates 24287 | best_loss 4.47\n",
            "2022-03-10 22:47:21 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)\n",
            "2022-03-10 22:47:21 | INFO | train | epoch 163 | loss 2.086 | nll_loss 0.269 | ppl 1.21 | wps 15568.2 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 24287 | lr 0.00028408 | gnorm 0.223 | train_wall 334 | gb_free 5.6 | wall 14545\n",
            "2022-03-10 22:47:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 164:   0% 0/149 [00:00<?, ?it/s]2022-03-10 22:47:21 | INFO | fairseq.trainer | begin training epoch 164\n",
            "2022-03-10 22:47:21 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 164:  99% 148/149 [05:34<00:02,  2.20s/it, loss=2.083, nll_loss=0.265, ppl=1.2, wps=15719.6, ups=0.44, wpb=35412, bsz=4019.1, num_updates=24400, lr=0.000283422, gnorm=0.214, train_wall=225, gb_free=5.4, wall=14801]2022-03-10 22:52:57 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 164 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 164 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.87it/s]\u001b[A\n",
            "epoch 164 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.91it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 22:52:57 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 4.918 | nll_loss 3.448 | ppl 10.92 | wps 12705.9 | wpb 2934.3 | bsz 333.3 | num_updates 24436 | best_loss 4.47\n",
            "2022-03-10 22:52:57 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)\n",
            "2022-03-10 22:52:57 | INFO | train | epoch 164 | loss 2.084 | nll_loss 0.267 | ppl 1.2 | wps 15567.8 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 24436 | lr 0.000283213 | gnorm 0.219 | train_wall 334 | gb_free 6.2 | wall 14881\n",
            "2022-03-10 22:52:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 165:   0% 0/149 [00:00<?, ?it/s]2022-03-10 22:52:58 | INFO | fairseq.trainer | begin training epoch 165\n",
            "2022-03-10 22:52:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 165:  99% 148/149 [05:34<00:02,  2.32s/it, loss=2.085, nll_loss=0.269, ppl=1.2, wps=15586.2, ups=0.44, wpb=35240.8, bsz=3932.2, num_updates=24500, lr=0.000282843, gnorm=0.224, train_wall=224, gb_free=5.3, wall=15028]2022-03-10 22:58:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 165 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 165 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.92it/s]\u001b[A\n",
            "epoch 165 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.94it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 22:58:34 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 4.957 | nll_loss 3.488 | ppl 11.22 | wps 12773.1 | wpb 2934.3 | bsz 333.3 | num_updates 24585 | best_loss 4.47\n",
            "2022-03-10 22:58:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 24585 updates\n",
            "2022-03-10 22:58:34 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/checkpoint165.pt\n",
            "2022-03-10 22:58:37 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/checkpoint165.pt\n",
            "2022-03-10 22:58:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint165.pt (epoch 165 @ 24585 updates, score 4.957) (writing took 8.353450558992336 seconds)\n",
            "2022-03-10 22:58:42 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)\n",
            "2022-03-10 22:58:42 | INFO | train | epoch 165 | loss 2.085 | nll_loss 0.269 | ppl 1.21 | wps 15184 | ups 0.43 | wpb 35146.4 | bsz 4026.8 | num_updates 24585 | lr 0.000282353 | gnorm 0.232 | train_wall 334 | gb_free 7.1 | wall 15226\n",
            "2022-03-10 22:58:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 166:   0% 0/149 [00:00<?, ?it/s]2022-03-10 22:58:43 | INFO | fairseq.trainer | begin training epoch 166\n",
            "2022-03-10 22:58:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 166:  99% 148/149 [05:34<00:02,  2.20s/it, loss=2.1, nll_loss=0.283, ppl=1.22, wps=15757.4, ups=0.44, wpb=35672.9, bsz=4229.8, num_updates=24700, lr=0.000281695, gnorm=0.237, train_wall=226, gb_free=4.8, wall=15487]2022-03-10 23:04:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 166 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 166 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.99it/s]\u001b[A\n",
            "epoch 166 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.99it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 23:04:19 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 4.954 | nll_loss 3.483 | ppl 11.18 | wps 12729.2 | wpb 2934.3 | bsz 333.3 | num_updates 24734 | best_loss 4.47\n",
            "2022-03-10 23:04:19 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)\n",
            "2022-03-10 23:04:19 | INFO | train | epoch 166 | loss 2.098 | nll_loss 0.281 | ppl 1.21 | wps 15567.9 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 24734 | lr 0.000281502 | gnorm 0.243 | train_wall 334 | gb_free 7.2 | wall 15563\n",
            "2022-03-10 23:04:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 167:   0% 0/149 [00:00<?, ?it/s]2022-03-10 23:04:19 | INFO | fairseq.trainer | begin training epoch 167\n",
            "2022-03-10 23:04:19 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 167:  99% 148/149 [05:34<00:02,  2.29s/it, loss=2.085, nll_loss=0.268, ppl=1.2, wps=15435.7, ups=0.45, wpb=34620.4, bsz=3837.8, num_updates=24800, lr=0.000281127, gnorm=0.227, train_wall=223, gb_free=5.4, wall=15711]2022-03-10 23:09:54 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 167 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 167 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.91it/s]\u001b[A\n",
            "epoch 167 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.93it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 23:09:55 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 4.913 | nll_loss 3.443 | ppl 10.87 | wps 12776 | wpb 2934.3 | bsz 333.3 | num_updates 24883 | best_loss 4.47\n",
            "2022-03-10 23:09:55 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)\n",
            "2022-03-10 23:09:55 | INFO | train | epoch 167 | loss 2.087 | nll_loss 0.27 | ppl 1.21 | wps 15568.3 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 24883 | lr 0.000280658 | gnorm 0.222 | train_wall 334 | gb_free 5.4 | wall 15899\n",
            "2022-03-10 23:09:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 168:   0% 0/149 [00:00<?, ?it/s]2022-03-10 23:09:55 | INFO | fairseq.trainer | begin training epoch 168\n",
            "2022-03-10 23:09:55 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 168:  99% 148/149 [05:34<00:02,  2.25s/it, loss=2.082, nll_loss=0.266, ppl=1.2, wps=15536.4, ups=0.44, wpb=35036.7, bsz=3945.9, num_updates=25000, lr=0.00028, gnorm=0.219, train_wall=225, gb_free=4.8, wall=16163]2022-03-10 23:15:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 168 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 168 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.91it/s]\u001b[A\n",
            "epoch 168 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.93it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 23:15:31 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 4.923 | nll_loss 3.453 | ppl 10.95 | wps 12838.1 | wpb 2934.3 | bsz 333.3 | num_updates 25032 | best_loss 4.47\n",
            "2022-03-10 23:15:31 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)\n",
            "2022-03-10 23:15:31 | INFO | train | epoch 168 | loss 2.084 | nll_loss 0.268 | ppl 1.2 | wps 15571.8 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 25032 | lr 0.000279821 | gnorm 0.221 | train_wall 334 | gb_free 5.7 | wall 16235\n",
            "2022-03-10 23:15:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 169:   0% 0/149 [00:00<?, ?it/s]2022-03-10 23:15:32 | INFO | fairseq.trainer | begin training epoch 169\n",
            "2022-03-10 23:15:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 169:  99% 148/149 [05:34<00:02,  2.29s/it, loss=2.082, nll_loss=0.267, ppl=1.2, wps=15639.2, ups=0.44, wpb=35655.3, bsz=4118.3, num_updates=25100, lr=0.000279442, gnorm=0.219, train_wall=226, gb_free=4.7, wall=16391]2022-03-10 23:21:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 169 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 169 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  3.00it/s]\u001b[A\n",
            "epoch 169 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  4.00it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 23:21:08 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 4.935 | nll_loss 3.465 | ppl 11.04 | wps 12750.1 | wpb 2934.3 | bsz 333.3 | num_updates 25181 | best_loss 4.47\n",
            "2022-03-10 23:21:08 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)\n",
            "2022-03-10 23:21:08 | INFO | train | epoch 169 | loss 2.082 | nll_loss 0.266 | ppl 1.2 | wps 15561.2 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 25181 | lr 0.000278992 | gnorm 0.222 | train_wall 334 | gb_free 5.2 | wall 16572\n",
            "2022-03-10 23:21:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 170:   0% 0/149 [00:00<?, ?it/s]2022-03-10 23:21:08 | INFO | fairseq.trainer | begin training epoch 170\n",
            "2022-03-10 23:21:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 170:  99% 148/149 [05:34<00:02,  2.23s/it, loss=2.077, nll_loss=0.262, ppl=1.2, wps=15717.5, ups=0.44, wpb=35410.5, bsz=4012.7, num_updates=25300, lr=0.000278335, gnorm=0.209, train_wall=225, gb_free=6.4, wall=16842]2022-03-10 23:26:43 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 170 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 170 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.98it/s]\u001b[A\n",
            "epoch 170 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.98it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 23:26:44 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 4.923 | nll_loss 3.451 | ppl 10.93 | wps 12759.7 | wpb 2934.3 | bsz 333.3 | num_updates 25330 | best_loss 4.47\n",
            "2022-03-10 23:26:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 25330 updates\n",
            "2022-03-10 23:26:44 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/checkpoint170.pt\n",
            "2022-03-10 23:26:48 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/checkpoint170.pt\n",
            "2022-03-10 23:26:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint170.pt (epoch 170 @ 25330 updates, score 4.923) (writing took 8.340559295000276 seconds)\n",
            "2022-03-10 23:26:53 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)\n",
            "2022-03-10 23:26:53 | INFO | train | epoch 170 | loss 2.08 | nll_loss 0.264 | ppl 1.2 | wps 15188 | ups 0.43 | wpb 35146.4 | bsz 4026.8 | num_updates 25330 | lr 0.00027817 | gnorm 0.214 | train_wall 334 | gb_free 5.6 | wall 16917\n",
            "2022-03-10 23:26:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 171:   0% 0/149 [00:00<?, ?it/s]2022-03-10 23:26:53 | INFO | fairseq.trainer | begin training epoch 171\n",
            "2022-03-10 23:26:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 171:  99% 148/149 [05:34<00:02,  2.29s/it, loss=2.08, nll_loss=0.264, ppl=1.2, wps=14760.5, ups=0.43, wpb=34470.2, bsz=3999, num_updates=25400, lr=0.000277787, gnorm=0.221, train_wall=223, gb_free=4.9, wall=17075]2022-03-10 23:32:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 171 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 171 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.95it/s]\u001b[A\n",
            "epoch 171 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.96it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 23:32:29 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 4.923 | nll_loss 3.455 | ppl 10.97 | wps 12733.3 | wpb 2934.3 | bsz 333.3 | num_updates 25479 | best_loss 4.47\n",
            "2022-03-10 23:32:29 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)\n",
            "2022-03-10 23:32:29 | INFO | train | epoch 171 | loss 2.08 | nll_loss 0.264 | ppl 1.2 | wps 15572.2 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 25479 | lr 0.000277356 | gnorm 0.217 | train_wall 334 | gb_free 5.2 | wall 17253\n",
            "2022-03-10 23:32:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 172:   0% 0/149 [00:00<?, ?it/s]2022-03-10 23:32:29 | INFO | fairseq.trainer | begin training epoch 172\n",
            "2022-03-10 23:32:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 172:  99% 148/149 [05:34<00:02,  2.22s/it, loss=2.078, nll_loss=0.263, ppl=1.2, wps=15732, ups=0.44, wpb=35446.3, bsz=3924.2, num_updates=25600, lr=0.000276699, gnorm=0.213, train_wall=225, gb_free=5.5, wall=17528]2022-03-10 23:38:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 172 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 172 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.92it/s]\u001b[A\n",
            "epoch 172 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.94it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 23:38:05 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 4.941 | nll_loss 3.478 | ppl 11.14 | wps 12706.4 | wpb 2934.3 | bsz 333.3 | num_updates 25628 | best_loss 4.47\n",
            "2022-03-10 23:38:05 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)\n",
            "2022-03-10 23:38:05 | INFO | train | epoch 172 | loss 2.078 | nll_loss 0.263 | ppl 1.2 | wps 15565.7 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 25628 | lr 0.000276548 | gnorm 0.214 | train_wall 334 | gb_free 6.4 | wall 17589\n",
            "2022-03-10 23:38:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 173:   0% 0/149 [00:00<?, ?it/s]2022-03-10 23:38:06 | INFO | fairseq.trainer | begin training epoch 173\n",
            "2022-03-10 23:38:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 173:  99% 148/149 [05:34<00:02,  2.22s/it, loss=2.073, nll_loss=0.258, ppl=1.2, wps=15468.9, ups=0.44, wpb=35003.2, bsz=4074.6, num_updates=25700, lr=0.00027616, gnorm=0.206, train_wall=224, gb_free=5.3, wall=17754]2022-03-10 23:43:41 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 173 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 173 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.96it/s]\u001b[A\n",
            "epoch 173 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.97it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 23:43:42 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 4.934 | nll_loss 3.471 | ppl 11.09 | wps 12739.6 | wpb 2934.3 | bsz 333.3 | num_updates 25777 | best_loss 4.47\n",
            "2022-03-10 23:43:42 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)\n",
            "2022-03-10 23:43:42 | INFO | train | epoch 173 | loss 2.077 | nll_loss 0.262 | ppl 1.2 | wps 15556 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 25777 | lr 0.000275748 | gnorm 0.212 | train_wall 334 | gb_free 6.2 | wall 17926\n",
            "2022-03-10 23:43:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 174:   0% 0/149 [00:00<?, ?it/s]2022-03-10 23:43:42 | INFO | fairseq.trainer | begin training epoch 174\n",
            "2022-03-10 23:43:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 174:  99% 148/149 [05:34<00:02,  2.24s/it, loss=2.08, nll_loss=0.265, ppl=1.2, wps=15561.4, ups=0.44, wpb=35031, bsz=4135.7, num_updates=25900, lr=0.000275092, gnorm=0.216, train_wall=225, gb_free=4.9, wall=18204]2022-03-10 23:49:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 174 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 174 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.92it/s]\u001b[A\n",
            "epoch 174 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.94it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 23:49:18 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 4.941 | nll_loss 3.473 | ppl 11.11 | wps 12732.2 | wpb 2934.3 | bsz 333.3 | num_updates 25926 | best_loss 4.47\n",
            "2022-03-10 23:49:18 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)\n",
            "2022-03-10 23:49:18 | INFO | train | epoch 174 | loss 2.078 | nll_loss 0.263 | ppl 1.2 | wps 15574.7 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 25926 | lr 0.000274954 | gnorm 0.215 | train_wall 334 | gb_free 4.9 | wall 18262\n",
            "2022-03-10 23:49:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 175:   0% 0/149 [00:00<?, ?it/s]2022-03-10 23:49:19 | INFO | fairseq.trainer | begin training epoch 175\n",
            "2022-03-10 23:49:19 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 175:  99% 148/149 [05:34<00:02,  2.30s/it, loss=2.074, nll_loss=0.26, ppl=1.2, wps=15472.1, ups=0.44, wpb=35032, bsz=3993.3, num_updates=26000, lr=0.000274563, gnorm=0.214, train_wall=225, gb_free=6.1, wall=18430]2022-03-10 23:54:54 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 175 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 175 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.93it/s]\u001b[A\n",
            "epoch 175 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.95it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-10 23:54:54 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 4.954 | nll_loss 3.492 | ppl 11.25 | wps 12765.2 | wpb 2934.3 | bsz 333.3 | num_updates 26075 | best_loss 4.47\n",
            "2022-03-10 23:54:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 26075 updates\n",
            "2022-03-10 23:54:55 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/checkpoint175.pt\n",
            "2022-03-10 23:54:58 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/checkpoint175.pt\n",
            "2022-03-10 23:55:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint175.pt (epoch 175 @ 26075 updates, score 4.954) (writing took 8.676963799996884 seconds)\n",
            "2022-03-10 23:55:03 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)\n",
            "2022-03-10 23:55:03 | INFO | train | epoch 175 | loss 2.077 | nll_loss 0.262 | ppl 1.2 | wps 15172.3 | ups 0.43 | wpb 35146.4 | bsz 4026.8 | num_updates 26075 | lr 0.000274167 | gnorm 0.219 | train_wall 334 | gb_free 6.6 | wall 18608\n",
            "2022-03-10 23:55:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 176:   0% 0/149 [00:00<?, ?it/s]2022-03-10 23:55:04 | INFO | fairseq.trainer | begin training epoch 176\n",
            "2022-03-10 23:55:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 176:  99% 148/149 [05:34<00:02,  2.34s/it, loss=2.079, nll_loss=0.265, ppl=1.2, wps=15621.2, ups=0.44, wpb=35347.2, bsz=4002, num_updates=26200, lr=0.000273513, gnorm=0.219, train_wall=226, gb_free=4.7, wall=18891]2022-03-11 00:00:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 176 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 176 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.91it/s]\u001b[A\n",
            "epoch 176 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.93it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-11 00:00:40 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 4.928 | nll_loss 3.46 | ppl 11 | wps 12697.1 | wpb 2934.3 | bsz 333.3 | num_updates 26224 | best_loss 4.47\n",
            "2022-03-11 00:00:40 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)\n",
            "2022-03-11 00:00:40 | INFO | train | epoch 176 | loss 2.079 | nll_loss 0.265 | ppl 1.2 | wps 15569.3 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 26224 | lr 0.000273387 | gnorm 0.223 | train_wall 335 | gb_free 6.6 | wall 18944\n",
            "2022-03-11 00:00:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 177:   0% 0/149 [00:00<?, ?it/s]2022-03-11 00:00:40 | INFO | fairseq.trainer | begin training epoch 177\n",
            "2022-03-11 00:00:40 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 177:  99% 148/149 [05:34<00:02,  2.23s/it, loss=2.068, nll_loss=0.253, ppl=1.19, wps=15626.2, ups=0.44, wpb=35162.9, bsz=3866.6, num_updates=26300, lr=0.000272992, gnorm=0.21, train_wall=223, gb_free=4.9, wall=19116]2022-03-11 00:06:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 177 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 177 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.96it/s]\u001b[A\n",
            "epoch 177 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.97it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-11 00:06:16 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 4.911 | nll_loss 3.444 | ppl 10.88 | wps 12818.2 | wpb 2934.3 | bsz 333.3 | num_updates 26373 | best_loss 4.47\n",
            "2022-03-11 00:06:16 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)\n",
            "2022-03-11 00:06:16 | INFO | train | epoch 177 | loss 2.077 | nll_loss 0.263 | ppl 1.2 | wps 15560.5 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 26373 | lr 0.000272614 | gnorm 0.22 | train_wall 334 | gb_free 7.5 | wall 19280\n",
            "2022-03-11 00:06:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 178:   0% 0/149 [00:00<?, ?it/s]2022-03-11 00:06:17 | INFO | fairseq.trainer | begin training epoch 178\n",
            "2022-03-11 00:06:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 178:  99% 148/149 [05:34<00:02,  2.21s/it, loss=2.073, nll_loss=0.259, ppl=1.2, wps=15768.4, ups=0.44, wpb=35740.5, bsz=3958.6, num_updates=26500, lr=0.00027196, gnorm=0.211, train_wall=226, gb_free=4.6, wall=19569]2022-03-11 00:11:52 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 178 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 178 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.96it/s]\u001b[A\n",
            "epoch 178 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.97it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-11 00:11:53 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 4.942 | nll_loss 3.477 | ppl 11.13 | wps 12887 | wpb 2934.3 | bsz 333.3 | num_updates 26522 | best_loss 4.47\n",
            "2022-03-11 00:11:53 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)\n",
            "2022-03-11 00:11:53 | INFO | train | epoch 178 | loss 2.076 | nll_loss 0.262 | ppl 1.2 | wps 15561.5 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 26522 | lr 0.000271847 | gnorm 0.219 | train_wall 334 | gb_free 6.6 | wall 19617\n",
            "2022-03-11 00:11:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 179:   0% 0/149 [00:00<?, ?it/s]2022-03-11 00:11:53 | INFO | fairseq.trainer | begin training epoch 179\n",
            "2022-03-11 00:11:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 179:  99% 148/149 [05:34<00:02,  2.26s/it, loss=2.077, nll_loss=0.264, ppl=1.2, wps=15411.3, ups=0.44, wpb=34675.5, bsz=4200.9, num_updates=26600, lr=0.000271448, gnorm=0.22, train_wall=223, gb_free=4.7, wall=19794]2022-03-11 00:17:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 179 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 179 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.92it/s]\u001b[A\n",
            "epoch 179 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.94it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-11 00:17:29 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 4.917 | nll_loss 3.446 | ppl 10.89 | wps 12832.9 | wpb 2934.3 | bsz 333.3 | num_updates 26671 | best_loss 4.47\n",
            "2022-03-11 00:17:29 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)\n",
            "2022-03-11 00:17:29 | INFO | train | epoch 179 | loss 2.076 | nll_loss 0.262 | ppl 1.2 | wps 15571.4 | ups 0.44 | wpb 35146.4 | bsz 4026.8 | num_updates 26671 | lr 0.000271087 | gnorm 0.217 | train_wall 334 | gb_free 5 | wall 19953\n",
            "2022-03-11 00:17:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 180:   0% 0/149 [00:00<?, ?it/s]2022-03-11 00:17:29 | INFO | fairseq.trainer | begin training epoch 180\n",
            "2022-03-11 00:17:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 180:  99% 148/149 [05:34<00:02,  2.24s/it, loss=2.076, nll_loss=0.263, ppl=1.2, wps=15601.7, ups=0.44, wpb=35246, bsz=4051.7, num_updates=26800, lr=0.000270434, gnorm=0.215, train_wall=226, gb_free=4.9, wall=20246]2022-03-11 00:23:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 180 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 180 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  2.95it/s]\u001b[A\n",
            "epoch 180 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.96it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-03-11 00:23:06 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 4.932 | nll_loss 3.464 | ppl 11.03 | wps 12702.1 | wpb 2934.3 | bsz 333.3 | num_updates 26820 | best_loss 4.47\n",
            "2022-03-11 00:23:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 26820 updates\n",
            "2022-03-11 00:23:06 | INFO | fairseq.trainer | Saving checkpoint to /content/checkpoints/checkpoint180.pt\n",
            "2022-03-11 00:23:09 | INFO | fairseq.trainer | Finished saving checkpoint to /content/checkpoints/checkpoint180.pt\n",
            "2022-03-11 00:23:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint180.pt (epoch 180 @ 26820 updates, score 4.932) (writing took 8.101309925012174 seconds)\n",
            "2022-03-11 00:23:14 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)\n",
            "2022-03-11 00:23:14 | INFO | train | epoch 180 | loss 2.074 | nll_loss 0.261 | ppl 1.2 | wps 15189.9 | ups 0.43 | wpb 35146.4 | bsz 4026.8 | num_updates 26820 | lr 0.000270333 | gnorm 0.213 | train_wall 334 | gb_free 5.4 | wall 20298\n",
            "2022-03-11 00:23:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 149\n",
            "epoch 181:   0% 0/149 [00:00<?, ?it/s]2022-03-11 00:23:14 | INFO | fairseq.trainer | begin training epoch 181\n",
            "2022-03-11 00:23:14 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 181:  28% 41/149 [01:33<04:03,  2.26s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/checkpoints/checkpoint_best.pt /content/drive/MyDrive/15M/GPU_wit600k"
      ],
      "metadata": {
        "id": "sRY0_M4dMF3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip \"/content/checkpoints\" \"/content/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o856tjyOG52I",
        "outputId": "edfc2aef-4ef4-4faf-942d-a16a96dddd93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/ (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/checkpoints.zip /content/drive/MyDrive/15M/GPU_2"
      ],
      "metadata": {
        "id": "65U8GbrbMjtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r GPU.zip abc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp01edyVLGUq",
        "outputId": "9c7fddf2-90d8-4970-850a-d81d2d1ea379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: abc/ (stored 0%)\n",
            "  adding: abc/test_th_220k (deflated 77%)\n",
            "  adding: abc/train_th_220k (deflated 77%)\n",
            "  adding: abc/train_en_220k (deflated 61%)\n",
            "  adding: abc/log.txt (deflated 75%)\n",
            "  adding: abc/data_enth_bin/ (stored 0%)\n",
            "  adding: abc/data_enth_bin/test.src-trg.src.idx (deflated 81%)\n",
            "  adding: abc/data_enth_bin/valid.src-trg.src.idx (deflated 78%)\n",
            "  adding: abc/data_enth_bin/train.src-trg.src.idx (deflated 81%)\n",
            "  adding: abc/data_enth_bin/dict.trg.txt (deflated 72%)\n",
            "  adding: abc/data_enth_bin/test.src-trg.src.bin (deflated 39%)\n",
            "  adding: abc/data_enth_bin/preprocess.log (deflated 59%)\n",
            "  adding: abc/data_enth_bin/test.src-trg.trg.bin (deflated 35%)\n",
            "  adding: abc/data_enth_bin/valid.src-trg.trg.bin (deflated 31%)\n",
            "  adding: abc/data_enth_bin/valid.src-trg.src.bin (deflated 36%)\n",
            "  adding: abc/data_enth_bin/train.src-trg.src.bin (deflated 39%)\n",
            "  adding: abc/data_enth_bin/train.src-trg.trg.bin (deflated 35%)\n",
            "  adding: abc/data_enth_bin/dict.src.txt (deflated 62%)\n",
            "  adding: abc/data_enth_bin/test.src-trg.trg.idx (deflated 80%)\n",
            "  adding: abc/data_enth_bin/train.src-trg.trg.idx (deflated 81%)\n",
            "  adding: abc/data_enth_bin/valid.src-trg.trg.idx (deflated 77%)\n",
            "  adding: abc/test_en_220k (deflated 61%)\n",
            "  adding: abc/REF.txt (deflated 77%)\n",
            "  adding: abc/bpe/ (stored 0%)\n",
            "  adding: abc/bpe/test.bpe.trg (deflated 77%)\n",
            "  adding: abc/bpe/test.bpe.src (deflated 61%)\n",
            "  adding: abc/bpe/trg.bpe (deflated 74%)\n",
            "  adding: abc/bpe/src.bpe (deflated 65%)\n",
            "  adding: abc/bpe/train.bpe.trg (deflated 77%)\n",
            "  adding: abc/bpe/train.bpe.src (deflated 61%)\n",
            "  adding: abc/bpe/val.bpe.trg (deflated 76%)\n",
            "  adding: abc/bpe/val.bpe.src (deflated 57%)\n",
            "  adding: abc/val_th_220k (deflated 76%)\n",
            "  adding: abc/translated.txt (deflated 78%)\n",
            "  adding: abc/val_en_220k (deflated 57%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/GPU.zip /content/drive/MyDrive/15M/GPU_wit600k/"
      ],
      "metadata": {
        "id": "Z9gzg1KpLUHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python /content/fairseq/fairseq_cli/train.py ./data_enth_bin --arch transformer_wmt_en_de \\\n",
        "# --optimizer adam --adam-betas '(0.9,0.98)' --clip-norm 0.0 \\\n",
        "# --lr-scheduler inverse_sqrt --warmup-init-lr 1e-07 --warmup-updates 4000 \\\n",
        "# --lr 0.0007 --min-lr 1e-09 --max-epoch 1\\\n",
        "# --weight-decay 0.0 --criterion label_smoothed_cross_entropy \\\n",
        "# --label-smoothing 0.1 --max-tokens 4096 --update-freq 2 \\\n",
        "# --log-interval 10 --save-interval-updates 1000 \\\n",
        "# --keep-interval-updates 5 --distributed-world-size 1"
      ],
      "metadata": {
        "id": "L2kyXqys3FBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !fairseq-generate ./data_enth_bin \\\n",
        "# --path checkpoints/checkpoint_best.pt \\\n",
        "# --batch-size 128 --beam 5 --remove-bpe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPW-Lrij520V",
        "outputId": "a696d3b0-a447-4337-848b-9181316cb971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-09 02:18:10 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2022-03-09 02:18:11 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'checkpoints/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 32, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 32, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': './data_enth_bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2022-03-09 02:18:11 | INFO | fairseq.tasks.translation | [src] dictionary: 14000 types\n",
            "2022-03-09 02:18:11 | INFO | fairseq.tasks.translation | [trg] dictionary: 14312 types\n",
            "2022-03-09 02:18:11 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/checkpoint_best.pt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-generate\", line 8, in <module>\n",
            "    sys.exit(cli_main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/generate.py\", line 413, in cli_main\n",
            "    main(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/generate.py\", line 50, in main\n",
            "    return _main(cfg, sys.stdout)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/generate.py\", line 106, in _main\n",
            "    task.load_dataset(cfg.dataset.gen_subset, task_cfg=saved_cfg.task)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq/tasks/translation.py\", line 356, in load_dataset\n",
            "    pad_to_multiple=self.cfg.required_seq_len_multiple,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq/tasks/translation.py\", line 86, in load_langpair_dataset\n",
            "    prefix + src, src_dict, dataset_impl\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq/data/data_utils.py\", line 110, in load_indexed_dataset\n",
            "    dictionary=dictionary,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq/data/indexed_dataset.py\", line 86, in make_dataset\n",
            "    return MMapIndexedDataset(path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq/data/indexed_dataset.py\", line 494, in __init__\n",
            "    self._do_init(path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq/data/indexed_dataset.py\", line 508, in _do_init\n",
            "    data_file_path(self._path), mode=\"r\", order=\"C\"\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/memmap.py\", line 267, in __new__\n",
            "    mm = mmap.mmap(fid.fileno(), bytes, access=acc, offset=start)\n",
            "ValueError: cannot mmap an empty file\n",
            "Exception ignored in: <function MMapIndexedDataset.__del__ at 0x7f38054370e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq/data/indexed_dataset.py\", line 513, in __del__\n",
            "    self._bin_buffer_mmap._mmap.close()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\", line 83, in __getattr__\n",
            "    raise AttributeError\n",
            "AttributeError: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-generate ./data_enth_bin \\\n",
        "--path checkpoints/checkpoint_best.pt \\\n",
        "--batch-size 128 --beam 5 --remove-bpe \\\n",
        "| grep -P \"[D|T]-[0-9]+\" > log.txt\n",
        "# | grep -P \"D-[0-9]+\" > log.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydxSpRd8EqlA",
        "outputId": "5d945e7f-d6f7-4483-b76d-671652d5fbf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-10 17:20:23 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2022-03-10 17:20:26 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'checkpoints/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 128, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 128, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': './data_enth_bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2022-03-10 17:20:26 | INFO | fairseq.tasks.translation | [src] dictionary: 52656 types\n",
            "2022-03-10 17:20:26 | INFO | fairseq.tasks.translation | [trg] dictionary: 21680 types\n",
            "2022-03-10 17:20:26 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/checkpoint_best.pt\n",
            "2022-03-10 17:20:29 | INFO | fairseq.data.data_utils | loaded 80,000 examples from: ./data_enth_bin/test.src-trg.src\n",
            "2022-03-10 17:20:29 | INFO | fairseq.data.data_utils | loaded 80,000 examples from: ./data_enth_bin/test.src-trg.trg\n",
            "2022-03-10 17:20:29 | INFO | fairseq.tasks.translation | ./data_enth_bin test src-trg 80000 examples\n",
            "2022-03-10 17:29:17 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2022-03-10 17:29:17 | INFO | fairseq_cli.generate | Translated 80,000 sentences (665,064 tokens) in 187.7s (426.32 sentences/s, 3544.13 tokens/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REF = []\n",
        "translated = []\n",
        "for line in open(\"log.txt\",'r',encoding='utf8').readlines():\n",
        "  splited_line = line.split('\\t')\n",
        "  if 'T' in splited_line[0]:\n",
        "    REF.append(splited_line[1].strip())\n",
        "  else:\n",
        "    translated.append(splited_line[2].strip())\n",
        "  # print(splited_line)\n",
        "  # break\n",
        "open('REF.txt','w',encoding='utf8').write('\\n'.join(REF))\n",
        "open('translated.txt','w',encoding='utf8').write('\\n'.join(translated))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc3INjoTBPMQ",
        "outputId": "7dce115b-c1ba-430d-d0ba-8bfd18ac6e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2847929"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat translated.txt | sacrebleu REF.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqAvPp4slP-r",
        "outputId": "3323e5b8-549a-4bee-e580-1ae01dda2f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            " \"name\": \"BLEU\",\n",
            " \"score\": 35.3,\n",
            " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.0.0\",\n",
            " \"verbose_score\": \"62.6/42.3/30.9/23.7 (BP = 0.946 ratio = 0.948 hyp_len = 585206 ref_len = 617602)\",\n",
            " \"nrefs\": \"1\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"no\",\n",
            " \"tok\": \"13a\",\n",
            " \"smooth\": \"exp\",\n",
            " \"version\": \"2.0.0\"\n",
            "}\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction**"
      ],
      "metadata": {
        "id": "hc0hHH2B4aPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fairseq.models.transformer import TransformerModel\n",
        "model = TransformerModel.from_pretrained(\n",
        "    \"/content/drive/MyDrive/15M/GPU_wit600k\", # model name or path\n",
        "    checkpoint_file=\"checkpoint_best.pt\", # checkpoint file\n",
        "    data_name_or_path='/content/data_enth_bin', # path of folder enth\n",
        "    bpe='subword_nmt', # bpe engine \n",
        "    bpe_codes='/content/bpe/src.bpe' # bpe codes (file from subword_nmt learn bpe)\n",
        " )\n",
        "# use function translate to translate the sentence\n",
        "model.translate(\"I love you\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "HAZrhzdV4dGQ",
        "outputId": "c3b8fd2e-a51c-4659-9525-dfc4afdfe6bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-10 17:31:43 | INFO | fairseq.file_utils | loading archive file /content/drive/MyDrive/15M/GPU_wit600k\n",
            "2022-03-10 17:31:43 | INFO | fairseq.file_utils | loading archive file /content/data_enth_bin\n",
            "2022-03-10 17:31:45 | INFO | fairseq.tasks.translation | [src] dictionary: 52656 types\n",
            "2022-03-10 17:31:45 | INFO | fairseq.tasks.translation | [trg] dictionary: 21680 types\n",
            "2022-03-10 17:31:46 | INFO | fairseq.models.fairseq_model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 14000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 14000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 150000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [3], 'lr': [0.0007], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 10000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_wmt_en_de', activation_dropout=0.0, activation_fn='relu', adam_betas=(0.9, 0.999), adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_wmt_en_de', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe='subword_nmt', bpe_codes='/content/bpe/src.bpe', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/content/data_enth_bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0007], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=14000, max_tokens_valid=14000, max_update=150000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=5, save_interval_updates=10000, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[3], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': '/content/data_enth_bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0007]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'subword_nmt', 'bpe_codes': '/content/bpe/src.bpe', 'bpe_separator': '@@'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ความ รัก ที่ มี ให้ กับ คุณ'"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6sTpaoAg4xJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(\"/content/en_test.csv\")\n",
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "kK6TY7vz4ztI",
        "outputId": "a0dcf327-285b-47ee-dfeb-8e403b489e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d9f0bcfa-b208-494b-a208-e88c8e912934\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What! on fire!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>what is your hobby?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>This is a tragic love story.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Is this road safe?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Please turn in your assignments on time.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>1516</td>\n",
              "      <td>\"In the past, the United States government sto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>1517</td>\n",
              "      <td>ExxonMobil wishes to assure members of the pub...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>1518</td>\n",
              "      <td>The inquest was opened at the request of famil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1519</th>\n",
              "      <td>1519</td>\n",
              "      <td>Despite beginning out-patient treatment next w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1520</th>\n",
              "      <td>1520</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1521 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9f0bcfa-b208-494b-a208-e88c8e912934')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d9f0bcfa-b208-494b-a208-e88c8e912934 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d9f0bcfa-b208-494b-a208-e88c8e912934');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Unnamed: 0                                                  0\n",
              "0              0                                     What! on fire!\n",
              "1              1                                what is your hobby?\n",
              "2              2                       This is a tragic love story.\n",
              "3              3                                 Is this road safe?\n",
              "4              4           Please turn in your assignments on time.\n",
              "...          ...                                                ...\n",
              "1516        1516  \"In the past, the United States government sto...\n",
              "1517        1517  ExxonMobil wishes to assure members of the pub...\n",
              "1518        1518  The inquest was opened at the request of famil...\n",
              "1519        1519  Despite beginning out-patient treatment next w...\n",
              "1520        1520                                                NaN\n",
              "\n",
              "[1521 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.drop(['Unnamed: 0'], axis=1)"
      ],
      "metadata": {
        "id": "lEMEAHoU7dEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "_uoRqPge7kIS",
        "outputId": "3f4a443a-5467-4b49-8cae-60abb72642a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-191cba81-8b9e-46ff-a886-2f0b09ac7d50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What! on fire!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what is your hobby?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is a tragic love story.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Is this road safe?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Please turn in your assignments on time.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>\"In the past, the United States government sto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>ExxonMobil wishes to assure members of the pub...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>The inquest was opened at the request of famil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1519</th>\n",
              "      <td>Despite beginning out-patient treatment next w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1520</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1521 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-191cba81-8b9e-46ff-a886-2f0b09ac7d50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-191cba81-8b9e-46ff-a886-2f0b09ac7d50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-191cba81-8b9e-46ff-a886-2f0b09ac7d50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                      0\n",
              "0                                        What! on fire!\n",
              "1                                   what is your hobby?\n",
              "2                          This is a tragic love story.\n",
              "3                                    Is this road safe?\n",
              "4              Please turn in your assignments on time.\n",
              "...                                                 ...\n",
              "1516  \"In the past, the United States government sto...\n",
              "1517  ExxonMobil wishes to assure members of the pub...\n",
              "1518  The inquest was opened at the request of famil...\n",
              "1519  Despite beginning out-patient treatment next w...\n",
              "1520                                                NaN\n",
              "\n",
              "[1521 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.columns=['en_text']"
      ],
      "metadata": {
        "id": "unfUO6wo7HWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3lAL7JM37cuB",
        "outputId": "76b52c5c-0999-446b-b9af-f67d0bcec6ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dc8e3129-d357-4ca0-987c-88986f70c9e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What! on fire!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what is your hobby?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is a tragic love story.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Is this road safe?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Please turn in your assignments on time.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>\"In the past, the United States government sto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>ExxonMobil wishes to assure members of the pub...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>The inquest was opened at the request of famil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1519</th>\n",
              "      <td>Despite beginning out-patient treatment next w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1520</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1521 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc8e3129-d357-4ca0-987c-88986f70c9e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc8e3129-d357-4ca0-987c-88986f70c9e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc8e3129-d357-4ca0-987c-88986f70c9e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                en_text\n",
              "0                                        What! on fire!\n",
              "1                                   what is your hobby?\n",
              "2                          This is a tragic love story.\n",
              "3                                    Is this road safe?\n",
              "4              Please turn in your assignments on time.\n",
              "...                                                 ...\n",
              "1516  \"In the past, the United States government sto...\n",
              "1517  ExxonMobil wishes to assure members of the pub...\n",
              "1518  The inquest was opened at the request of famil...\n",
              "1519  Despite beginning out-patient treatment next w...\n",
              "1520                                                NaN\n",
              "\n",
              "[1521 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def preprocessTest_en(df):\n",
        "  '''\n",
        "  drop Nan\n",
        "  replace \"Alright!\" -> \"Alright !\", \"Goodnight.\" -> \"Goodnight .\" เว้นจุด ! ? ที่ท้ายประโยค\n",
        "  replace \"Alright, bye\" -> \"Alright , bye\"\n",
        "  replace \"&quot;\" -> '\"' (ฟันหนู)\n",
        "  '''\n",
        "  df = df.dropna()\n",
        "\n",
        "  df['en_text'] = df['en_text'].map(lambda x: x[:-1] + ' .' if x.endswith('.')  else x)\n",
        "  df['en_text'] = df['en_text'].map(lambda x: x[:-1] + ' ?' if x.endswith('?')  else x)\n",
        "  df['en_text'] = df['en_text'].map(lambda x: x[:-1] + ' !' if x.endswith('!')  else x)\n",
        "\n",
        "  E_idx = df[(df['en_text'].str.contains(',') == True) & (df['en_text'].str.contains(', ') == True)& (df['en_text'].str.contains(' ,') == False)].index\n",
        "  df['en_text'][E_idx] = df[(df['en_text'].str.contains(',') == True) & (df['en_text'].str.contains(', ') == True)& (df['en_text'].str.contains(' ,') == False)]['en_text'].str.replace(\",\", \" ,\")\n",
        "\n",
        "  df['en_text'].map(lambda x : re.sub('&quot;','\\\"',x))\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "9uwtbBrt5VX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HOPE = preprocessTest_en(test_df)\n",
        "HOPE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934
        },
        "id": "SYZVfFod5Xei",
        "outputId": "f7733fe4-e814-4ea5-ce3c-dd10d6a2da7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:1135: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._set_values(indexer, value)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1b159aab-87db-4634-a862-07fcf584e376\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What! on fire !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what is your hobby ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is a tragic love story .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Is this road safe ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Please turn in your assignments on time .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>He criticised the outgoing head of the U.N.'s ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>\"In the past , the United States government st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>ExxonMobil wishes to assure members of the pub...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>The inquest was opened at the request of famil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1519</th>\n",
              "      <td>Despite beginning out-patient treatment next w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1520 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b159aab-87db-4634-a862-07fcf584e376')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b159aab-87db-4634-a862-07fcf584e376 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b159aab-87db-4634-a862-07fcf584e376');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                en_text\n",
              "0                                       What! on fire !\n",
              "1                                  what is your hobby ?\n",
              "2                         This is a tragic love story .\n",
              "3                                   Is this road safe ?\n",
              "4             Please turn in your assignments on time .\n",
              "...                                                 ...\n",
              "1515  He criticised the outgoing head of the U.N.'s ...\n",
              "1516  \"In the past , the United States government st...\n",
              "1517  ExxonMobil wishes to assure members of the pub...\n",
              "1518  The inquest was opened at the request of famil...\n",
              "1519  Despite beginning out-patient treatment next w...\n",
              "\n",
              "[1520 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NEW_HOPE = list(HOPE['en_text'])\n",
        "NEW_HOPE[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD6f5Kgs8dmc",
        "outputId": "a2a1e352-e091-4a12-d1db-f76c957c2a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What! on fire !',\n",
              " 'what is your hobby ?',\n",
              " 'This is a tragic love story .',\n",
              " 'Is this road safe ?',\n",
              " 'Please turn in your assignments on time .']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "result = []\n",
        "for text in tqdm(NEW_HOPE):\n",
        "  result.append(model.translate(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7c7cb67453754937b5b7d9ee28011147",
            "ffe150a6b24547c4a420193f0ba71bb9",
            "98edfa7c17914381a8f18bf8814630b8",
            "f8500f4348c14d308ae842b8a8382931",
            "3167a300e17a45fc887ac5c6ed9e1437",
            "ece7e46f004643d1871ead91f2d507c4",
            "14893ab166054c72b67e120555137349",
            "4b161da59ad642a084b77474a569e6c4",
            "dd12e1957a5943c094f0f6ab708332a3",
            "399537f954054ff2b5a7eb165fdb5f8c",
            "cc5032420262426096eeebf6c25d1593"
          ]
        },
        "id": "klvmdpeC9Z0-",
        "outputId": "aa3bc0b9-78ee-4e77-86c4-2ebac84ecac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c7cb67453754937b5b7d9ee28011147",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1520 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = pd.DataFrame([result])\n",
        "b = a.transpose()\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "5WHJdE2Z-HYR",
        "outputId": "64878b15-346b-4e0e-a61a-bab2576d5473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c965afd9-5cf4-423c-afad-93e3510be27b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ไฟ ไหม้ อย่าง ไร ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>งาน อดิเรก ของ คุณ คือ อะไร ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ความ พยายาม ของ เขา เป็น เรื่อง รัก ที่ น่า เศ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>เท ร ็ ก ซ ์ ให้ ปลอดภัย ไหม ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>สัญญา เช่า ที่ เป็น ที่ รับ มอบหมาย ให้ ทำงาน ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>ใน ฐานะ ที่ เป็น ผู้ ที่ เป็น ผู้นำ ใน ฐานะ ที...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>\" The a r i o t i as i l i a ดอก a r i a ดอก เ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>เท ร เล ค โฮ เท ล เป็น สิ่ง ที่ ต้องการ ให้ คว...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>การ คุม สติ แล้ว เขา ถูก เปิด ให้ กับ ผู้ เครา...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1519</th>\n",
              "      <td>ใน ฐานะ ที่ เป็น ผู้ ที่ มี ความ สามารถ ใน การ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1520 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c965afd9-5cf4-423c-afad-93e3510be27b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c965afd9-5cf4-423c-afad-93e3510be27b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c965afd9-5cf4-423c-afad-93e3510be27b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                      0\n",
              "0                                    ไฟ ไหม้ อย่าง ไร ?\n",
              "1                         งาน อดิเรก ของ คุณ คือ อะไร ?\n",
              "2     ความ พยายาม ของ เขา เป็น เรื่อง รัก ที่ น่า เศ...\n",
              "3                        เท ร ็ ก ซ ์ ให้ ปลอดภัย ไหม ?\n",
              "4     สัญญา เช่า ที่ เป็น ที่ รับ มอบหมาย ให้ ทำงาน ...\n",
              "...                                                 ...\n",
              "1515  ใน ฐานะ ที่ เป็น ผู้ ที่ เป็น ผู้นำ ใน ฐานะ ที...\n",
              "1516  \" The a r i o t i as i l i a ดอก a r i a ดอก เ...\n",
              "1517  เท ร เล ค โฮ เท ล เป็น สิ่ง ที่ ต้องการ ให้ คว...\n",
              "1518  การ คุม สติ แล้ว เขา ถูก เปิด ให้ กับ ผู้ เครา...\n",
              "1519  ใน ฐานะ ที่ เป็น ผู้ ที่ มี ความ สามารถ ใน การ...\n",
              "\n",
              "[1520 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faith = b.rename(columns={0: \"th_text\"})"
      ],
      "metadata": {
        "id": "QxxT9P86BDPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faith"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "bVpG3CGwBnq1",
        "outputId": "51210b18-ed4c-485f-df78-fb4a669619ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-45de4880-0b39-454a-86d0-2fd5b1108b92\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>th_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ไฟ ไหม้ อย่าง ไร ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>งาน อดิเรก ของ คุณ คือ อะไร ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ความ พยายาม ของ เขา เป็น เรื่อง รัก ที่ น่า เศ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>เท ร ็ ก ซ ์ ให้ ปลอดภัย ไหม ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>สัญญา เช่า ที่ เป็น ที่ รับ มอบหมาย ให้ ทำงาน ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>ใน ฐานะ ที่ เป็น ผู้ ที่ เป็น ผู้นำ ใน ฐานะ ที...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>\" The a r i o t i as i l i a ดอก a r i a ดอก เ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>เท ร เล ค โฮ เท ล เป็น สิ่ง ที่ ต้องการ ให้ คว...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>การ คุม สติ แล้ว เขา ถูก เปิด ให้ กับ ผู้ เครา...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1519</th>\n",
              "      <td>ใน ฐานะ ที่ เป็น ผู้ ที่ มี ความ สามารถ ใน การ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1520 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45de4880-0b39-454a-86d0-2fd5b1108b92')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45de4880-0b39-454a-86d0-2fd5b1108b92 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45de4880-0b39-454a-86d0-2fd5b1108b92');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                th_text\n",
              "0                                    ไฟ ไหม้ อย่าง ไร ?\n",
              "1                         งาน อดิเรก ของ คุณ คือ อะไร ?\n",
              "2     ความ พยายาม ของ เขา เป็น เรื่อง รัก ที่ น่า เศ...\n",
              "3                        เท ร ็ ก ซ ์ ให้ ปลอดภัย ไหม ?\n",
              "4     สัญญา เช่า ที่ เป็น ที่ รับ มอบหมาย ให้ ทำงาน ...\n",
              "...                                                 ...\n",
              "1515  ใน ฐานะ ที่ เป็น ผู้ ที่ เป็น ผู้นำ ใน ฐานะ ที...\n",
              "1516  \" The a r i o t i as i l i a ดอก a r i a ดอก เ...\n",
              "1517  เท ร เล ค โฮ เท ล เป็น สิ่ง ที่ ต้องการ ให้ คว...\n",
              "1518  การ คุม สติ แล้ว เขา ถูก เปิด ให้ กับ ผู้ เครา...\n",
              "1519  ใน ฐานะ ที่ เป็น ผู้ ที่ มี ความ สามารถ ใน การ...\n",
              "\n",
              "[1520 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def processTest_th(df):\n",
        "  # --------------ถ้า preprocess ก่อน predict ให้รันทั้งหมด -----------------------\n",
        "  df = df.fillna(\"\")\n",
        "  def removeunderscore(df): \n",
        "    df['th_text'] = df['th_text'].str.replace(\"_\", \"\") \n",
        "    return df\n",
        "  df = removeunderscore(df)\n",
        "\n",
        "  def fill_th_q(df, word, new_word):\n",
        "    idx = df[df[\"th_text\"].str.endswith(word)].index\n",
        "    df['th_text'][idx] = df[df['th_text'].str.endswith(word)][\"th_text\"].str.replace(word, new_word)\n",
        "    return df\n",
        "\n",
        "  fill_th_q(df, \" ไหม\", \" ไหม ?\")\n",
        "  fill_th_q(df, \" อะไร\", \" อะไร ?\")\n",
        "  fill_th_q(df, \" รึยัง\", \" รึยัง ?\")\n",
        "  fill_th_q(df, \" อย่าง ไร ดี\", \" อย่าง ไร ดี ?\")\n",
        "\n",
        "  def dup_th(df, word, new_word):\n",
        "    idx = df[df[\"th_text\"].str.contains(word)].index\n",
        "    df.th_text[idx] = df[df['th_text'].str.contains(word)][\"th_text\"].str.replace(word, new_word)\n",
        "    return df\n",
        "\n",
        "  dup_th(df, \"มาก มาก \", \"มาก ๆ \")\n",
        "  dup_th(df, \"ทุก ทุก \", \"ทุก ๆ \")\n",
        "  dup_th(df, \"แน่ แน่ \", \"แน่ ๆ \")\n",
        "  dup_th(df, \"อื่น อื่น \", \"อื่น ๆ \")\n",
        "  dup_th(df, \"ค่อย ค่อย \", \"ค่อย ๆ \")\n",
        "  dup_th(df, \"คร่าว คร่าว \", \"คร่าว ๆ \")\n",
        "  dup_th(df, \"จิ๊บ จิ๊บ \", \"จิ๊บ ๆ \")\n",
        "  dup_th(df, \"จริง จริง \", \"จริง ๆ \")\n",
        "  dup_th(df, \"ข้าง ข้าง \", \"ข้าง ๆ \")\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "evywpPrEA8vM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faiths = processTest_th(faith)\n",
        "faiths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "yEL7oNqWBdTb",
        "outputId": "6a5748f6-4c70-4a7a-b124-16b81a26e1c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-53fa616a-040f-4e07-a3a0-d137a21520c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>th_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ไฟ ไหม้ อย่าง ไร ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>งาน อดิเรก ของ คุณ คือ อะไร ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ความ พยายาม ของ เขา เป็น เรื่อง รัก ที่ น่า เศ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>เท ร ็ ก ซ ์ ให้ ปลอดภัย ไหม ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>สัญญา เช่า ที่ เป็น ที่ รับ มอบหมาย ให้ ทำงาน ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>ใน ฐานะ ที่ เป็น ผู้ ที่ เป็น ผู้นำ ใน ฐานะ ที...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>\" The a r i o t i as i l i a ดอก a r i a ดอก เ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>เท ร เล ค โฮ เท ล เป็น สิ่ง ที่ ต้องการ ให้ คว...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>การ คุม สติ แล้ว เขา ถูก เปิด ให้ กับ ผู้ เครา...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1519</th>\n",
              "      <td>ใน ฐานะ ที่ เป็น ผู้ ที่ มี ความ สามารถ ใน การ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1520 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53fa616a-040f-4e07-a3a0-d137a21520c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53fa616a-040f-4e07-a3a0-d137a21520c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53fa616a-040f-4e07-a3a0-d137a21520c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                th_text\n",
              "0                                    ไฟ ไหม้ อย่าง ไร ?\n",
              "1                         งาน อดิเรก ของ คุณ คือ อะไร ?\n",
              "2     ความ พยายาม ของ เขา เป็น เรื่อง รัก ที่ น่า เศ...\n",
              "3                        เท ร ็ ก ซ ์ ให้ ปลอดภัย ไหม ?\n",
              "4     สัญญา เช่า ที่ เป็น ที่ รับ มอบหมาย ให้ ทำงาน ...\n",
              "...                                                 ...\n",
              "1515  ใน ฐานะ ที่ เป็น ผู้ ที่ เป็น ผู้นำ ใน ฐานะ ที...\n",
              "1516  \" The a r i o t i as i l i a ดอก a r i a ดอก เ...\n",
              "1517  เท ร เล ค โฮ เท ล เป็น สิ่ง ที่ ต้องการ ให้ คว...\n",
              "1518  การ คุม สติ แล้ว เขา ถูก เปิด ให้ กับ ผู้ เครา...\n",
              "1519  ใน ฐานะ ที่ เป็น ผู้ ที่ มี ความ สามารถ ใน การ...\n",
              "\n",
              "[1520 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faiths.to_csv('faiths.csv')"
      ],
      "metadata": {
        "id": "qr9Qo9Ks-SLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "ft83AmSw3T3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d33cc835-58b2-496b-ad38-86321bb4d3b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r fairseq.zip fairseq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HJdrAxfAeSA",
        "outputId": "141dd489-1e1e-4be1-dd2b-42baa5aa2b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps\n",
            "\tzip warning: name not matched: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/utils\n",
            "updating: fairseq/ (stored 0%)\n",
            "updating: fairseq/hubconf.py (deflated 54%)\n",
            "updating: fairseq/.gitignore (deflated 48%)\n",
            "updating: fairseq/fairseq.egg-info/ (stored 0%)\n",
            "updating: fairseq/fairseq.egg-info/dependency_links.txt (stored 0%)\n",
            "updating: fairseq/fairseq.egg-info/requires.txt (deflated 26%)\n",
            "updating: fairseq/fairseq.egg-info/SOURCES.txt (deflated 85%)\n",
            "updating: fairseq/fairseq.egg-info/entry_points.txt (deflated 66%)\n",
            "updating: fairseq/fairseq.egg-info/top_level.txt (deflated 10%)\n",
            "updating: fairseq/fairseq.egg-info/PKG-INFO (deflated 69%)\n",
            "updating: fairseq/fairseq.egg-info/not-zip-safe (stored 0%)\n",
            "updating: fairseq/CONTRIBUTING.md (deflated 59%)\n",
            "updating: fairseq/.isort.cfg (deflated 39%)\n",
            "updating: fairseq/docs/ (stored 0%)\n",
            "updating: fairseq/docs/getting_started.rst (deflated 58%)\n",
            "updating: fairseq/docs/data.rst (deflated 69%)\n",
            "updating: fairseq/docs/_static/ (stored 0%)\n",
            "updating: fairseq/docs/_static/theme_overrides.css (deflated 47%)\n",
            "updating: fairseq/docs/make.bat (deflated 45%)\n",
            "updating: fairseq/docs/hydra_integration.md (deflated 62%)\n",
            "updating: fairseq/docs/command_line_tools.rst (deflated 74%)\n",
            "updating: fairseq/docs/Makefile (deflated 44%)\n",
            "updating: fairseq/docs/overview.rst (deflated 54%)\n",
            "updating: fairseq/docs/lr_scheduler.rst (deflated 70%)\n",
            "updating: fairseq/docs/index.rst (deflated 48%)\n",
            "updating: fairseq/docs/modules.rst (deflated 34%)\n",
            "updating: fairseq/docs/tutorial_classifying_names.rst (deflated 67%)\n",
            "updating: fairseq/docs/criterions.rst (deflated 67%)\n",
            "updating: fairseq/docs/optim.rst (deflated 73%)\n",
            "updating: fairseq/docs/tasks.rst (deflated 57%)\n",
            "updating: fairseq/docs/fairseq.gif (deflated 14%)\n",
            "updating: fairseq/docs/fairseq_logo.png (deflated 23%)\n",
            "updating: fairseq/docs/conf.py (deflated 56%)\n",
            "updating: fairseq/docs/models.rst (deflated 73%)\n",
            "updating: fairseq/docs/tutorial_simple_lstm.rst (deflated 73%)\n",
            "updating: fairseq/docs/docutils.conf (stored 0%)\n",
            "updating: fairseq/docs/requirements.txt (deflated 7%)\n",
            "updating: fairseq/examples/ (stored 0%)\n",
            "updating: fairseq/examples/speech_synthesis/ (stored 0%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/ (stored 0%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/get_feature_manifest.py (deflated 73%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/get_common_voice_audio_manifest.py (deflated 65%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/vad/ (stored 0%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/vad/__init__.py (deflated 66%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/denoise_and_vad_audio.py (deflated 67%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/speaker_embedder/ (stored 0%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/speaker_embedder/__init__.py (deflated 65%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/__init__.py (deflated 25%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/get_vctk_audio_manifest.py (deflated 61%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/denoiser/ (stored 0%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/denoiser/utils.py (deflated 63%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/denoiser/demucs.py (deflated 71%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/denoiser/pretrained.py (deflated 64%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/denoiser/__init__.py (deflated 25%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/denoiser/resample.py (deflated 63%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/get_ljspeech_audio_manifest.py (deflated 59%)\n",
            "updating: fairseq/examples/speech_synthesis/preprocessing/get_speaker_embedding.py (deflated 61%)\n",
            "updating: fairseq/examples/speech_synthesis/generate_waveform.py (deflated 69%)\n",
            "updating: fairseq/examples/speech_synthesis/utils.py (deflated 66%)\n",
            "updating: fairseq/examples/speech_synthesis/docs/ (stored 0%)\n",
            "updating: fairseq/examples/speech_synthesis/docs/common_voice_example.md (deflated 55%)\n",
            "updating: fairseq/examples/speech_synthesis/docs/vctk_example.md (deflated 54%)\n",
            "updating: fairseq/examples/speech_synthesis/docs/ljspeech_example.md (deflated 61%)\n",
            "updating: fairseq/examples/speech_synthesis/data_utils.py (deflated 71%)\n",
            "updating: fairseq/examples/speech_synthesis/evaluation/ (stored 0%)\n",
            "updating: fairseq/examples/speech_synthesis/evaluation/eval_f0.py (deflated 67%)\n",
            "updating: fairseq/examples/speech_synthesis/evaluation/eval_asr.py (deflated 65%)\n",
            "updating: fairseq/examples/speech_synthesis/evaluation/get_eval_manifest.py (deflated 60%)\n",
            "updating: fairseq/examples/speech_synthesis/evaluation/__init__.py (deflated 25%)\n",
            "updating: fairseq/examples/speech_synthesis/evaluation/eval_sp.py (deflated 66%)\n",
            "updating: fairseq/examples/speech_synthesis/README.md (deflated 45%)\n",
            "updating: fairseq/examples/speech_synthesis/__init__.py (deflated 25%)\n",
            "updating: fairseq/examples/.gitignore (deflated 6%)\n",
            "updating: fairseq/examples/flores101/ (stored 0%)\n",
            "updating: fairseq/examples/flores101/flores_logo.png (deflated 10%)\n",
            "updating: fairseq/examples/flores101/README.md (deflated 54%)\n",
            "updating: fairseq/examples/wmt20/ (stored 0%)\n",
            "updating: fairseq/examples/wmt20/README.md (deflated 70%)\n",
            "updating: fairseq/examples/normformer/ (stored 0%)\n",
            "updating: fairseq/examples/normformer/train_lm.sh (deflated 67%)\n",
            "updating: fairseq/examples/normformer/README.md (deflated 60%)\n",
            "updating: fairseq/examples/roberta/ (stored 0%)\n",
            "updating: fairseq/examples/roberta/README.race.md (deflated 52%)\n",
            "updating: fairseq/examples/roberta/wsc/ (stored 0%)\n",
            "updating: fairseq/examples/roberta/wsc/wsc_criterion.py (deflated 72%)\n",
            "updating: fairseq/examples/roberta/wsc/wsc_utils.py (deflated 72%)\n",
            "updating: fairseq/examples/roberta/wsc/wsc_task.py (deflated 76%)\n",
            "updating: fairseq/examples/roberta/wsc/README.md (deflated 61%)\n",
            "updating: fairseq/examples/roberta/wsc/__init__.py (deflated 34%)\n",
            "updating: fairseq/examples/roberta/multiprocessing_bpe_encoder.py (deflated 64%)\n",
            "updating: fairseq/examples/roberta/README.pretraining.md (deflated 55%)\n",
            "updating: fairseq/examples/roberta/commonsense_qa/ (stored 0%)\n",
            "updating: fairseq/examples/roberta/commonsense_qa/download_cqa_data.sh (deflated 49%)\n",
            "updating: fairseq/examples/roberta/commonsense_qa/commonsense_qa_task.py (deflated 67%)\n",
            "updating: fairseq/examples/roberta/commonsense_qa/README.md (deflated 53%)\n",
            "updating: fairseq/examples/roberta/commonsense_qa/__init__.py (deflated 27%)\n",
            "updating: fairseq/examples/roberta/config/ (stored 0%)\n",
            "updating: fairseq/examples/roberta/config/pretraining/ (stored 0%)\n",
            "updating: fairseq/examples/roberta/config/pretraining/base.yaml (deflated 42%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/ (stored 0%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/rte.yaml (deflated 50%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/mrpc.yaml (deflated 50%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/mnli.yaml (deflated 50%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/qnli.yaml (deflated 50%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/sts_b.yaml (deflated 49%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/cola.yaml (deflated 50%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/qqp.yaml (deflated 50%)\n",
            "updating: fairseq/examples/roberta/config/finetuning/sst_2.yaml (deflated 50%)\n",
            "updating: fairseq/examples/roberta/README.custom_classification.md (deflated 58%)\n",
            "updating: fairseq/examples/roberta/preprocess_RACE.sh (deflated 64%)\n",
            "updating: fairseq/examples/roberta/README.glue.md (deflated 49%)\n",
            "updating: fairseq/examples/roberta/preprocess_GLUE_tasks.sh (deflated 71%)\n",
            "updating: fairseq/examples/roberta/README.md (deflated 64%)\n",
            "updating: fairseq/examples/roberta/preprocess_RACE.py (deflated 66%)\n",
            "updating: fairseq/examples/translation_moe/ (stored 0%)\n",
            "updating: fairseq/examples/translation_moe/translation_moe_src/ (stored 0%)\n",
            "updating: fairseq/examples/translation_moe/translation_moe_src/mean_pool_gating_network.py (deflated 61%)\n",
            "updating: fairseq/examples/translation_moe/translation_moe_src/logsumexp_moe.py (deflated 44%)\n",
            "updating: fairseq/examples/translation_moe/translation_moe_src/__init__.py (deflated 27%)\n",
            "updating: fairseq/examples/translation_moe/translation_moe_src/translation_moe.py (deflated 72%)\n",
            "updating: fairseq/examples/translation_moe/score.py (deflated 67%)\n",
            "updating: fairseq/examples/translation_moe/README.md (deflated 58%)\n",
            "updating: fairseq/examples/joint_alignment_translation/ (stored 0%)\n",
            "updating: fairseq/examples/joint_alignment_translation/README.md (deflated 52%)\n",
            "updating: fairseq/examples/joint_alignment_translation/prepare-wmt18en2de_no_norm_no_escape_no_agressive.sh (deflated 59%)\n",
            "updating: fairseq/examples/shuffled_word_order/ (stored 0%)\n",
            "updating: fairseq/examples/shuffled_word_order/README.finetuning.md (deflated 62%)\n",
            "updating: fairseq/examples/shuffled_word_order/README.md (deflated 74%)\n",
            "updating: fairseq/examples/adaptive_span/ (stored 0%)\n",
            "updating: fairseq/examples/adaptive_span/adaptive_span_model.py (deflated 73%)\n",
            "updating: fairseq/examples/adaptive_span/adaptive_span_model_wrapper.py (deflated 67%)\n",
            "updating: fairseq/examples/adaptive_span/adagrad_with_grad_clip.py (deflated 67%)\n",
            "updating: fairseq/examples/adaptive_span/truncated_bptt_lm_task.py (deflated 67%)\n",
            "updating: fairseq/examples/adaptive_span/README.md (deflated 60%)\n",
            "updating: fairseq/examples/adaptive_span/adaptive_span_attention.py (deflated 69%)\n",
            "updating: fairseq/examples/adaptive_span/__init__.py (deflated 49%)\n",
            "updating: fairseq/examples/adaptive_span/adaptive_span_loss.py (deflated 69%)\n",
            "updating: fairseq/examples/translation/ (stored 0%)\n",
            "updating: fairseq/examples/translation/prepare-iwslt17-multilingual.sh (deflated 68%)\n",
            "updating: fairseq/examples/translation/prepare-wmt14en2de.sh (deflated 62%)\n",
            "updating: fairseq/examples/translation/prepare-iwslt14.sh (deflated 61%)\n",
            "updating: fairseq/examples/translation/README.md (deflated 73%)\n",
            "updating: fairseq/examples/translation/prepare-wmt14en2fr.sh (deflated 63%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/ (stored 0%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/models/ (stored 0%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/models/s2t_dualinputtransformer.py (deflated 82%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/models/__init__.py (deflated 29%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/models/s2t_dualinputxmtransformer.py (deflated 82%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/docs/ (stored 0%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/docs/iwslt2021.md (deflated 60%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/docs/ende-mustc.md (deflated 69%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/configs/ (stored 0%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/configs/mustc_noise.list (deflated 65%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/scripts/ (stored 0%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/scripts/g2p_encode.py (deflated 67%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/README.md (deflated 56%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/__init__.py (deflated 28%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/criterions/ (stored 0%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/criterions/text_guide_cross_entropy_acc.py (deflated 75%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/criterions/__init__.py (deflated 42%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/tasks/ (stored 0%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/tasks/speech_text_joint.py (deflated 75%)\n",
            "updating: fairseq/examples/speech_text_joint_to_text/tasks/__init__.py (deflated 29%)\n",
            "updating: fairseq/examples/scaling_nmt/ (stored 0%)\n",
            "updating: fairseq/examples/scaling_nmt/README.md (deflated 56%)\n",
            "updating: fairseq/examples/MMPT/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/.gitignore (deflated 46%)\n",
            "updating: fairseq/examples/MMPT/videoclip.png (deflated 5%)\n",
            "updating: fairseq/examples/MMPT/endtask.md (deflated 55%)\n",
            "updating: fairseq/examples/MMPT/CONFIG.md (deflated 59%)\n",
            "updating: fairseq/examples/MMPT/projects/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/mmfusionmtm.yaml (deflated 54%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/youcookcap.yaml (deflated 50%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/test_coin.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/coin.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/vtt.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/youcook.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/test_crosstask.yaml (deflated 61%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/test_youcookcap.yaml (deflated 47%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/how2.yaml (deflated 52%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/test_vttqa.yaml (deflated 45%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/vttqa.yaml (deflated 49%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/crosstask.yaml (deflated 58%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/test_crosstask_zs.yaml (deflated 60%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/test_youcook.yaml (deflated 49%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm/test_vtt.yaml (deflated 45%)\n",
            "updating: fairseq/examples/MMPT/projects/mtm/vlm.yaml (deflated 25%)\n",
            "updating: fairseq/examples/MMPT/projects/mfmmlm.yaml (deflated 65%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip.yaml (deflated 43%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_crosstask_videoclip.yaml (deflated 62%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_vttqa_zs.yaml (deflated 47%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_youcook_videoclip.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/coin_videoclip.yaml (deflated 52%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_coin_zs.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/how2.yaml (deflated 55%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_vtt_zs.yaml (deflated 47%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_vtt_videoclip.yaml (deflated 48%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_crosstask_zs_videoclip.yaml (deflated 61%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_coin_videoclip.yaml (deflated 53%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_youcook_zs.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_vttqa_videoclip.yaml (deflated 48%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/test_didemo_zs.yaml (deflated 50%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/crosstask_videoclip.yaml (deflated 59%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/youcook_videoclip.yaml (deflated 52%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/vtt_videoclip.yaml (deflated 52%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoclip/vttqa_videoclip.yaml (deflated 50%)\n",
            "updating: fairseq/examples/MMPT/projects/retri/videoretri.yaml (deflated 64%)\n",
            "updating: fairseq/examples/MMPT/projects/task/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/projects/task/youcookcap.yaml (deflated 48%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_crosstask_videoclip.yaml (deflated 33%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_coin.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/task/coin.yaml (deflated 49%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_vttqa_zs.yaml (deflated 39%)\n",
            "updating: fairseq/examples/MMPT/projects/task/vtt.yaml (deflated 50%)\n",
            "updating: fairseq/examples/MMPT/projects/task/ft.yaml (deflated 40%)\n",
            "updating: fairseq/examples/MMPT/projects/task/youcook.yaml (deflated 50%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_youcook_videoclip.yaml (deflated 32%)\n",
            "updating: fairseq/examples/MMPT/projects/task/coin_videoclip.yaml (deflated 32%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_coin_zs.yaml (deflated 37%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_crosstask.yaml (deflated 61%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_youcookcap.yaml (deflated 48%)\n",
            "updating: fairseq/examples/MMPT/projects/task/how2.yaml (deflated 50%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_vtt_zs.yaml (deflated 39%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_vtt_videoclip.yaml (deflated 32%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_vttqa.yaml (deflated 45%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_crosstask_zs_videoclip.yaml (deflated 33%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_coin_videoclip.yaml (deflated 33%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_youcook_zs.yaml (deflated 39%)\n",
            "updating: fairseq/examples/MMPT/projects/task/default.yaml (deflated 38%)\n",
            "updating: fairseq/examples/MMPT/projects/task/vttqa.yaml (deflated 44%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_vttqa_videoclip.yaml (deflated 32%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_didemo_zs.yaml (deflated 49%)\n",
            "updating: fairseq/examples/MMPT/projects/task/crosstask.yaml (deflated 61%)\n",
            "updating: fairseq/examples/MMPT/projects/task/crosstask_videoclip.yaml (deflated 35%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_crosstask_zs.yaml (deflated 60%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_youcook.yaml (deflated 51%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test_vtt.yaml (deflated 45%)\n",
            "updating: fairseq/examples/MMPT/projects/task/youcook_videoclip.yaml (deflated 44%)\n",
            "updating: fairseq/examples/MMPT/projects/task/vtt_videoclip.yaml (deflated 43%)\n",
            "updating: fairseq/examples/MMPT/projects/task/vttqa_videoclip.yaml (deflated 44%)\n",
            "updating: fairseq/examples/MMPT/projects/task/test.yaml (deflated 32%)\n",
            "updating: fairseq/examples/MMPT/locallaunch.py (deflated 69%)\n",
            "updating: fairseq/examples/MMPT/vlm.png (deflated 6%)\n",
            "updating: fairseq/examples/MMPT/mmpt_cli/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt_cli/predict.py (deflated 68%)\n",
            "updating: fairseq/examples/MMPT/mmpt_cli/localjob.py (deflated 71%)\n",
            "updating: fairseq/examples/MMPT/scripts/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/scripts/text_token_extractor/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/scripts/text_token_extractor/pretokenization.py (deflated 63%)\n",
            "updating: fairseq/examples/MMPT/scripts/text_token_extractor/configs/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/scripts/text_token_extractor/configs/bert-base-uncased.yaml (deflated 28%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/pathbuilder.py (deflated 69%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/videoreader.py (deflated 76%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/model.py (deflated 59%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/random_sequence_shuffler.py (deflated 61%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/extract.py (deflated 72%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/how2/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/how2/s3d.sh (deflated 29%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/shard_feature.py (deflated 64%)\n",
            "updating: fairseq/examples/MMPT/scripts/video_feature_extractor/preprocessing.py (deflated 70%)\n",
            "updating: fairseq/examples/MMPT/setup.py (deflated 41%)\n",
            "updating: fairseq/examples/MMPT/README.md (deflated 60%)\n",
            "updating: fairseq/examples/MMPT/mmpt/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/losses/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/losses/fairseqmmloss.py (deflated 59%)\n",
            "updating: fairseq/examples/MMPT/mmpt/losses/__init__.py (deflated 43%)\n",
            "updating: fairseq/examples/MMPT/mmpt/losses/loss.py (deflated 79%)\n",
            "updating: fairseq/examples/MMPT/mmpt/losses/nce.py (deflated 77%)\n",
            "updating: fairseq/examples/MMPT/mmpt/models/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/models/mmfusionnlg.py (deflated 78%)\n",
            "updating: fairseq/examples/MMPT/mmpt/models/mmfusion.py (deflated 84%)\n",
            "updating: fairseq/examples/MMPT/mmpt/models/fairseqmmmodel.py (deflated 59%)\n",
            "updating: fairseq/examples/MMPT/mmpt/models/transformermodel.py (deflated 83%)\n",
            "updating: fairseq/examples/MMPT/mmpt/models/__init__.py (deflated 46%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/dedupprocessor.py (deflated 73%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/models/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/models/s3dg.py (deflated 75%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/how2processor.py (deflated 79%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/how2retriprocessor.py (deflated 76%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/dsprocessor.py (deflated 77%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/processor.py (deflated 75%)\n",
            "updating: fairseq/examples/MMPT/mmpt/processors/__init__.py (deflated 62%)\n",
            "updating: fairseq/examples/MMPT/mmpt/modules/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/modules/vectorpool.py (deflated 77%)\n",
            "updating: fairseq/examples/MMPT/mmpt/modules/retri.py (deflated 84%)\n",
            "updating: fairseq/examples/MMPT/mmpt/modules/mm.py (deflated 69%)\n",
            "updating: fairseq/examples/MMPT/mmpt/modules/__init__.py (deflated 31%)\n",
            "updating: fairseq/examples/MMPT/mmpt/evaluators/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/evaluators/metric.py (deflated 72%)\n",
            "updating: fairseq/examples/MMPT/mmpt/evaluators/evaluator.py (deflated 66%)\n",
            "updating: fairseq/examples/MMPT/mmpt/evaluators/predictor.py (deflated 79%)\n",
            "updating: fairseq/examples/MMPT/mmpt/evaluators/__init__.py (deflated 36%)\n",
            "updating: fairseq/examples/MMPT/mmpt/utils/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/utils/load_config.py (deflated 67%)\n",
            "updating: fairseq/examples/MMPT/mmpt/utils/__init__.py (deflated 60%)\n",
            "updating: fairseq/examples/MMPT/mmpt/utils/shardedtensor.py (deflated 62%)\n",
            "updating: fairseq/examples/MMPT/mmpt/__init__.py (deflated 43%)\n",
            "updating: fairseq/examples/MMPT/mmpt/datasets/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/datasets/fairseqmmdataset.py (deflated 61%)\n",
            "updating: fairseq/examples/MMPT/mmpt/datasets/__init__.py (deflated 33%)\n",
            "updating: fairseq/examples/MMPT/mmpt/datasets/mmdataset.py (deflated 69%)\n",
            "updating: fairseq/examples/MMPT/mmpt/tasks/ (stored 0%)\n",
            "updating: fairseq/examples/MMPT/mmpt/tasks/task.py (deflated 74%)\n",
            "updating: fairseq/examples/MMPT/mmpt/tasks/vlmtask.py (deflated 49%)\n",
            "updating: fairseq/examples/MMPT/mmpt/tasks/fairseqmmtask.py (deflated 64%)\n",
            "updating: fairseq/examples/MMPT/mmpt/tasks/__init__.py (deflated 53%)\n",
            "updating: fairseq/examples/MMPT/mmpt/tasks/retritask.py (deflated 72%)\n",
            "updating: fairseq/examples/MMPT/mmpt/tasks/milncetask.py (deflated 57%)\n",
            "updating: fairseq/examples/MMPT/DATASET.md (deflated 53%)\n",
            "updating: fairseq/examples/MMPT/pretraining.md (deflated 49%)\n",
            "updating: fairseq/examples/unsupervised_quality_estimation/ (stored 0%)\n",
            "updating: fairseq/examples/unsupervised_quality_estimation/repeat_lines.py (deflated 51%)\n",
            "updating: fairseq/examples/unsupervised_quality_estimation/meteor.py (deflated 66%)\n",
            "updating: fairseq/examples/unsupervised_quality_estimation/README.md (deflated 64%)\n",
            "updating: fairseq/examples/unsupervised_quality_estimation/aggregate_scores.py (deflated 55%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/ (stored 0%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/models/ (stored 0%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/models/discriminative_reranking_model.py (deflated 76%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/models/__init__.py (deflated 30%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/drnmt_rerank.py (deflated 70%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/config/ (stored 0%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/config/deen.yaml (deflated 48%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/scripts/ (stored 0%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/scripts/prep_data.py (deflated 71%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/README.md (deflated 67%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/criterions/ (stored 0%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/criterions/__init__.py (deflated 32%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/criterions/discriminative_reranking_criterion.py (deflated 65%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/tasks/ (stored 0%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/tasks/discriminative_reranking_task.py (deflated 76%)\n",
            "updating: fairseq/examples/discriminative_reranking_nmt/tasks/__init__.py (deflated 35%)\n",
            "updating: fairseq/examples/pay_less_attention_paper/ (stored 0%)\n",
            "updating: fairseq/examples/pay_less_attention_paper/README.md (deflated 74%)\n",
            "updating: fairseq/examples/megatron_11b/ (stored 0%)\n",
            "updating: fairseq/examples/megatron_11b/detok.py (deflated 49%)\n",
            "updating: fairseq/examples/megatron_11b/README.md (deflated 59%)\n",
            "updating: fairseq/examples/constrained_decoding/ (stored 0%)\n",
            "updating: fairseq/examples/constrained_decoding/tok.py (deflated 46%)\n",
            "updating: fairseq/examples/constrained_decoding/README.md (deflated 60%)\n",
            "updating: fairseq/examples/constrained_decoding/normalize.py (deflated 44%)\n",
            "updating: fairseq/examples/operators/ (stored 0%)\n",
            "updating: fairseq/examples/operators/utils.h (deflated 42%)\n",
            "updating: fairseq/examples/operators/alignment_train_kernel.cu (deflated 74%)\n",
            "updating: fairseq/examples/operators/alignment_train_cpu.cpp (deflated 71%)\n",
            "updating: fairseq/examples/operators/alignment_train_cuda.cpp (deflated 43%)\n",
            "updating: fairseq/examples/operators/alignment_train_cuda.h (deflated 33%)\n",
            "updating: fairseq/examples/quant_noise/ (stored 0%)\n",
            "updating: fairseq/examples/quant_noise/transformer_quantization_config.yaml (deflated 50%)\n",
            "updating: fairseq/examples/quant_noise/README.md (deflated 68%)\n",
            "updating: fairseq/examples/hubert/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/dump_km_label.py (deflated 60%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/dump_hubert_feature_s2t.py (deflated 59%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/dump_w2v2_feature.py (deflated 60%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/feature_utils.py (deflated 54%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/README.md (deflated 59%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/dump_hubert_feature.py (deflated 60%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/learn_kmeans.py (deflated 66%)\n",
            "updating: fairseq/examples/hubert/simple_kmeans/dump_mfcc_feature.py (deflated 59%)\n",
            "updating: fairseq/examples/hubert/update_ckpt.py (deflated 45%)\n",
            "updating: fairseq/examples/hubert/config/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/decode/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/decode/ax_sweep/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/decode/ax_sweep/transformer.yaml (deflated 57%)\n",
            "updating: fairseq/examples/hubert/config/decode/ax_sweep/ngram.yaml (deflated 57%)\n",
            "updating: fairseq/examples/hubert/config/decode/infer_viterbi.yaml (deflated 45%)\n",
            "updating: fairseq/examples/hubert/config/decode/infer_fsqlm.yaml (deflated 57%)\n",
            "updating: fairseq/examples/hubert/config/decode/infer_kenlm.yaml (deflated 57%)\n",
            "updating: fairseq/examples/hubert/config/decode/run/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/decode/run/submitit_slurm_8gpu.yaml (deflated 53%)\n",
            "updating: fairseq/examples/hubert/config/decode/run/submitit_slurm.yaml (deflated 53%)\n",
            "updating: fairseq/examples/hubert/config/finetune/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/finetune/base_10h.yaml (deflated 55%)\n",
            "updating: fairseq/examples/hubert/config/finetune/lm/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/finetune/lm/ls_4gram.yaml (deflated 43%)\n",
            "updating: fairseq/examples/hubert/config/finetune/run/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/finetune/run/submitit_reg.yaml (deflated 46%)\n",
            "updating: fairseq/examples/hubert/config/finetune/ckpt/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/finetune/ckpt/it1.yaml (deflated 22%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/hubert_base_librispeech.yaml (deflated 54%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/data/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/data/iter2.yaml (deflated 14%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/data/iter1.yaml (deflated 14%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/hubert_large_librivox.yaml (deflated 56%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/run/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/run/submitit_reg.yaml (deflated 46%)\n",
            "updating: fairseq/examples/hubert/config/pretrain/hubert_xlarge_librivox.yaml (deflated 56%)\n",
            "updating: fairseq/examples/hubert/measure_teacher_quality.py (deflated 69%)\n",
            "updating: fairseq/examples/hubert/tests/ (stored 0%)\n",
            "updating: fairseq/examples/hubert/tests/sample.large.L20.len (stored 0%)\n",
            "updating: fairseq/examples/hubert/tests/sample.base.L9.len (stored 0%)\n",
            "updating: fairseq/examples/hubert/tests/test_finetuned_asr.sh (deflated 53%)\n",
            "updating: fairseq/examples/hubert/tests/6313-76958-0021.flac (deflated 4%)\n",
            "updating: fairseq/examples/hubert/tests/sample.xlarge.L30.npy (deflated 7%)\n",
            "updating: fairseq/examples/hubert/tests/sample.base.L9.km500.km (deflated 66%)\n",
            "updating: fairseq/examples/hubert/tests/sample.large.hypo.word (deflated 31%)\n",
            "updating: fairseq/examples/hubert/tests/sample.xlarge.hypo.word (deflated 31%)\n",
            "updating: fairseq/examples/hubert/tests/test_feature_and_unit.sh (deflated 69%)\n",
            "updating: fairseq/examples/hubert/tests/sample.base.L9.npy (deflated 7%)\n",
            "updating: fairseq/examples/hubert/tests/sample.large.L20.npy (deflated 7%)\n",
            "updating: fairseq/examples/hubert/tests/sample.xlarge.L30.len (stored 0%)\n",
            "updating: fairseq/examples/hubert/README.md (deflated 68%)\n",
            "updating: fairseq/examples/m2m_100/ (stored 0%)\n",
            "updating: fairseq/examples/m2m_100/process_data/ (stored 0%)\n",
            "updating: fairseq/examples/m2m_100/process_data/dedup_data.py (deflated 70%)\n",
            "updating: fairseq/examples/m2m_100/process_data/remove_too_much_punc.py (deflated 62%)\n",
            "updating: fairseq/examples/m2m_100/process_data/clean_histogram.py (deflated 70%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/ (stored 0%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/thirdparty/ (stored 0%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/thirdparty/.gitignore (deflated 43%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/seg_ja.sh (deflated 30%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/tokenizer_ar.sh (deflated 41%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/tokenize_indic.py (deflated 47%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/README.md (deflated 44%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/tokenize_zh.py (deflated 33%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/seg_ko.sh (deflated 31%)\n",
            "updating: fairseq/examples/m2m_100/tokenizers/tokenize_thai.py (deflated 32%)\n",
            "updating: fairseq/examples/m2m_100/tok.sh (deflated 65%)\n",
            "updating: fairseq/examples/m2m_100/install_dependecies.sh (deflated 60%)\n",
            "updating: fairseq/examples/m2m_100/README.md (deflated 67%)\n",
            "updating: fairseq/examples/rxf/ (stored 0%)\n",
            "updating: fairseq/examples/rxf/rxf_src/ (stored 0%)\n",
            "updating: fairseq/examples/rxf/rxf_src/sentence_prediction_r3f.py (deflated 72%)\n",
            "updating: fairseq/examples/rxf/rxf_src/__init__.py (deflated 28%)\n",
            "updating: fairseq/examples/rxf/rxf_src/label_smoothed_cross_entropy_r3f.py (deflated 70%)\n",
            "updating: fairseq/examples/rxf/README.md (deflated 51%)\n",
            "updating: fairseq/examples/rxf/__init__.py (deflated 27%)\n",
            "updating: fairseq/examples/criss/ (stored 0%)\n",
            "updating: fairseq/examples/criss/download_and_preprocess_flores_test.sh (deflated 55%)\n",
            "updating: fairseq/examples/criss/mining/ (stored 0%)\n",
            "updating: fairseq/examples/criss/mining/mine_example.sh (deflated 72%)\n",
            "updating: fairseq/examples/criss/mining/mine.py (deflated 70%)\n",
            "updating: fairseq/examples/criss/unsupervised_mt/ (stored 0%)\n",
            "updating: fairseq/examples/criss/unsupervised_mt/eval.sh (deflated 66%)\n",
            "updating: fairseq/examples/criss/save_encoder.py (deflated 68%)\n",
            "updating: fairseq/examples/criss/sentence_retrieval/ (stored 0%)\n",
            "updating: fairseq/examples/criss/sentence_retrieval/encoder_analysis.py (deflated 65%)\n",
            "updating: fairseq/examples/criss/sentence_retrieval/sentence_retrieval_tatoeba.sh (deflated 65%)\n",
            "updating: fairseq/examples/criss/download_and_preprocess_tatoeba.sh (deflated 53%)\n",
            "updating: fairseq/examples/criss/README.md (deflated 54%)\n",
            "updating: fairseq/examples/speech_recognition/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/models/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/models/vggtransformer.py (deflated 80%)\n",
            "updating: fairseq/examples/speech_recognition/models/__init__.py (deflated 39%)\n",
            "updating: fairseq/examples/speech_recognition/models/w2l_conv_glu_enc.py (deflated 66%)\n",
            "updating: fairseq/examples/speech_recognition/new/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/new/decoders/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/new/decoders/decoder.py (deflated 57%)\n",
            "updating: fairseq/examples/speech_recognition/new/decoders/flashlight_decoder.py (deflated 78%)\n",
            "updating: fairseq/examples/speech_recognition/new/decoders/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/new/decoders/base_decoder.py (deflated 62%)\n",
            "updating: fairseq/examples/speech_recognition/new/decoders/viterbi_decoder.py (deflated 40%)\n",
            "updating: fairseq/examples/speech_recognition/new/decoders/decoder_config.py (deflated 67%)\n",
            "updating: fairseq/examples/speech_recognition/new/README.md (deflated 60%)\n",
            "updating: fairseq/examples/speech_recognition/new/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/new/infer.py (deflated 71%)\n",
            "updating: fairseq/examples/speech_recognition/new/conf/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/new/conf/infer.yaml (deflated 44%)\n",
            "updating: fairseq/examples/speech_recognition/new/conf/hydra/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/new/conf/hydra/sweeper/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/new/conf/hydra/sweeper/ax.yaml (deflated 50%)\n",
            "updating: fairseq/examples/speech_recognition/w2l_decoder.py (deflated 77%)\n",
            "updating: fairseq/examples/speech_recognition/kaldi/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/kaldi/add-self-loop-simple.cc (deflated 60%)\n",
            "updating: fairseq/examples/speech_recognition/kaldi/kaldi_initializer.py (deflated 82%)\n",
            "updating: fairseq/examples/speech_recognition/kaldi/config/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/kaldi/config/kaldi_initializer.yaml (deflated 23%)\n",
            "updating: fairseq/examples/speech_recognition/kaldi/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/kaldi/kaldi_decoder.py (deflated 72%)\n",
            "updating: fairseq/examples/speech_recognition/data/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/data/data_utils.py (deflated 63%)\n",
            "updating: fairseq/examples/speech_recognition/data/replabels.py (deflated 66%)\n",
            "updating: fairseq/examples/speech_recognition/data/asr_dataset.py (deflated 65%)\n",
            "updating: fairseq/examples/speech_recognition/data/collaters.py (deflated 69%)\n",
            "updating: fairseq/examples/speech_recognition/data/__init__.py (deflated 28%)\n",
            "updating: fairseq/examples/speech_recognition/utils/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/utils/wer_utils.py (deflated 74%)\n",
            "updating: fairseq/examples/speech_recognition/README.md (deflated 62%)\n",
            "updating: fairseq/examples/speech_recognition/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/infer.py (deflated 71%)\n",
            "updating: fairseq/examples/speech_recognition/datasets/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/datasets/asr_prep_json.py (deflated 61%)\n",
            "updating: fairseq/examples/speech_recognition/datasets/prepare-librispeech.sh (deflated 66%)\n",
            "updating: fairseq/examples/speech_recognition/criterions/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/criterions/ASG_loss.py (deflated 68%)\n",
            "updating: fairseq/examples/speech_recognition/criterions/__init__.py (deflated 46%)\n",
            "updating: fairseq/examples/speech_recognition/criterions/cross_entropy_acc.py (deflated 67%)\n",
            "updating: fairseq/examples/speech_recognition/tasks/ (stored 0%)\n",
            "updating: fairseq/examples/speech_recognition/tasks/__init__.py (deflated 38%)\n",
            "updating: fairseq/examples/speech_recognition/tasks/speech_recognition.py (deflated 66%)\n",
            "updating: fairseq/examples/stories/ (stored 0%)\n",
            "updating: fairseq/examples/stories/README.md (deflated 59%)\n",
            "updating: fairseq/examples/bart/ (stored 0%)\n",
            "updating: fairseq/examples/bart/README.summarization.md (deflated 57%)\n",
            "updating: fairseq/examples/bart/summarize.py (deflated 63%)\n",
            "updating: fairseq/examples/bart/README.glue.md (deflated 52%)\n",
            "updating: fairseq/examples/bart/README.md (deflated 63%)\n",
            "updating: fairseq/examples/noisychannel/ (stored 0%)\n",
            "updating: fairseq/examples/noisychannel/rerank_tune.py (deflated 71%)\n",
            "updating: fairseq/examples/noisychannel/rerank_generate.py (deflated 83%)\n",
            "updating: fairseq/examples/noisychannel/rerank_score_lm.py (deflated 64%)\n",
            "updating: fairseq/examples/noisychannel/rerank_score_bw.py (deflated 75%)\n",
            "updating: fairseq/examples/noisychannel/README.md (deflated 70%)\n",
            "updating: fairseq/examples/noisychannel/__init__.py (deflated 27%)\n",
            "updating: fairseq/examples/noisychannel/rerank.py (deflated 79%)\n",
            "updating: fairseq/examples/noisychannel/rerank_utils.py (deflated 80%)\n",
            "updating: fairseq/examples/noisychannel/rerank_options.py (deflated 78%)\n",
            "updating: fairseq/examples/layerdrop/ (stored 0%)\n",
            "updating: fairseq/examples/layerdrop/README.md (deflated 64%)\n",
            "updating: fairseq/examples/backtranslation/ (stored 0%)\n",
            "updating: fairseq/examples/backtranslation/tokenized_bleu.sh (deflated 51%)\n",
            "updating: fairseq/examples/backtranslation/deduplicate_lines.py (deflated 53%)\n",
            "updating: fairseq/examples/backtranslation/prepare-de-monolingual.sh (deflated 72%)\n",
            "updating: fairseq/examples/backtranslation/prepare-wmt18en2de.sh (deflated 63%)\n",
            "updating: fairseq/examples/backtranslation/extract_bt_data.py (deflated 63%)\n",
            "updating: fairseq/examples/backtranslation/README.md (deflated 70%)\n",
            "updating: fairseq/examples/backtranslation/sacrebleu.sh (deflated 46%)\n",
            "updating: fairseq/examples/moe_lm/ (stored 0%)\n",
            "updating: fairseq/examples/moe_lm/model_card.md (deflated 59%)\n",
            "updating: fairseq/examples/moe_lm/data_card.md (deflated 66%)\n",
            "updating: fairseq/examples/moe_lm/README.md (deflated 62%)\n",
            "updating: fairseq/examples/pointer_generator/ (stored 0%)\n",
            "updating: fairseq/examples/pointer_generator/README.xsum.md (deflated 63%)\n",
            "updating: fairseq/examples/pointer_generator/preprocess.py (deflated 70%)\n",
            "updating: fairseq/examples/pointer_generator/pointer_generator_src/ (stored 0%)\n",
            "updating: fairseq/examples/pointer_generator/pointer_generator_src/__init__.py (deflated 27%)\n",
            "updating: fairseq/examples/pointer_generator/pointer_generator_src/transformer_pg.py (deflated 73%)\n",
            "updating: fairseq/examples/pointer_generator/README.md (deflated 56%)\n",
            "updating: fairseq/examples/pointer_generator/postprocess.py (deflated 65%)\n",
            "updating: fairseq/examples/language_model/ (stored 0%)\n",
            "updating: fairseq/examples/language_model/prepare-wikitext-103.sh (deflated 54%)\n",
            "updating: fairseq/examples/language_model/README.adaptive_inputs.md (deflated 52%)\n",
            "updating: fairseq/examples/language_model/README.md (deflated 60%)\n",
            "updating: fairseq/examples/language_model/README.conv.md (deflated 47%)\n",
            "updating: fairseq/examples/linformer/ (stored 0%)\n",
            "updating: fairseq/examples/linformer/README.md (deflated 44%)\n",
            "updating: fairseq/examples/linformer/linformer_src/ (stored 0%)\n",
            "updating: fairseq/examples/linformer/linformer_src/models/ (stored 0%)\n",
            "updating: fairseq/examples/linformer/linformer_src/models/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/linformer/linformer_src/models/linformer_roberta.py (deflated 69%)\n",
            "updating: fairseq/examples/linformer/linformer_src/modules/ (stored 0%)\n",
            "updating: fairseq/examples/linformer/linformer_src/modules/multihead_linear_attention.py (deflated 79%)\n",
            "updating: fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder_layer.py (deflated 65%)\n",
            "updating: fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder.py (deflated 60%)\n",
            "updating: fairseq/examples/linformer/linformer_src/modules/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/linformer/linformer_src/__init__.py (deflated 28%)\n",
            "updating: fairseq/examples/simultaneous_translation/ (stored 0%)\n",
            "updating: fairseq/examples/simultaneous_translation/eval/ (stored 0%)\n",
            "updating: fairseq/examples/simultaneous_translation/eval/agents/ (stored 0%)\n",
            "updating: fairseq/examples/simultaneous_translation/eval/agents/simul_t2t_enja.py (deflated 69%)\n",
            "updating: fairseq/examples/simultaneous_translation/models/ (stored 0%)\n",
            "updating: fairseq/examples/simultaneous_translation/models/convtransformer_simul_trans.py (deflated 74%)\n",
            "updating: fairseq/examples/simultaneous_translation/models/__init__.py (deflated 41%)\n",
            "updating: fairseq/examples/simultaneous_translation/models/transformer_monotonic_attention.py (deflated 75%)\n",
            "updating: fairseq/examples/simultaneous_translation/docs/ (stored 0%)\n",
            "updating: fairseq/examples/simultaneous_translation/docs/enja-waitk.md (deflated 55%)\n",
            "updating: fairseq/examples/simultaneous_translation/docs/ende-mma.md (deflated 70%)\n",
            "updating: fairseq/examples/simultaneous_translation/modules/ (stored 0%)\n",
            "updating: fairseq/examples/simultaneous_translation/modules/monotonic_transformer_layer.py (deflated 78%)\n",
            "updating: fairseq/examples/simultaneous_translation/modules/monotonic_multihead_attention.py (deflated 77%)\n",
            "updating: fairseq/examples/simultaneous_translation/modules/__init__.py (deflated 42%)\n",
            "updating: fairseq/examples/simultaneous_translation/modules/fixed_pre_decision.py (deflated 76%)\n",
            "updating: fairseq/examples/simultaneous_translation/tests/ (stored 0%)\n",
            "updating: fairseq/examples/simultaneous_translation/tests/test_alignment_train.py (deflated 68%)\n",
            "updating: fairseq/examples/simultaneous_translation/tests/test_text_models.py (deflated 79%)\n",
            "updating: fairseq/examples/simultaneous_translation/utils/ (stored 0%)\n",
            "updating: fairseq/examples/simultaneous_translation/utils/functions.py (deflated 61%)\n",
            "updating: fairseq/examples/simultaneous_translation/utils/monotonic_attention.py (deflated 70%)\n",
            "updating: fairseq/examples/simultaneous_translation/utils/__init__.py (deflated 41%)\n",
            "updating: fairseq/examples/simultaneous_translation/utils/p_choose_strategy.py (deflated 68%)\n",
            "updating: fairseq/examples/simultaneous_translation/README.md (deflated 48%)\n",
            "updating: fairseq/examples/simultaneous_translation/__init__.py (deflated 27%)\n",
            "updating: fairseq/examples/cross_lingual_language_model/ (stored 0%)\n",
            "updating: fairseq/examples/cross_lingual_language_model/README.md (deflated 53%)\n",
            "updating: fairseq/examples/laser/ (stored 0%)\n",
            "updating: fairseq/examples/laser/README.md (deflated 62%)\n",
            "updating: fairseq/examples/laser/laser_src/ (stored 0%)\n",
            "updating: fairseq/examples/laser/laser_src/laser_lstm.py (deflated 79%)\n",
            "updating: fairseq/examples/laser/laser_src/laser_transformer.py (deflated 73%)\n",
            "updating: fairseq/examples/laser/laser_src/laser_task.py (deflated 74%)\n",
            "updating: fairseq/examples/laser/laser_src/__init__.py (deflated 40%)\n",
            "updating: fairseq/examples/laser/laser_src/multitask_data_utils.py (deflated 69%)\n",
            "updating: fairseq/examples/conv_seq2seq/ (stored 0%)\n",
            "updating: fairseq/examples/conv_seq2seq/README.md (deflated 67%)\n",
            "updating: fairseq/examples/camembert/ (stored 0%)\n",
            "updating: fairseq/examples/camembert/README.md (deflated 66%)\n",
            "updating: fairseq/examples/wmt19/ (stored 0%)\n",
            "updating: fairseq/examples/wmt19/README.md (deflated 71%)\n",
            "updating: fairseq/examples/data2vec/ (stored 0%)\n",
            "updating: fairseq/examples/data2vec/models/ (stored 0%)\n",
            "updating: fairseq/examples/data2vec/models/data2vec_text.py (deflated 75%)\n",
            "updating: fairseq/examples/data2vec/models/data2vec_audio.py (deflated 77%)\n",
            "updating: fairseq/examples/data2vec/config/ (stored 0%)\n",
            "updating: fairseq/examples/data2vec/config/audio/ (stored 0%)\n",
            "updating: fairseq/examples/data2vec/config/audio/pretraining/ (stored 0%)\n",
            "updating: fairseq/examples/data2vec/config/audio/pretraining/base_librispeech.yaml (deflated 51%)\n",
            "updating: fairseq/examples/data2vec/config/text/ (stored 0%)\n",
            "updating: fairseq/examples/data2vec/config/text/pretraining/ (stored 0%)\n",
            "updating: fairseq/examples/data2vec/config/text/pretraining/base.yaml (deflated 52%)\n",
            "updating: fairseq/examples/data2vec/README.md (deflated 64%)\n",
            "updating: fairseq/examples/mbart/ (stored 0%)\n",
            "updating: fairseq/examples/mbart/README.md (deflated 58%)\n",
            "updating: fairseq/examples/fully_sharded_data_parallel/ (stored 0%)\n",
            "updating: fairseq/examples/fully_sharded_data_parallel/README.md (deflated 73%)\n",
            "updating: fairseq/examples/fast_noisy_channel/ (stored 0%)\n",
            "updating: fairseq/examples/fast_noisy_channel/noisy_channel_translation.py (deflated 72%)\n",
            "updating: fairseq/examples/fast_noisy_channel/noisy_channel_sequence_generator.py (deflated 77%)\n",
            "updating: fairseq/examples/fast_noisy_channel/README.md (deflated 77%)\n",
            "updating: fairseq/examples/fast_noisy_channel/__init__.py (deflated 42%)\n",
            "updating: fairseq/examples/fast_noisy_channel/noisy_channel_beam_search.py (deflated 65%)\n",
            "updating: fairseq/examples/textless_nlp/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/tools/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/tools/resynthesize_speech.py (deflated 67%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/tools/README.md (deflated 51%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/abx_metrics/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/abx_metrics/dump_abx_feats.py (deflated 63%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/abx_metrics/README.md (deflated 54%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/README.md (deflated 39%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/cut_as.py (deflated 56%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/dict.ltr.txt (deflated 31%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/bleu_utils.py (deflated 67%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/ppx.py (deflated 61%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/README.md (deflated 61%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/self_auto_bleu.py (deflated 69%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/continuation_eval.py (deflated 60%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/README.md (deflated 69%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/utils.py (deflated 70%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/w2v2_feature_reader.py (deflated 54%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/cpc_feature_reader.py (deflated 73%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/hubert_feature_reader.py (deflated 57%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/logmel_feature_reader.py (deflated 49%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/clustering/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/clustering/utils.py (deflated 44%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/clustering/cluster_kmeans.py (deflated 72%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/clustering/quantize_with_kmeans.py (deflated 66%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/clustering/dump_feats.py (deflated 63%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/speech2unit/clustering/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/glow.py (deflated 72%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/convert_to_16k.py (deflated 60%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/utils.py (deflated 59%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/synthesize_audio_from_units.py (deflated 66%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tts_data.py (deflated 64%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/README.md (deflated 72%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/multiproc.py (deflated 48%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/waveglow_denoiser.py (deflated 63%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/utils.py (deflated 68%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/cmudict.py (deflated 56%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/symbols.py (deflated 36%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/text.py (deflated 60%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/stft.py (deflated 64%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py (deflated 82%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/cleaners.py (deflated 61%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/audio_processing.py (deflated 59%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/layers.py (deflated 68%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/numbers.py (deflated 68%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/ulm/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/ulm/sample.py (deflated 64%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/ulm/README.md (deflated 63%)\n",
            "updating: fairseq/examples/textless_nlp/gslm/README.md (deflated 52%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/generate_waveform.py (deflated 59%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/eval/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/eval/cont_metrics.py (deflated 78%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/eval/__init__.py (deflated 25%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/inference_dataset.py (deflated 68%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/quantize_f0.py (deflated 63%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/prepare_dataset.py (deflated 66%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/preprocess_f0.py (deflated 56%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/data_utils.py (deflated 65%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/truncated_laplace.py (deflated 48%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/scripts/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/scripts/join_units_manifest.py (deflated 60%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/scripts/prepare_f0_quantization.sh (deflated 52%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/scripts/prepare_data.sh (deflated 54%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/sample/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/sample/sample.py (deflated 75%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/sample/__init__.py (deflated 25%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/README.md (deflated 66%)\n",
            "updating: fairseq/examples/textless_nlp/pgslm/naive_decoder.py (deflated 55%)\n",
            "updating: fairseq/examples/textless_nlp/speech-resynth/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/speech-resynth/img/ (stored 0%)\n",
            "updating: fairseq/examples/textless_nlp/speech-resynth/img/fig.png (deflated 3%)\n",
            "updating: fairseq/examples/textless_nlp/speech-resynth/README.md (deflated 55%)\n",
            "updating: fairseq/examples/attention_head_selection/ (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/README.md (deflated 76%)\n",
            "updating: fairseq/examples/attention_head_selection/src/ (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/models/ (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/models/head_selection_s2t_transformer.py (deflated 76%)\n",
            "updating: fairseq/examples/attention_head_selection/src/models/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/models/head_selection_transformer.py (deflated 81%)\n",
            "updating: fairseq/examples/attention_head_selection/src/data/ (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/data/speech_to_text_dataset_with_domain.py (deflated 76%)\n",
            "updating: fairseq/examples/attention_head_selection/src/data/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/modules/ (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/modules/attn_head_selector.py (deflated 69%)\n",
            "updating: fairseq/examples/attention_head_selection/src/modules/multihead_functional.py (deflated 75%)\n",
            "updating: fairseq/examples/attention_head_selection/src/modules/head_selection_transformer_layer.py (deflated 80%)\n",
            "updating: fairseq/examples/attention_head_selection/src/modules/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/modules/multihead_attention_selection.py (deflated 79%)\n",
            "updating: fairseq/examples/attention_head_selection/src/speech_to_text_head_selection.py (deflated 76%)\n",
            "updating: fairseq/examples/attention_head_selection/src/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/loss/ (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/loss/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/attention_head_selection/src/loss/attention_head_selection.py (deflated 51%)\n",
            "updating: fairseq/examples/wmt21/ (stored 0%)\n",
            "updating: fairseq/examples/wmt21/scripts/ (stored 0%)\n",
            "updating: fairseq/examples/wmt21/scripts/normalize-punctuation.perl (deflated 56%)\n",
            "updating: fairseq/examples/wmt21/scripts/replace-unicode-punctuation.perl (deflated 46%)\n",
            "updating: fairseq/examples/wmt21/eval.sh (deflated 52%)\n",
            "updating: fairseq/examples/wmt21/README.md (deflated 43%)\n",
            "updating: fairseq/examples/__init__.py (deflated 30%)\n",
            "updating: fairseq/examples/nonautoregressive_translation/ (stored 0%)\n",
            "updating: fairseq/examples/nonautoregressive_translation/README.md (deflated 61%)\n",
            "updating: fairseq/examples/nonautoregressive_translation/scripts.md (deflated 82%)\n",
            "updating: fairseq/examples/wav2vec/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/xlsr/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/xlsr/config/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/xlsr/config/finetune.yaml (deflated 50%)\n",
            "updating: fairseq/examples/wav2vec/xlsr/README.md (deflated 58%)\n",
            "updating: fairseq/examples/wav2vec/wav2vec_manifest.py (deflated 61%)\n",
            "updating: fairseq/examples/wav2vec/config/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/config/pretraining/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox.yaml (deflated 51%)\n",
            "updating: fairseq/examples/wav2vec/config/pretraining/wav2vec2_base_librispeech.yaml (deflated 48%)\n",
            "updating: fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox_tpu-pod.yaml (deflated 51%)\n",
            "updating: fairseq/examples/wav2vec/config/pretraining/wav2vec2_conformer_base_librispeech.yaml (deflated 48%)\n",
            "updating: fairseq/examples/wav2vec/config/pretraining/wav2vec2_conformer_large_librivox.yaml (deflated 51%)\n",
            "updating: fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox_tpu.yaml (deflated 51%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/vox_10h.yaml (deflated 49%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/base_10h.yaml (deflated 49%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/base_960h.yaml (deflated 46%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/base_100h.yaml (deflated 46%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/vox_10m.yaml (deflated 49%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/vox_1h.yaml (deflated 49%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/vox_960h.yaml (deflated 46%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/vox_100h.yaml (deflated 46%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/base_1h.yaml (deflated 49%)\n",
            "updating: fairseq/examples/wav2vec/config/finetuning/base_10m.yaml (deflated 49%)\n",
            "updating: fairseq/examples/wav2vec/scripts/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/scripts/binarize_manifest.sh (deflated 60%)\n",
            "updating: fairseq/examples/wav2vec/libri_labels.py (deflated 60%)\n",
            "updating: fairseq/examples/wav2vec/README.md (deflated 76%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/models/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/models/wav2vec_u.py (deflated 76%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/models/__init__.py (deflated 27%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/generate/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/generate/viterbi.yaml (deflated 33%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/gan/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/gan/w2vu.yaml (deflated 62%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/train.uid (deflated 72%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/valid.uid (deflated 64%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/test.uid (deflated 75%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/train_text.uid (deflated 67%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/finetuning/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/finetuning/w2v_finetune.yaml (deflated 47%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_matched/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_matched/train.uid (deflated 73%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_matched/valid.uid (deflated 75%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_matched/test.uid (deflated 75%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/config/timit_matched/train_text.uid (deflated 73%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/data/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/data/random_input_dataset.py (deflated 66%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/data/extracted_features_dataset.py (deflated 66%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/data/__init__.py (deflated 42%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/w2vu_generate.py (deflated 74%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/ltr_to_wrd.py (deflated 32%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/filter_tsv.py (deflated 48%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/phonemize_with_sil.py (deflated 61%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/normalize_and_filter_text.py (deflated 56%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/wer.py (deflated 57%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/prepare_text.sh (deflated 71%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/copy_labels.py (deflated 26%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/mean_pool.py (deflated 63%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/g2p_wrd_to_phn.py (deflated 53%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/remove_silence.py (deflated 56%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_cluster_faiss.py (deflated 64%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/prepare_timit.sh (deflated 61%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_apply_cluster_faiss.py (deflated 64%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/prepare_audio.sh (deflated 67%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/apply_pca.py (deflated 60%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/merge_clusters.py (deflated 64%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/filter_lexicon.py (deflated 48%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/vads.py (deflated 55%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_extract_features.py (deflated 62%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/pca.py (deflated 53%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/normalize_text.py (deflated 38%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/scripts/wrd_to_ltr.py (deflated 30%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_lda_mllt.sh (deflated 63%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_deltas.sh (deflated 60%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_sat.sh (deflated 66%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/path.sh (deflated 42%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/cmd.sh (deflated 48%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_word_step2.sh (deflated 47%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select.py (deflated 66%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/score.sh (deflated 54%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lang.sh (deflated 60%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/copy_aligned_text.py (deflated 8%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lm.sh (deflated 51%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/decode.sh (deflated 48%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select_decode_word.sh (deflated 43%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lang_word.sh (deflated 56%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/show_wer.sh (deflated 62%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/train_subset_lgbeam.sh (deflated 74%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select_decode.sh (deflated 43%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_data_from_w2v.py (deflated 63%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/train.sh (deflated 57%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_word_step1.sh (deflated 57%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_phone.sh (deflated 47%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/kaldi_self_train/README.md (deflated 57%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/README.md (deflated 58%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/tasks/ (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/tasks/__init__.py (deflated 30%)\n",
            "updating: fairseq/examples/wav2vec/unsupervised/tasks/unpaired_audio_text.py (deflated 76%)\n",
            "updating: fairseq/examples/wav2vec/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/wav2vec/wav2vec_featurize.py (deflated 68%)\n",
            "updating: fairseq/examples/wav2vec/vq-wav2vec_featurize.py (deflated 69%)\n",
            "updating: fairseq/examples/xglm/ (stored 0%)\n",
            "updating: fairseq/examples/xglm/model_card.md (deflated 58%)\n",
            "updating: fairseq/examples/xglm/README.md (deflated 63%)\n",
            "updating: fairseq/examples/multilingual/ (stored 0%)\n",
            "updating: fairseq/examples/multilingual/train_multilingual_model.sh (deflated 48%)\n",
            "updating: fairseq/examples/multilingual/finetune_multilingual_model.sh (deflated 49%)\n",
            "updating: fairseq/examples/multilingual/multilingual_fairseq_gen.sh (deflated 45%)\n",
            "updating: fairseq/examples/multilingual/README.md (deflated 69%)\n",
            "updating: fairseq/examples/multilingual/ML50_langs.txt (deflated 30%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/ (stored 0%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_ted_and_extract.py (deflated 72%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_flores_data.sh (deflated 73%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_ML50_v1.sh (deflated 47%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/requirement.txt (stored 0%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/check_valid_test_overlaps.py (deflated 68%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/binarize.py (deflated 70%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_wmt19_and_before.py (deflated 78%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_iitb.sh (deflated 55%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_iwslt_and_extract.sh (deflated 71%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/preprocess_ML50_v1.sh (deflated 47%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/check_self_overlaps.py (deflated 67%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/check_iswlt_test_data.py (deflated 60%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/dedup_all.py (deflated 60%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_wmt20.sh (deflated 79%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_af_xh.sh (deflated 69%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/utils/ (stored 0%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/utils/strip_sgm.sh (deflated 24%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/utils/fasttext_multi_filter.py (deflated 60%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/utils/dedup.py (deflated 63%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/README.md (deflated 49%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_lotus.sh (deflated 69%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/download_wat19_my.sh (deflated 54%)\n",
            "updating: fairseq/examples/multilingual/data_scripts/remove_valid_test_in_train.py (deflated 76%)\n",
            "updating: fairseq/examples/speech_to_text/ (stored 0%)\n",
            "updating: fairseq/examples/speech_to_text/seg_mustc_data.py (deflated 56%)\n",
            "updating: fairseq/examples/speech_to_text/docs/ (stored 0%)\n",
            "updating: fairseq/examples/speech_to_text/docs/simulst_mustc_example.md (deflated 62%)\n",
            "updating: fairseq/examples/speech_to_text/docs/covost_example.md (deflated 81%)\n",
            "updating: fairseq/examples/speech_to_text/docs/mustc_example.md (deflated 78%)\n",
            "updating: fairseq/examples/speech_to_text/docs/mtedx_example.md (deflated 72%)\n",
            "updating: fairseq/examples/speech_to_text/docs/librispeech_example.md (deflated 55%)\n",
            "updating: fairseq/examples/speech_to_text/data_utils.py (deflated 70%)\n",
            "updating: fairseq/examples/speech_to_text/simultaneous_translation/ (stored 0%)\n",
            "updating: fairseq/examples/speech_to_text/simultaneous_translation/agents/ (stored 0%)\n",
            "updating: fairseq/examples/speech_to_text/simultaneous_translation/agents/fairseq_simul_st_agent.py (deflated 71%)\n",
            "updating: fairseq/examples/speech_to_text/prep_mustc_data.py (deflated 71%)\n",
            "updating: fairseq/examples/speech_to_text/README.md (deflated 56%)\n",
            "updating: fairseq/examples/speech_to_text/prep_covost_data.py (deflated 66%)\n",
            "updating: fairseq/examples/speech_to_text/prep_librispeech_data.py (deflated 62%)\n",
            "updating: fairseq/examples/speech_to_text/prep_mtedx_data.py (deflated 70%)\n",
            "updating: fairseq/examples/speech_to_speech/ (stored 0%)\n",
            "updating: fairseq/examples/speech_to_speech/preprocessing/ (stored 0%)\n",
            "updating: fairseq/examples/speech_to_speech/preprocessing/prep_s2ut_data.py (deflated 63%)\n",
            "updating: fairseq/examples/speech_to_speech/preprocessing/prep_s2spect_data.py (deflated 67%)\n",
            "updating: fairseq/examples/speech_to_speech/preprocessing/data_utils.py (deflated 69%)\n",
            "updating: fairseq/examples/speech_to_speech/preprocessing/__init__.py (deflated 25%)\n",
            "updating: fairseq/examples/speech_to_speech/generate_waveform_from_code.py (deflated 60%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/ (stored 0%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/configs/ (stored 0%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/configs/2StageS2ST.yaml (deflated 51%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/configs/3StageS2ST.yaml (deflated 61%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/configs/S2T.yaml (deflated 33%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/configs/DirectS2U.yaml (deflated 47%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/data_utils.py (deflated 70%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/core.py (deflated 77%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/README.md (deflated 52%)\n",
            "updating: fairseq/examples/speech_to_speech/benchmarking/get_metrics.py (deflated 67%)\n",
            "updating: fairseq/examples/speech_to_speech/README.md (deflated 67%)\n",
            "updating: fairseq/examples/speech_to_speech/__init__.py (deflated 25%)\n",
            "updating: fairseq/examples/byte_level_bpe/ (stored 0%)\n",
            "updating: fairseq/examples/byte_level_bpe/get_data.sh (deflated 66%)\n",
            "updating: fairseq/examples/byte_level_bpe/README.md (deflated 62%)\n",
            "updating: fairseq/examples/byte_level_bpe/gru_transformer.py (deflated 78%)\n",
            "updating: fairseq/examples/byte_level_bpe/get_bitext.py (deflated 78%)\n",
            "updating: fairseq/examples/gottbert/ (stored 0%)\n",
            "updating: fairseq/examples/gottbert/README.md (deflated 51%)\n",
            "updating: fairseq/examples/latent_depth/ (stored 0%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/ (stored 0%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/models/ (stored 0%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/models/latent_multilingual_transformer.py (deflated 72%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/models/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/models/latent_transformer.py (deflated 77%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/multilingual_translation_latent_depth.py (deflated 78%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/modules/ (stored 0%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/modules/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/modules/latent_layers.py (deflated 61%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/__init__.py (deflated 46%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/loss/ (stored 0%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/loss/__init__.py (stored 0%)\n",
            "updating: fairseq/examples/latent_depth/latent_depth_src/loss/latent_depth.py (deflated 72%)\n",
            "updating: fairseq/examples/latent_depth/README.md (deflated 56%)\n",
            "updating: fairseq/examples/paraphraser/ (stored 0%)\n",
            "updating: fairseq/examples/paraphraser/README.md (deflated 75%)\n",
            "updating: fairseq/examples/paraphraser/paraphrase.py (deflated 63%)\n",
            "updating: fairseq/examples/xlmr/ (stored 0%)\n",
            "updating: fairseq/examples/xlmr/README.md (deflated 57%)\n",
            "updating: fairseq/examples/truncated_bptt/ (stored 0%)\n",
            "updating: fairseq/examples/truncated_bptt/truncated_bptt_lm_task.py (deflated 67%)\n",
            "updating: fairseq/examples/truncated_bptt/README.md (deflated 53%)\n",
            "updating: fairseq/examples/truncated_bptt/__init__.py (deflated 27%)\n",
            "updating: fairseq/examples/truncated_bptt/transformer_xl_model.py (deflated 67%)\n",
            "updating: fairseq/.gitmodules (deflated 31%)\n",
            "updating: fairseq/.github/ (stored 0%)\n",
            "updating: fairseq/.github/ISSUE_TEMPLATE/ (stored 0%)\n",
            "updating: fairseq/.github/ISSUE_TEMPLATE/documentation.md (deflated 30%)\n",
            "updating: fairseq/.github/ISSUE_TEMPLATE/how-to-question.md (deflated 44%)\n",
            "updating: fairseq/.github/ISSUE_TEMPLATE/feature_request.md (deflated 49%)\n",
            "updating: fairseq/.github/ISSUE_TEMPLATE/bug_report.md (deflated 46%)\n",
            "updating: fairseq/.github/workflows/ (stored 0%)\n",
            "updating: fairseq/.github/workflows/build_wheels.yml (deflated 54%)\n",
            "updating: fairseq/.github/workflows/build.yml (deflated 58%)\n",
            "updating: fairseq/.github/stale.yml (deflated 63%)\n",
            "updating: fairseq/.github/PULL_REQUEST_TEMPLATE.md (deflated 36%)\n",
            "updating: fairseq/.github/ISSUE_TEMPLATE.md (deflated 29%)\n",
            "updating: fairseq/build/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/examples/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/examples/operators/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/examples/operators/alignment_train_cpu.o (deflated 78%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/data/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.o (deflated 81%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/data/data_utils_fast.o (deflated 81%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/clib/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/clib/libbase/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/clib/libbase/balanced_assignment.o (deflated 78%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/libbleu.o (deflated 75%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/module.o (deflated 66%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/clib/libnat/ (stored 0%)\n",
            "updating: fairseq/build/temp.linux-x86_64-3.7/fairseq/clib/libnat/edit_dist.o (deflated 79%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/ (stored 0%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/alignment_train_cpu_binding.cpython-37m-x86_64-linux-gnu.so (deflated 73%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/fairseq/ (stored 0%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/fairseq/libbase.cpython-37m-x86_64-linux-gnu.so (deflated 73%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/fairseq/libbleu.cpython-37m-x86_64-linux-gnu.so (deflated 62%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/fairseq/data/ (stored 0%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.cpython-37m-x86_64-linux-gnu.so (deflated 69%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/fairseq/data/data_utils_fast.cpython-37m-x86_64-linux-gnu.so (deflated 69%)\n",
            "updating: fairseq/build/lib.linux-x86_64-3.7/fairseq/libnat.cpython-37m-x86_64-linux-gnu.so (deflated 73%)\n",
            "updating: fairseq/.git/ (stored 0%)\n",
            "updating: fairseq/.git/HEAD (stored 0%)\n",
            "updating: fairseq/.git/config (deflated 34%)\n",
            "updating: fairseq/.git/description (deflated 14%)\n",
            "updating: fairseq/.git/index (deflated 61%)\n",
            "updating: fairseq/.git/packed-refs (deflated 51%)\n",
            "updating: fairseq/.git/info/ (stored 0%)\n",
            "updating: fairseq/.git/info/exclude (deflated 28%)\n",
            "updating: fairseq/.git/logs/ (stored 0%)\n",
            "updating: fairseq/.git/logs/HEAD (deflated 29%)\n",
            "updating: fairseq/.git/logs/refs/ (stored 0%)\n",
            "updating: fairseq/.git/logs/refs/heads/ (stored 0%)\n",
            "updating: fairseq/.git/logs/refs/heads/main (deflated 29%)\n",
            "updating: fairseq/.git/logs/refs/remotes/ (stored 0%)\n",
            "updating: fairseq/.git/logs/refs/remotes/origin/ (stored 0%)\n",
            "updating: fairseq/.git/logs/refs/remotes/origin/HEAD (deflated 29%)\n",
            "updating: fairseq/.git/branches/ (stored 0%)\n",
            "updating: fairseq/.git/refs/ (stored 0%)\n",
            "updating: fairseq/.git/refs/tags/ (stored 0%)\n",
            "updating: fairseq/.git/refs/heads/ (stored 0%)\n",
            "updating: fairseq/.git/refs/heads/main (stored 0%)\n",
            "updating: fairseq/.git/refs/remotes/ (stored 0%)\n",
            "updating: fairseq/.git/refs/remotes/origin/ (stored 0%)\n",
            "updating: fairseq/.git/refs/remotes/origin/HEAD (stored 0%)\n",
            "updating: fairseq/.git/hooks/ (stored 0%)\n",
            "updating: fairseq/.git/hooks/fsmonitor-watchman.sample (deflated 53%)\n",
            "updating: fairseq/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "updating: fairseq/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "updating: fairseq/.git/hooks/post-update.sample (deflated 27%)\n",
            "updating: fairseq/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "updating: fairseq/.git/hooks/pre-commit.sample (deflated 43%)\n",
            "updating: fairseq/.git/hooks/update.sample (deflated 68%)\n",
            "updating: fairseq/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "updating: fairseq/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "updating: fairseq/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "updating: fairseq/.git/hooks/pre-push.sample (deflated 50%)\n",
            "updating: fairseq/.git/objects/ (stored 0%)\n",
            "updating: fairseq/.git/objects/pack/ (stored 0%)\n",
            "updating: fairseq/.git/objects/pack/pack-9d973bac802ceacf2550f45f3c8ca5df45db7466.idx (deflated 2%)\n",
            "updating: fairseq/.git/objects/pack/pack-9d973bac802ceacf2550f45f3c8ca5df45db7466.pack (deflated 2%)\n",
            "updating: fairseq/.git/objects/info/ (stored 0%)\n",
            "updating: fairseq/CODE_OF_CONDUCT.md (deflated 55%)\n",
            "updating: fairseq/.circleci/ (stored 0%)\n",
            "updating: fairseq/.circleci/config.yml (deflated 72%)\n",
            "updating: fairseq/scripts/ (stored 0%)\n",
            "updating: fairseq/scripts/test_fsdp.sh (deflated 64%)\n",
            "updating: fairseq/scripts/spm_decode.py (deflated 56%)\n",
            "updating: fairseq/scripts/convert_model.lua (deflated 71%)\n",
            "updating: fairseq/scripts/constraints/ (stored 0%)\n",
            "updating: fairseq/scripts/constraints/extract.py (deflated 67%)\n",
            "updating: fairseq/scripts/constraints/validate.py (deflated 49%)\n",
            "updating: fairseq/scripts/count_docs.py (deflated 61%)\n",
            "updating: fairseq/scripts/shard_docs.py (deflated 59%)\n",
            "updating: fairseq/scripts/average_checkpoints.py (deflated 68%)\n",
            "updating: fairseq/scripts/build_sym_alignment.py (deflated 67%)\n",
            "updating: fairseq/scripts/compound_split_bleu.sh (deflated 39%)\n",
            "updating: fairseq/scripts/compare_namespaces.py (deflated 60%)\n",
            "updating: fairseq/scripts/spm_train.py (deflated 34%)\n",
            "updating: fairseq/scripts/read_binarized.py (deflated 54%)\n",
            "updating: fairseq/scripts/__init__.py (stored 0%)\n",
            "updating: fairseq/scripts/convert_dictionary.lua (deflated 45%)\n",
            "updating: fairseq/scripts/sacrebleu.sh (deflated 38%)\n",
            "updating: fairseq/scripts/spm_encode.py (deflated 66%)\n",
            "updating: fairseq/scripts/split_train_valid_docs.py (deflated 66%)\n",
            "updating: fairseq/scripts/rm_pt.py (deflated 71%)\n",
            "updating: fairseq/setup.cfg (deflated 7%)\n",
            "updating: fairseq/LICENSE (deflated 41%)\n",
            "updating: fairseq/setup.py (deflated 70%)\n",
            "updating: fairseq/pyproject.toml (deflated 18%)\n",
            "updating: fairseq/tests/ (stored 0%)\n",
            "updating: fairseq/tests/test_multi_corpus_dataset.py (deflated 68%)\n",
            "updating: fairseq/tests/test_espnet_multihead_attention.py (deflated 82%)\n",
            "updating: fairseq/tests/test_metrics.py (deflated 79%)\n",
            "updating: fairseq/tests/test_reproducibility.py (deflated 77%)\n",
            "updating: fairseq/tests/test_file_chunker_utils.py (deflated 65%)\n",
            "updating: fairseq/tests/test_binarizer.py (deflated 73%)\n",
            "updating: fairseq/tests/test_positional_encoding.py (deflated 71%)\n",
            "updating: fairseq/tests/test_iterators.py (deflated 82%)\n",
            "updating: fairseq/tests/test_concat_dataset.py (deflated 72%)\n",
            "updating: fairseq/tests/test_constraints.py (deflated 82%)\n",
            "updating: fairseq/tests/test_sequence_scorer.py (deflated 72%)\n",
            "updating: fairseq/tests/utils.py (deflated 79%)\n",
            "updating: fairseq/tests/test_utils.py (deflated 75%)\n",
            "updating: fairseq/tests/test_noising.py (deflated 82%)\n",
            "updating: fairseq/tests/test_transformer.py (deflated 62%)\n",
            "updating: fairseq/tests/test_valid_subset_checks.py (deflated 73%)\n",
            "updating: fairseq/tests/test_online_backtranslation.py (deflated 70%)\n",
            "updating: fairseq/tests/test_token_block_dataset.py (deflated 76%)\n",
            "updating: fairseq/tests/test_multi_corpus_sampled_dataset.py (deflated 70%)\n",
            "updating: fairseq/tests/test_checkpoint_utils.py (deflated 71%)\n",
            "updating: fairseq/tests/speech_recognition/ (stored 0%)\n",
            "updating: fairseq/tests/speech_recognition/test_cross_entropy.py (deflated 68%)\n",
            "updating: fairseq/tests/speech_recognition/test_collaters.py (deflated 62%)\n",
            "updating: fairseq/tests/speech_recognition/asr_test_base.py (deflated 79%)\n",
            "updating: fairseq/tests/speech_recognition/__init__.py (stored 0%)\n",
            "updating: fairseq/tests/speech_recognition/test_vggtransformer.py (deflated 81%)\n",
            "updating: fairseq/tests/speech_recognition/test_data_utils.py (deflated 69%)\n",
            "updating: fairseq/tests/test_multihead_attention.py (deflated 71%)\n",
            "updating: fairseq/tests/test_activation_checkpointing.py (deflated 69%)\n",
            "updating: fairseq/tests/distributed/ (stored 0%)\n",
            "updating: fairseq/tests/distributed/test_module_proxy_wrapper.py (deflated 70%)\n",
            "updating: fairseq/tests/distributed/test_distributed_timeout_wrapper.py (deflated 63%)\n",
            "updating: fairseq/tests/distributed/utils.py (deflated 60%)\n",
            "updating: fairseq/tests/distributed/test_utils.py (deflated 77%)\n",
            "updating: fairseq/tests/distributed/test_bmuf.py (deflated 73%)\n",
            "updating: fairseq/tests/distributed/__init__.py (stored 0%)\n",
            "updating: fairseq/tests/test_dictionary.py (deflated 71%)\n",
            "updating: fairseq/tests/speech/ (stored 0%)\n",
            "updating: fairseq/tests/speech/test_wav2vec2.py (deflated 66%)\n",
            "updating: fairseq/tests/speech/test_fastspeech2.py (deflated 55%)\n",
            "updating: fairseq/tests/speech/test_xm_transformer.py (deflated 48%)\n",
            "updating: fairseq/tests/speech/test_tts_transformer.py (deflated 55%)\n",
            "updating: fairseq/tests/speech/test_s2s_transformer.py (deflated 57%)\n",
            "updating: fairseq/tests/speech/test_s2t_conformer.py (deflated 45%)\n",
            "updating: fairseq/tests/speech/test_dualinput_s2t_transformer.py (deflated 63%)\n",
            "updating: fairseq/tests/speech/test_convtransformer_simul_trans.py (deflated 48%)\n",
            "updating: fairseq/tests/speech/__init__.py (deflated 70%)\n",
            "updating: fairseq/tests/speech/test_s2t_transformer.py (deflated 46%)\n",
            "updating: fairseq/tests/test_dataclass_utils.py (deflated 74%)\n",
            "updating: fairseq/tests/test_dataset.py (deflated 72%)\n",
            "updating: fairseq/tests/test_sequence_generator.py (deflated 84%)\n",
            "updating: fairseq/tests/test_backtranslation_dataset.py (deflated 73%)\n",
            "updating: fairseq/tests/test_huffman.py (deflated 78%)\n",
            "updating: fairseq/tests/test_sparse_multihead_attention.py (deflated 86%)\n",
            "updating: fairseq/tests/test_inference_dropout.py (deflated 79%)\n",
            "updating: fairseq/tests/test_fp16_optimizer.py (deflated 69%)\n",
            "updating: fairseq/tests/gpu/ (stored 0%)\n",
            "updating: fairseq/tests/gpu/test_ema_gpu.py (deflated 78%)\n",
            "updating: fairseq/tests/gpu/test_binaries_gpu.py (deflated 83%)\n",
            "updating: fairseq/tests/gpu/transformer_quantization_config.yaml (deflated 48%)\n",
            "updating: fairseq/tests/gpu/__init__.py (stored 0%)\n",
            "updating: fairseq/tests/test_hf_hub.py (deflated 45%)\n",
            "updating: fairseq/tests/test_iopath.py (deflated 56%)\n",
            "updating: fairseq/tests/test_character_token_embedder.py (deflated 59%)\n",
            "updating: fairseq/tests/test_file_io.py (deflated 64%)\n",
            "updating: fairseq/tests/test_plasma_utils.py (deflated 73%)\n",
            "updating: fairseq/tests/test_convtbc.py (deflated 65%)\n",
            "updating: fairseq/tests/__init__.py (stored 0%)\n",
            "updating: fairseq/tests/test_binaries.py (deflated 90%)\n",
            "updating: fairseq/tests/test_export.py (deflated 69%)\n",
            "updating: fairseq/tests/test_rotary_positional_embedding.py (deflated 73%)\n",
            "updating: fairseq/tests/test_lstm_jitable.py (deflated 65%)\n",
            "updating: fairseq/tests/test_train.py (deflated 80%)\n",
            "updating: fairseq/tests/test_amp_optimizer.py (deflated 63%)\n",
            "updating: fairseq/tests/test_lm_context_window.py (deflated 65%)\n",
            "updating: fairseq/tests/test_roberta.py (deflated 75%)\n",
            "updating: fairseq/tests/test_label_smoothing.py (deflated 73%)\n",
            "updating: fairseq/tests/test_data_utils.py (deflated 73%)\n",
            "updating: fairseq/tests/test_resampling_dataset.py (deflated 70%)\n",
            "updating: fairseq/tests/test_average_checkpoints.py (deflated 71%)\n",
            "updating: fairseq/tests/test_ema.py (deflated 80%)\n",
            "updating: fairseq/tests/test_memory_efficient_fp16.py (deflated 64%)\n",
            "updating: fairseq/alignment_train_cpu_binding.cpython-37m-x86_64-linux-gnu.so (deflated 73%)\n",
            "updating: fairseq/train.py (deflated 34%)\n",
            "updating: fairseq/README.md (deflated 69%)\n",
            "updating: fairseq/.pre-commit-config.yaml (deflated 55%)\n",
            "updating: fairseq/fairseq_cli/ (stored 0%)\n",
            "updating: fairseq/fairseq_cli/preprocess.py (deflated 76%)\n",
            "updating: fairseq/fairseq_cli/generate.py (deflated 72%)\n",
            "updating: fairseq/fairseq_cli/eval_lm.py (deflated 68%)\n",
            "updating: fairseq/fairseq_cli/hydra_train.py (deflated 61%)\n",
            "updating: fairseq/fairseq_cli/score.py (deflated 68%)\n",
            "updating: fairseq/fairseq_cli/interactive.py (deflated 70%)\n",
            "updating: fairseq/fairseq_cli/train.py (deflated 72%)\n",
            "updating: fairseq/fairseq_cli/__init__.py (stored 0%)\n",
            "updating: fairseq/fairseq_cli/validate.py (deflated 64%)\n",
            "updating: fairseq/fairseq/ (stored 0%)\n",
            "updating: fairseq/fairseq/version.py (stored 0%)\n",
            "updating: fairseq/fairseq/logging/ (stored 0%)\n",
            "updating: fairseq/fairseq/logging/metrics.py (deflated 74%)\n",
            "updating: fairseq/fairseq/logging/progress_bar.py (deflated 79%)\n",
            "updating: fairseq/fairseq/logging/meters.py (deflated 76%)\n",
            "updating: fairseq/fairseq/logging/__init__.py (stored 0%)\n",
            "updating: fairseq/fairseq/libbase.cpython-37m-x86_64-linux-gnu.so (deflated 73%)\n",
            "updating: fairseq/fairseq/registry.py (deflated 70%)\n",
            "updating: fairseq/fairseq/nan_detector.py (deflated 67%)\n",
            "updating: fairseq/fairseq/pdb.py (deflated 55%)\n",
            "updating: fairseq/fairseq/utils.py (deflated 70%)\n",
            "updating: fairseq/fairseq/tokenizer.py (deflated 33%)\n",
            "updating: fairseq/fairseq/binarizer.py (deflated 76%)\n",
            "updating: fairseq/fairseq/models/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/distributed_fairseq_model.py (deflated 71%)\n",
            "updating: fairseq/fairseq/models/model_utils.py (deflated 65%)\n",
            "updating: fairseq/fairseq/models/fconv_lm.py (deflated 75%)\n",
            "updating: fairseq/fairseq/models/roberta/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/roberta/alignment_utils.py (deflated 65%)\n",
            "updating: fairseq/fairseq/models/roberta/model_camembert.py (deflated 69%)\n",
            "updating: fairseq/fairseq/models/roberta/model.py (deflated 77%)\n",
            "updating: fairseq/fairseq/models/roberta/model_xlmr.py (deflated 61%)\n",
            "updating: fairseq/fairseq/models/roberta/enc_dec.py (deflated 73%)\n",
            "updating: fairseq/fairseq/models/roberta/__init__.py (deflated 50%)\n",
            "updating: fairseq/fairseq/models/roberta/model_gottbert.py (deflated 58%)\n",
            "updating: fairseq/fairseq/models/roberta/hub_interface.py (deflated 69%)\n",
            "updating: fairseq/fairseq/models/huggingface/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/huggingface/hf_gpt2.py (deflated 72%)\n",
            "updating: fairseq/fairseq/models/huggingface/__init__.py (deflated 49%)\n",
            "updating: fairseq/fairseq/models/ema/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/ema/ema.py (deflated 67%)\n",
            "updating: fairseq/fairseq/models/ema/__init__.py (deflated 43%)\n",
            "updating: fairseq/fairseq/models/multilingual_transformer.py (deflated 78%)\n",
            "updating: fairseq/fairseq/models/lightconv.py (deflated 83%)\n",
            "updating: fairseq/fairseq/models/fairseq_decoder.py (deflated 66%)\n",
            "updating: fairseq/fairseq/models/lstm_lm.py (deflated 74%)\n",
            "updating: fairseq/fairseq/models/hubert/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/hubert/hubert.py (deflated 76%)\n",
            "updating: fairseq/fairseq/models/hubert/hubert_asr.py (deflated 75%)\n",
            "updating: fairseq/fairseq/models/hubert/__init__.py (deflated 34%)\n",
            "updating: fairseq/fairseq/models/lightconv_lm.py (deflated 80%)\n",
            "updating: fairseq/fairseq/models/bart/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/bart/model.py (deflated 77%)\n",
            "updating: fairseq/fairseq/models/bart/__init__.py (deflated 32%)\n",
            "updating: fairseq/fairseq/models/bart/hub_interface.py (deflated 68%)\n",
            "updating: fairseq/fairseq/models/fairseq_model.py (deflated 77%)\n",
            "updating: fairseq/fairseq/models/transformer_align.py (deflated 70%)\n",
            "updating: fairseq/fairseq/models/transformer_lm.py (deflated 84%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/tts_transformer.py (deflated 78%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/hifigan.py (deflated 81%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/fastspeech2.py (deflated 77%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/codehifigan.py (deflated 69%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/__init__.py (deflated 37%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/vocoder.py (deflated 72%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/tacotron2.py (deflated 78%)\n",
            "updating: fairseq/fairseq/models/text_to_speech/hub_interface.py (deflated 68%)\n",
            "updating: fairseq/fairseq/models/fconv.py (deflated 78%)\n",
            "updating: fairseq/fairseq/models/transformer/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/transformer/transformer_base.py (deflated 68%)\n",
            "updating: fairseq/fairseq/models/transformer/transformer_encoder.py (deflated 75%)\n",
            "updating: fairseq/fairseq/models/transformer/transformer_decoder.py (deflated 76%)\n",
            "updating: fairseq/fairseq/models/transformer/__init__.py (deflated 69%)\n",
            "updating: fairseq/fairseq/models/transformer/transformer_config.py (deflated 72%)\n",
            "updating: fairseq/fairseq/models/transformer/transformer_legacy.py (deflated 82%)\n",
            "updating: fairseq/fairseq/models/transformer_ulm.py (deflated 77%)\n",
            "updating: fairseq/fairseq/models/lstm.py (deflated 80%)\n",
            "updating: fairseq/fairseq/models/transformer_from_pretrained_xlm.py (deflated 73%)\n",
            "updating: fairseq/fairseq/models/composite_encoder.py (deflated 66%)\n",
            "updating: fairseq/fairseq/models/__init__.py (deflated 70%)\n",
            "updating: fairseq/fairseq/models/wav2vec/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/wav2vec/wav2vec2.py (deflated 79%)\n",
            "updating: fairseq/fairseq/models/wav2vec/utils.py (deflated 43%)\n",
            "updating: fairseq/fairseq/models/wav2vec/wav2vec2_asr.py (deflated 76%)\n",
            "updating: fairseq/fairseq/models/wav2vec/__init__.py (deflated 40%)\n",
            "updating: fairseq/fairseq/models/wav2vec/wav2vec.py (deflated 76%)\n",
            "updating: fairseq/fairseq/models/fairseq_incremental_decoder.py (deflated 65%)\n",
            "updating: fairseq/fairseq/models/fairseq_encoder.py (deflated 62%)\n",
            "updating: fairseq/fairseq/models/nat/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/nat/levenshtein_utils.py (deflated 76%)\n",
            "updating: fairseq/fairseq/models/nat/levenshtein_transformer.py (deflated 79%)\n",
            "updating: fairseq/fairseq/models/nat/iterative_nonautoregressive_transformer.py (deflated 75%)\n",
            "updating: fairseq/fairseq/models/nat/cmlm_transformer.py (deflated 74%)\n",
            "updating: fairseq/fairseq/models/nat/nonautoregressive_transformer.py (deflated 77%)\n",
            "updating: fairseq/fairseq/models/nat/insertion_transformer.py (deflated 72%)\n",
            "updating: fairseq/fairseq/models/nat/nat_crf_transformer.py (deflated 71%)\n",
            "updating: fairseq/fairseq/models/nat/__init__.py (deflated 51%)\n",
            "updating: fairseq/fairseq/models/nat/fairseq_nat_model.py (deflated 74%)\n",
            "updating: fairseq/fairseq/models/nat/nonautoregressive_ensembles.py (deflated 79%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/s2t_transformer.py (deflated 78%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/convtransformer.py (deflated 78%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/s2t_conformer.py (deflated 73%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/utils.py (deflated 77%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/modules/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/modules/augmented_memory_attention.py (deflated 76%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/modules/emformer.py (deflated 81%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/berard.py (deflated 77%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/__init__.py (deflated 49%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/hub_interface.py (deflated 66%)\n",
            "updating: fairseq/fairseq/models/speech_to_text/xm_transformer.py (deflated 78%)\n",
            "updating: fairseq/fairseq/models/speech_to_speech/ (stored 0%)\n",
            "updating: fairseq/fairseq/models/speech_to_speech/s2s_transformer.py (deflated 83%)\n",
            "updating: fairseq/fairseq/models/speech_to_speech/s2s_conformer.py (deflated 66%)\n",
            "updating: fairseq/fairseq/models/speech_to_speech/__init__.py (deflated 39%)\n",
            "updating: fairseq/fairseq/models/speech_to_speech/modules.py (deflated 61%)\n",
            "updating: fairseq/fairseq/models/masked_lm.py (deflated 78%)\n",
            "updating: fairseq/fairseq/models/fconv_self_att.py (deflated 80%)\n",
            "updating: fairseq/fairseq/file_io.py (deflated 74%)\n",
            "updating: fairseq/fairseq/libbleu.cpython-37m-x86_64-linux-gnu.so (deflated 62%)\n",
            "updating: fairseq/fairseq/config/ (stored 0%)\n",
            "updating: fairseq/fairseq/config/config.yaml (deflated 49%)\n",
            "updating: fairseq/fairseq/config/__init__.py (deflated 25%)\n",
            "updating: fairseq/fairseq/config/model/ (stored 0%)\n",
            "updating: fairseq/fairseq/config/model/wav2vec2/ (stored 0%)\n",
            "updating: fairseq/fairseq/config/model/wav2vec2/wav2vec2_base.yaml (deflated 23%)\n",
            "updating: fairseq/fairseq/config/model/wav2vec2/wav2vec2_large.yaml (deflated 44%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/ (stored 0%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_gpt.yaml (deflated 60%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_baevski_wiki103.yaml (deflated 59%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_wiki103.yaml (deflated 59%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_gpt2_big.yaml (deflated 60%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_gpt2_medium.yaml (deflated 60%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_gpt2_small.yaml (deflated 60%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_gbw.yaml (deflated 60%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_baevski_gbw.yaml (deflated 60%)\n",
            "updating: fairseq/fairseq/config/model/transformer_lm/transformer_lm_big.yaml (deflated 60%)\n",
            "updating: fairseq/fairseq/config/model/wav2vec/ (stored 0%)\n",
            "updating: fairseq/fairseq/config/model/wav2vec/vq_wav2vec_gumbel.yaml (deflated 8%)\n",
            "updating: fairseq/fairseq/trainer.py (deflated 78%)\n",
            "updating: fairseq/fairseq/incremental_decoding_utils.py (deflated 67%)\n",
            "updating: fairseq/fairseq/distributed/ (stored 0%)\n",
            "updating: fairseq/fairseq/distributed/utils.py (deflated 76%)\n",
            "updating: fairseq/fairseq/distributed/tpu_distributed_data_parallel.py (deflated 58%)\n",
            "updating: fairseq/fairseq/distributed/module_proxy_wrapper.py (deflated 67%)\n",
            "updating: fairseq/fairseq/distributed/fully_sharded_data_parallel.py (deflated 67%)\n",
            "updating: fairseq/fairseq/distributed/__init__.py (deflated 59%)\n",
            "updating: fairseq/fairseq/distributed/distributed_timeout_wrapper.py (deflated 65%)\n",
            "updating: fairseq/fairseq/distributed/legacy_distributed_data_parallel.py (deflated 69%)\n",
            "updating: fairseq/fairseq/hub_utils.py (deflated 73%)\n",
            "updating: fairseq/fairseq/dataclass/ (stored 0%)\n",
            "updating: fairseq/fairseq/dataclass/configs.py (deflated 77%)\n",
            "updating: fairseq/fairseq/dataclass/utils.py (deflated 74%)\n",
            "updating: fairseq/fairseq/dataclass/__init__.py (deflated 34%)\n",
            "updating: fairseq/fairseq/dataclass/initialize.py (deflated 61%)\n",
            "updating: fairseq/fairseq/dataclass/constants.py (deflated 54%)\n",
            "updating: fairseq/fairseq/version.txt (stored 0%)\n",
            "updating: fairseq/fairseq/data/ (stored 0%)\n",
            "updating: fairseq/fairseq/data/data_utils_fast.cpp (deflated 87%)\n",
            "updating: fairseq/fairseq/data/transform_eos_dataset.py (deflated 74%)\n",
            "updating: fairseq/fairseq/data/audio/ (stored 0%)\n",
            "updating: fairseq/fairseq/data/audio/audio_utils.py (deflated 69%)\n",
            "updating: fairseq/fairseq/data/audio/frm_text_to_speech_dataset.py (deflated 72%)\n",
            "updating: fairseq/fairseq/data/audio/multi_modality_dataset.py (deflated 74%)\n",
            "updating: fairseq/fairseq/data/audio/speech_to_text_dataset.py (deflated 74%)\n",
            "updating: fairseq/fairseq/data/audio/text_to_speech_dataset.py (deflated 75%)\n",
            "updating: fairseq/fairseq/data/audio/speech_to_text_joint_dataset.py (deflated 76%)\n",
            "updating: fairseq/fairseq/data/audio/__init__.py (stored 0%)\n",
            "updating: fairseq/fairseq/data/audio/speech_to_speech_dataset.py (deflated 77%)\n",
            "updating: fairseq/fairseq/data/audio/feature_transforms/ (stored 0%)\n",
            "updating: fairseq/fairseq/data/audio/feature_transforms/utterance_cmvn.py (deflated 59%)\n",
            "updating: fairseq/fairseq/data/audio/feature_transforms/delta_deltas.py (deflated 58%)\n",
            "updating: fairseq/fairseq/data/audio/feature_transforms/global_cmvn.py (deflated 55%)\n",
            "updating: fairseq/fairseq/data/audio/feature_transforms/specaugment.py (deflated 72%)\n",
            "updating: fairseq/fairseq/data/audio/feature_transforms/__init__.py (deflated 68%)\n",
            "updating: fairseq/fairseq/data/audio/hubert_dataset.py (deflated 73%)\n",
            "updating: fairseq/fairseq/data/audio/data_cfg.py (deflated 72%)\n",
            "updating: fairseq/fairseq/data/audio/raw_audio_dataset.py (deflated 75%)\n",
            "updating: fairseq/fairseq/data/numel_dataset.py (deflated 55%)\n",
            "updating: fairseq/fairseq/data/monolingual_dataset.py (deflated 72%)\n",
            "updating: fairseq/fairseq/data/roll_dataset.py (deflated 44%)\n",
            "updating: fairseq/fairseq/data/text_compressor.py (deflated 69%)\n",
            "updating: fairseq/fairseq/data/encoders/ (stored 0%)\n",
            "updating: fairseq/fairseq/data/encoders/subword_nmt_bpe.py (deflated 63%)\n",
            "updating: fairseq/fairseq/data/encoders/byte_bpe.py (deflated 57%)\n",
            "updating: fairseq/fairseq/data/encoders/space_tokenizer.py (deflated 48%)\n",
            "updating: fairseq/fairseq/data/encoders/gpt2_bpe.py (deflated 57%)\n",
            "updating: fairseq/fairseq/data/encoders/fastbpe.py (deflated 54%)\n",
            "updating: fairseq/fairseq/data/encoders/utils.py (deflated 54%)\n",
            "updating: fairseq/fairseq/data/encoders/byte_utils.py (deflated 55%)\n",
            "updating: fairseq/fairseq/data/encoders/sentencepiece_bpe.py (deflated 60%)\n",
            "updating: fairseq/fairseq/data/encoders/characters.py (deflated 48%)\n",
            "updating: fairseq/fairseq/data/encoders/gpt2_bpe_utils.py (deflated 62%)\n",
            "updating: fairseq/fairseq/data/encoders/bytes.py (deflated 54%)\n",
            "updating: fairseq/fairseq/data/encoders/__init__.py (deflated 47%)\n",
            "updating: fairseq/fairseq/data/encoders/moses_tokenizer.py (deflated 61%)\n",
            "updating: fairseq/fairseq/data/encoders/hf_bert_bpe.py (deflated 60%)\n",
            "updating: fairseq/fairseq/data/encoders/hf_byte_bpe.py (deflated 59%)\n",
            "updating: fairseq/fairseq/data/encoders/nltk_tokenizer.py (deflated 52%)\n",
            "updating: fairseq/fairseq/data/dictionary.py (deflated 72%)\n",
            "updating: fairseq/fairseq/data/offset_tokens_dataset.py (deflated 43%)\n",
            "updating: fairseq/fairseq/data/data_utils_fast.pyx (deflated 73%)\n",
            "updating: fairseq/fairseq/data/add_target_dataset.py (deflated 69%)\n",
            "updating: fairseq/fairseq/data/iterators.py (deflated 78%)\n",
            "updating: fairseq/fairseq/data/mask_tokens_dataset.py (deflated 71%)\n",
            "updating: fairseq/fairseq/data/token_block_utils_fast.cpython-37m-x86_64-linux-gnu.so (deflated 69%)\n",
            "updating: fairseq/fairseq/data/num_samples_dataset.py (deflated 42%)\n",
            "updating: fairseq/fairseq/data/concat_sentences_dataset.py (deflated 66%)\n",
            "updating: fairseq/fairseq/data/shorten_dataset.py (deflated 67%)\n",
            "updating: fairseq/fairseq/data/concat_dataset.py (deflated 70%)\n",
            "updating: fairseq/fairseq/data/token_block_dataset.py (deflated 71%)\n",
            "updating: fairseq/fairseq/data/lru_cache_dataset.py (deflated 47%)\n",
            "updating: fairseq/fairseq/data/strip_token_dataset.py (deflated 52%)\n",
            "updating: fairseq/fairseq/data/fairseq_dataset.py (deflated 69%)\n",
            "updating: fairseq/fairseq/data/denoising_dataset.py (deflated 73%)\n",
            "updating: fairseq/fairseq/data/transform_eos_concat_langpair_dataset.py (deflated 75%)\n",
            "updating: fairseq/fairseq/data/replace_dataset.py (deflated 55%)\n",
            "updating: fairseq/fairseq/data/huffman/ (stored 0%)\n",
            "updating: fairseq/fairseq/data/huffman/huffman_mmap_indexed_dataset.py (deflated 72%)\n",
            "updating: fairseq/fairseq/data/huffman/__init__.py (deflated 55%)\n",
            "updating: fairseq/fairseq/data/huffman/huffman_coder.py (deflated 70%)\n",
            "updating: fairseq/fairseq/data/multi_corpus_dataset.py (deflated 71%)\n",
            "updating: fairseq/fairseq/data/append_token_dataset.py (deflated 61%)\n",
            "updating: fairseq/fairseq/data/token_block_utils_fast.pyx (deflated 75%)\n",
            "updating: fairseq/fairseq/data/prepend_dataset.py (deflated 56%)\n",
            "updating: fairseq/fairseq/data/data_utils.py (deflated 70%)\n",
            "updating: fairseq/fairseq/data/prepend_token_dataset.py (deflated 61%)\n",
            "updating: fairseq/fairseq/data/fasta_dataset.py (deflated 64%)\n",
            "updating: fairseq/fairseq/data/pad_dataset.py (deflated 61%)\n",
            "updating: fairseq/fairseq/data/base_wrapper_dataset.py (deflated 71%)\n",
            "updating: fairseq/fairseq/data/bucket_pad_length_dataset.py (deflated 64%)\n",
            "updating: fairseq/fairseq/data/indexed_dataset.py (deflated 77%)\n",
            "updating: fairseq/fairseq/data/noising.py (deflated 71%)\n",
            "updating: fairseq/fairseq/data/backtranslation_dataset.py (deflated 67%)\n",
            "updating: fairseq/fairseq/data/raw_label_dataset.py (deflated 48%)\n",
            "updating: fairseq/fairseq/data/round_robin_zip_datasets.py (deflated 70%)\n",
            "updating: fairseq/fairseq/data/resampling_dataset.py (deflated 65%)\n",
            "updating: fairseq/fairseq/data/codedataset.py (deflated 73%)\n",
            "updating: fairseq/fairseq/data/legacy/ (stored 0%)\n",
            "updating: fairseq/fairseq/data/legacy/masked_lm_dataset.py (deflated 71%)\n",
            "updating: fairseq/fairseq/data/legacy/masked_lm_dictionary.py (deflated 67%)\n",
            "updating: fairseq/fairseq/data/legacy/__init__.py (deflated 48%)\n",
            "updating: fairseq/fairseq/data/legacy/block_pair_dataset.py (deflated 72%)\n",
            "updating: fairseq/fairseq/data/data_utils_fast.cpython-37m-x86_64-linux-gnu.so (deflated 69%)\n",
            "updating: fairseq/fairseq/data/language_pair_dataset.py (deflated 75%)\n",
            "updating: fairseq/fairseq/data/__init__.py (deflated 75%)\n",
            "updating: fairseq/fairseq/data/subsample_dataset.py (deflated 62%)\n",
            "updating: fairseq/fairseq/data/lm_context_window_dataset.py (deflated 67%)\n",
            "updating: fairseq/fairseq/data/plasma_utils.py (deflated 68%)\n",
            "updating: fairseq/fairseq/data/nested_dictionary_dataset.py (deflated 66%)\n",
            "updating: fairseq/fairseq/data/transform_eos_lang_pair_dataset.py (deflated 71%)\n",
            "updating: fairseq/fairseq/data/colorize_dataset.py (deflated 50%)\n",
            "updating: fairseq/fairseq/data/sort_dataset.py (deflated 47%)\n",
            "updating: fairseq/fairseq/data/multilingual/ (stored 0%)\n",
            "updating: fairseq/fairseq/data/multilingual/sampled_multi_dataset.py (deflated 74%)\n",
            "updating: fairseq/fairseq/data/multilingual/sampled_multi_epoch_dataset.py (deflated 72%)\n",
            "updating: fairseq/fairseq/data/multilingual/sampling_method.py (deflated 65%)\n",
            "updating: fairseq/fairseq/data/multilingual/multilingual_data_manager.py (deflated 80%)\n",
            "updating: fairseq/fairseq/data/multilingual/__init__.py (deflated 25%)\n",
            "updating: fairseq/fairseq/data/multilingual/multilingual_utils.py (deflated 58%)\n",
            "updating: fairseq/fairseq/data/multi_corpus_sampled_dataset.py (deflated 69%)\n",
            "updating: fairseq/fairseq/data/token_block_utils_fast.cpp (deflated 87%)\n",
            "updating: fairseq/fairseq/data/id_dataset.py (deflated 43%)\n",
            "updating: fairseq/fairseq/data/list_dataset.py (deflated 54%)\n",
            "updating: fairseq/fairseq/token_generation_constraints.py (deflated 75%)\n",
            "updating: fairseq/fairseq/modules/ (stored 0%)\n",
            "updating: fairseq/fairseq/modules/lightconv_layer/ (stored 0%)\n",
            "updating: fairseq/fairseq/modules/lightconv_layer/lightconv_cuda.cpp (deflated 63%)\n",
            "updating: fairseq/fairseq/modules/lightconv_layer/lightconv_layer.py (deflated 69%)\n",
            "updating: fairseq/fairseq/modules/lightconv_layer/lightconv_cuda.cuh (deflated 77%)\n",
            "updating: fairseq/fairseq/modules/lightconv_layer/lightconv_cuda_kernel.cu (deflated 83%)\n",
            "updating: fairseq/fairseq/modules/lightconv_layer/setup.py (deflated 47%)\n",
            "updating: fairseq/fairseq/modules/lightconv_layer/__init__.py (deflated 30%)\n",
            "updating: fairseq/fairseq/modules/lightconv_layer/cuda_function_gen.py (deflated 82%)\n",
            "updating: fairseq/fairseq/modules/dynamic_convolution.py (deflated 75%)\n",
            "updating: fairseq/fairseq/modules/transformer_layer.py (deflated 81%)\n",
            "updating: fairseq/fairseq/modules/kmeans_attention.py (deflated 74%)\n",
            "updating: fairseq/fairseq/modules/conv_tbc.py (deflated 60%)\n",
            "updating: fairseq/fairseq/modules/lstm_cell_with_zoneout.py (deflated 49%)\n",
            "updating: fairseq/fairseq/modules/scalar_bias.py (deflated 49%)\n",
            "updating: fairseq/fairseq/modules/quantization/ (stored 0%)\n",
            "updating: fairseq/fairseq/modules/quantization/quantization_options.py (deflated 63%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/ (stored 0%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/utils.py (deflated 71%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/modules/ (stored 0%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/modules/qconv.py (deflated 66%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/modules/qlinear.py (deflated 63%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/modules/qemb.py (deflated 68%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/modules/__init__.py (deflated 36%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/__init__.py (deflated 27%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/pq.py (deflated 67%)\n",
            "updating: fairseq/fairseq/modules/quantization/pq/em.py (deflated 71%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/ (stored 0%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/utils.py (deflated 60%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/ops.py (deflated 71%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/modules/ (stored 0%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/modules/qconv.py (deflated 68%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/modules/qlinear.py (deflated 64%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/modules/qact.py (deflated 62%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/modules/qemb.py (deflated 68%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/modules/__init__.py (deflated 40%)\n",
            "updating: fairseq/fairseq/modules/quantization/scalar/__init__.py (deflated 25%)\n",
            "updating: fairseq/fairseq/modules/quantization/__init__.py (stored 0%)\n",
            "updating: fairseq/fairseq/modules/beamable_mm.py (deflated 59%)\n",
            "updating: fairseq/fairseq/modules/linearized_convolution.py (deflated 69%)\n",
            "updating: fairseq/fairseq/modules/adaptive_softmax.py (deflated 73%)\n",
            "updating: fairseq/fairseq/modules/cuda_utils.cu (deflated 70%)\n",
            "updating: fairseq/fairseq/modules/conformer_layer.py (deflated 77%)\n",
            "updating: fairseq/fairseq/modules/espnet_multihead_attention.py (deflated 76%)\n",
            "updating: fairseq/fairseq/modules/checkpoint_activations.py (deflated 71%)\n",
            "updating: fairseq/fairseq/modules/sinusoidal_positional_embedding.py (deflated 66%)\n",
            "updating: fairseq/fairseq/modules/unfold.py (deflated 45%)\n",
            "updating: fairseq/fairseq/modules/fp32_group_norm.py (deflated 50%)\n",
            "updating: fairseq/fairseq/modules/fp32_instance_norm.py (deflated 60%)\n",
            "updating: fairseq/fairseq/modules/dynamic_crf_layer.py (deflated 72%)\n",
            "updating: fairseq/fairseq/modules/cross_entropy.py (deflated 65%)\n",
            "updating: fairseq/fairseq/modules/adaptive_input.py (deflated 64%)\n",
            "updating: fairseq/fairseq/modules/positional_encoding.py (deflated 74%)\n",
            "updating: fairseq/fairseq/modules/sparse_multihead_attention.py (deflated 70%)\n",
            "updating: fairseq/fairseq/modules/transformer_sentence_encoder_layer.py (deflated 74%)\n",
            "updating: fairseq/fairseq/modules/learned_positional_embedding.py (deflated 60%)\n",
            "updating: fairseq/fairseq/modules/transpose_last.py (deflated 46%)\n",
            "updating: fairseq/fairseq/modules/sparse_transformer_sentence_encoder.py (deflated 71%)\n",
            "updating: fairseq/fairseq/modules/character_token_embedder.py (deflated 70%)\n",
            "updating: fairseq/fairseq/modules/gumbel_vector_quantizer.py (deflated 69%)\n",
            "updating: fairseq/fairseq/modules/transformer_sentence_encoder.py (deflated 74%)\n",
            "updating: fairseq/fairseq/modules/rotary_positional_embedding.py (deflated 58%)\n",
            "updating: fairseq/fairseq/modules/lightweight_convolution.py (deflated 76%)\n",
            "updating: fairseq/fairseq/modules/downsampled_multihead_attention.py (deflated 78%)\n",
            "updating: fairseq/fairseq/modules/layer_drop.py (deflated 55%)\n",
            "updating: fairseq/fairseq/modules/sparse_transformer_sentence_encoder_layer.py (deflated 66%)\n",
            "updating: fairseq/fairseq/modules/positional_embedding.py (deflated 60%)\n",
            "updating: fairseq/fairseq/modules/kmeans_vector_quantizer.py (deflated 63%)\n",
            "updating: fairseq/fairseq/modules/grad_multiply.py (deflated 42%)\n",
            "updating: fairseq/fairseq/modules/fairseq_dropout.py (deflated 63%)\n",
            "updating: fairseq/fairseq/modules/multihead_attention.py (deflated 79%)\n",
            "updating: fairseq/fairseq/modules/__init__.py (deflated 71%)\n",
            "updating: fairseq/fairseq/modules/base_layer.py (deflated 68%)\n",
            "updating: fairseq/fairseq/modules/quant_noise.py (deflated 68%)\n",
            "updating: fairseq/fairseq/modules/layer_norm.py (deflated 61%)\n",
            "updating: fairseq/fairseq/modules/fp32_batch_norm.py (deflated 61%)\n",
            "updating: fairseq/fairseq/modules/vggblock.py (deflated 66%)\n",
            "updating: fairseq/fairseq/modules/location_attention.py (deflated 66%)\n",
            "updating: fairseq/fairseq/modules/gelu.py (deflated 41%)\n",
            "updating: fairseq/fairseq/modules/same_pad.py (deflated 45%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/ (stored 0%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/dynamicconv_cuda.cuh (deflated 61%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/dynamicconv_cuda_kernel.cu (deflated 74%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/dynamicconv_layer.py (deflated 75%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/setup.py (deflated 48%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/dynamiconv_cpu.cpp (deflated 65%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/__init__.py (deflated 29%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/cuda_function_gen.py (deflated 77%)\n",
            "updating: fairseq/fairseq/modules/dynamicconv_layer/dynamicconv_cuda.cpp (deflated 64%)\n",
            "updating: fairseq/fairseq/modules/ema_module.py (deflated 67%)\n",
            "updating: fairseq/fairseq/sequence_scorer.py (deflated 70%)\n",
            "updating: fairseq/fairseq/model_parallel/ (stored 0%)\n",
            "updating: fairseq/fairseq/model_parallel/models/ (stored 0%)\n",
            "updating: fairseq/fairseq/model_parallel/models/transformer.py (deflated 68%)\n",
            "updating: fairseq/fairseq/model_parallel/models/roberta/ (stored 0%)\n",
            "updating: fairseq/fairseq/model_parallel/models/roberta/model.py (deflated 73%)\n",
            "updating: fairseq/fairseq/model_parallel/models/roberta/__init__.py (deflated 27%)\n",
            "updating: fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/ (stored 0%)\n",
            "updating: fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py (deflated 79%)\n",
            "updating: fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/__init__.py (deflated 27%)\n",
            "updating: fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/layers.py (deflated 81%)\n",
            "updating: fairseq/fairseq/model_parallel/models/transformer_lm.py (deflated 75%)\n",
            "updating: fairseq/fairseq/model_parallel/models/__init__.py (deflated 50%)\n",
            "updating: fairseq/fairseq/model_parallel/modules/ (stored 0%)\n",
            "updating: fairseq/fairseq/model_parallel/modules/transformer_layer.py (deflated 76%)\n",
            "updating: fairseq/fairseq/model_parallel/modules/multihead_attention.py (deflated 77%)\n",
            "updating: fairseq/fairseq/model_parallel/modules/__init__.py (deflated 51%)\n",
            "updating: fairseq/fairseq/model_parallel/__init__.py (deflated 29%)\n",
            "updating: fairseq/fairseq/model_parallel/megatron_trainer.py (deflated 66%)\n",
            "updating: fairseq/fairseq/model_parallel/megatron/ (stored 0%)\n",
            "updating: fairseq/fairseq/model_parallel/criterions/ (stored 0%)\n",
            "updating: fairseq/fairseq/model_parallel/criterions/vocab_parallel_cross_entropy.py (deflated 64%)\n",
            "updating: fairseq/fairseq/model_parallel/criterions/__init__.py (deflated 42%)\n",
            "updating: fairseq/fairseq/options.py (deflated 76%)\n",
            "updating: fairseq/fairseq/__init__.py (deflated 59%)\n",
            "updating: fairseq/fairseq/file_chunker_utils.py (deflated 62%)\n",
            "updating: fairseq/fairseq/benchmark/ (stored 0%)\n",
            "updating: fairseq/fairseq/benchmark/dummy_dataset.py (deflated 65%)\n",
            "updating: fairseq/fairseq/benchmark/dummy_masked_lm.py (deflated 63%)\n",
            "updating: fairseq/fairseq/benchmark/dummy_model.py (deflated 68%)\n",
            "updating: fairseq/fairseq/benchmark/dummy_lm.py (deflated 62%)\n",
            "updating: fairseq/fairseq/benchmark/dummy_mt.py (deflated 67%)\n",
            "updating: fairseq/fairseq/benchmark/__init__.py (deflated 36%)\n",
            "updating: fairseq/fairseq/clib/ (stored 0%)\n",
            "updating: fairseq/fairseq/clib/libbase/ (stored 0%)\n",
            "updating: fairseq/fairseq/clib/libbase/balanced_assignment.cpp (deflated 64%)\n",
            "updating: fairseq/fairseq/clib/libbleu/ (stored 0%)\n",
            "updating: fairseq/fairseq/clib/libbleu/module.cpp (deflated 42%)\n",
            "updating: fairseq/fairseq/clib/libbleu/libbleu.cpp (deflated 67%)\n",
            "updating: fairseq/fairseq/clib/cuda/ (stored 0%)\n",
            "updating: fairseq/fairseq/clib/cuda/ngram_repeat_block_cuda.cpp (deflated 59%)\n",
            "updating: fairseq/fairseq/clib/cuda/ngram_repeat_block_cuda_kernel.cu (deflated 60%)\n",
            "updating: fairseq/fairseq/clib/libnat/ (stored 0%)\n",
            "updating: fairseq/fairseq/clib/libnat/edit_dist.cpp (deflated 79%)\n",
            "updating: fairseq/fairseq/clib/libnat_cuda/ (stored 0%)\n",
            "updating: fairseq/fairseq/clib/libnat_cuda/edit_dist.h (deflated 55%)\n",
            "updating: fairseq/fairseq/clib/libnat_cuda/edit_dist.cu (deflated 83%)\n",
            "updating: fairseq/fairseq/clib/libnat_cuda/binding.cpp (deflated 64%)\n",
            "updating: fairseq/fairseq/speech_generator.py (deflated 77%)\n",
            "updating: fairseq/fairseq/quantization_utils.py (deflated 71%)\n",
            "updating: fairseq/fairseq/optim/ (stored 0%)\n",
            "updating: fairseq/fairseq/optim/adadelta.py (deflated 57%)\n",
            "updating: fairseq/fairseq/optim/fairseq_optimizer.py (deflated 72%)\n",
            "updating: fairseq/fairseq/optim/amp_optimizer.py (deflated 66%)\n",
            "updating: fairseq/fairseq/optim/adamax.py (deflated 68%)\n",
            "updating: fairseq/fairseq/optim/nag.py (deflated 65%)\n",
            "updating: fairseq/fairseq/optim/fused_lamb.py (deflated 58%)\n",
            "updating: fairseq/fairseq/optim/adafactor.py (deflated 72%)\n",
            "updating: fairseq/fairseq/optim/dynamic_loss_scaler.py (deflated 68%)\n",
            "updating: fairseq/fairseq/optim/shard.py (deflated 57%)\n",
            "updating: fairseq/fairseq/optim/composite.py (deflated 72%)\n",
            "updating: fairseq/fairseq/optim/__init__.py (deflated 56%)\n",
            "updating: fairseq/fairseq/optim/sgd.py (deflated 55%)\n",
            "updating: fairseq/fairseq/optim/fused_adam.py (deflated 75%)\n",
            "updating: fairseq/fairseq/optim/cpu_adam.py (deflated 70%)\n",
            "updating: fairseq/fairseq/optim/bmuf.py (deflated 71%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/ (stored 0%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/fairseq_lr_scheduler.py (deflated 66%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/manual_lr_scheduler.py (deflated 71%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/cosine_lr_scheduler.py (deflated 68%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/polynomial_decay_schedule.py (deflated 69%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/fixed_schedule.py (deflated 66%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/triangular_lr_scheduler.py (deflated 62%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/step_lr_scheduler.py (deflated 68%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/pass_through.py (deflated 62%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py (deflated 68%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/__init__.py (deflated 51%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/inverse_square_root_schedule.py (deflated 65%)\n",
            "updating: fairseq/fairseq/optim/lr_scheduler/tri_stage_lr_scheduler.py (deflated 70%)\n",
            "updating: fairseq/fairseq/optim/fp16_optimizer.py (deflated 80%)\n",
            "updating: fairseq/fairseq/optim/adagrad.py (deflated 52%)\n",
            "updating: fairseq/fairseq/optim/adam.py (deflated 69%)\n",
            "updating: fairseq/fairseq/criterions/ (stored 0%)\n",
            "updating: fairseq/fairseq/criterions/label_smoothed_cross_entropy_with_alignment.py (deflated 68%)\n",
            "updating: fairseq/fairseq/criterions/hubert_criterion.py (deflated 72%)\n",
            "updating: fairseq/fairseq/criterions/model_criterion.py (deflated 68%)\n",
            "updating: fairseq/fairseq/criterions/sentence_prediction.py (deflated 70%)\n",
            "updating: fairseq/fairseq/criterions/sentence_ranking.py (deflated 66%)\n",
            "updating: fairseq/fairseq/criterions/label_smoothed_cross_entropy_latency_augmented.py (deflated 74%)\n",
            "updating: fairseq/fairseq/criterions/tacotron2_loss.py (deflated 71%)\n",
            "updating: fairseq/fairseq/criterions/cross_entropy.py (deflated 64%)\n",
            "updating: fairseq/fairseq/criterions/fairseq_criterion.py (deflated 65%)\n",
            "updating: fairseq/fairseq/criterions/ctc.py (deflated 75%)\n",
            "updating: fairseq/fairseq/criterions/composite_loss.py (deflated 70%)\n",
            "updating: fairseq/fairseq/criterions/speech_to_speech_criterion.py (deflated 79%)\n",
            "updating: fairseq/fairseq/criterions/__init__.py (deflated 50%)\n",
            "updating: fairseq/fairseq/criterions/nat_loss.py (deflated 69%)\n",
            "updating: fairseq/fairseq/criterions/legacy_masked_lm.py (deflated 68%)\n",
            "updating: fairseq/fairseq/criterions/wav2vec_criterion.py (deflated 71%)\n",
            "updating: fairseq/fairseq/criterions/fastspeech2_loss.py (deflated 70%)\n",
            "updating: fairseq/fairseq/criterions/masked_lm.py (deflated 61%)\n",
            "updating: fairseq/fairseq/criterions/label_smoothed_cross_entropy.py (deflated 70%)\n",
            "updating: fairseq/fairseq/criterions/adaptive_loss.py (deflated 64%)\n",
            "updating: fairseq/fairseq/criterions/speech_ulm_criterion.py (deflated 69%)\n",
            "updating: fairseq/fairseq/ngram_repeat_block.py (deflated 68%)\n",
            "updating: fairseq/fairseq/search.py (deflated 76%)\n",
            "updating: fairseq/fairseq/file_utils.py (deflated 68%)\n",
            "updating: fairseq/fairseq/scoring/ (stored 0%)\n",
            "updating: fairseq/fairseq/scoring/tokenizer.py (deflated 63%)\n",
            "updating: fairseq/fairseq/scoring/wer.py (deflated 63%)\n",
            "updating: fairseq/fairseq/scoring/meteor.py (deflated 56%)\n",
            "updating: fairseq/fairseq/scoring/chrf.py (deflated 55%)\n",
            "updating: fairseq/fairseq/scoring/bertscore.py (deflated 58%)\n",
            "updating: fairseq/fairseq/scoring/__init__.py (deflated 53%)\n",
            "updating: fairseq/fairseq/scoring/bleu.py (deflated 69%)\n",
            "updating: fairseq/fairseq/checkpoint_utils.py (deflated 74%)\n",
            "updating: fairseq/fairseq/sequence_generator.py (deflated 76%)\n",
            "updating: fairseq/fairseq/libnat.cpython-37m-x86_64-linux-gnu.so (deflated 73%)\n",
            "updating: fairseq/fairseq/iterative_refinement_generator.py (deflated 75%)\n",
            "updating: fairseq/fairseq/tasks/ (stored 0%)\n",
            "updating: fairseq/fairseq/tasks/audio_finetuning.py (deflated 74%)\n",
            "updating: fairseq/fairseq/tasks/fairseq_task.py (deflated 75%)\n",
            "updating: fairseq/fairseq/tasks/speech_ulm_task.py (deflated 72%)\n",
            "updating: fairseq/fairseq/tasks/multilingual_translation.py (deflated 75%)\n",
            "updating: fairseq/fairseq/tasks/denoising.py (deflated 73%)\n",
            "updating: fairseq/fairseq/tasks/sentence_prediction.py (deflated 72%)\n",
            "updating: fairseq/fairseq/tasks/multilingual_language_modeling.py (deflated 75%)\n",
            "updating: fairseq/fairseq/tasks/sentence_ranking.py (deflated 70%)\n",
            "updating: fairseq/fairseq/tasks/multilingual_denoising.py (deflated 72%)\n",
            "updating: fairseq/fairseq/tasks/translation_lev.py (deflated 72%)\n",
            "updating: fairseq/fairseq/tasks/audio_pretraining.py (deflated 71%)\n",
            "updating: fairseq/fairseq/tasks/semisupervised_translation.py (deflated 80%)\n",
            "updating: fairseq/fairseq/tasks/speech_to_text.py (deflated 70%)\n",
            "updating: fairseq/fairseq/tasks/language_modeling.py (deflated 72%)\n",
            "updating: fairseq/fairseq/tasks/simultaneous_translation.py (deflated 58%)\n",
            "updating: fairseq/fairseq/tasks/cross_lingual_lm.py (deflated 67%)\n",
            "updating: fairseq/fairseq/tasks/frm_text_to_speech.py (deflated 65%)\n",
            "updating: fairseq/fairseq/tasks/translation.py (deflated 73%)\n",
            "updating: fairseq/fairseq/tasks/speech_to_speech.py (deflated 74%)\n",
            "updating: fairseq/fairseq/tasks/multilingual_masked_lm.py (deflated 73%)\n",
            "updating: fairseq/fairseq/tasks/__init__.py (deflated 66%)\n",
            "updating: fairseq/fairseq/tasks/online_backtranslation.py (deflated 74%)\n",
            "updating: fairseq/fairseq/tasks/hubert_pretraining.py (deflated 70%)\n",
            "updating: fairseq/fairseq/tasks/legacy_masked_lm.py (deflated 67%)\n",
            "updating: fairseq/fairseq/tasks/masked_lm.py (deflated 72%)\n",
            "updating: fairseq/fairseq/tasks/translation_from_pretrained_bart.py (deflated 67%)\n",
            "updating: fairseq/fairseq/tasks/text_to_speech.py (deflated 70%)\n",
            "updating: fairseq/fairseq/tasks/translation_multi_simple_epoch.py (deflated 75%)\n",
            "updating: fairseq/fairseq/tasks/translation_from_pretrained_xlm.py (deflated 56%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/checkpoints/checkpoint60.pt /content/drive/MyDrive/SuperAI2/MachineTranslation/"
      ],
      "metadata": {
        "id": "KXpXn1wuAsNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58c4fbae-d99b-40bb-e686-b2028c730ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/content/drive/MyDrive/SuperAI2/MachineTranslation/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/checkpoints/checkpoint_best.pt /content/drive/MyDrive/SuperAI2/MachineTranslation/\n",
        "!cp /content/checkpoints/checkpoint_last.pt /content/drive/MyDrive/SuperAI2/MachineTranslation/"
      ],
      "metadata": {
        "id": "hdUmwdjABJY4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4b19d24-e65b-4118-b4b1-8bb6dbba1e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/content/drive/MyDrive/SuperAI2/MachineTranslation/': No such file or directory\n",
            "cp: cannot create regular file '/content/drive/MyDrive/SuperAI2/MachineTranslation/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://object.pouta.csc.fi/Tatoeba-Challenge-v2021-08-07/eng-tha.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju_CEFYGjvsK",
        "outputId": "b8e32fa5-4ec8-4831-a260-958c55209257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-08 05:31:29--  https://object.pouta.csc.fi/Tatoeba-Challenge-v2021-08-07/eng-tha.tar\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvf /content/eng-tha.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZB0EiOHj6RU",
        "outputId": "ccfd6746-1a38-4f52-a21a-dc45d7b34f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/release/v2021-08-07/eng-tha/\n",
            "data/release/v2021-08-07/eng-tha/train.src.gz\n",
            "data/release/v2021-08-07/eng-tha/dev.trg\n",
            "data/release/v2021-08-07/eng-tha/train.id.gz\n",
            "data/release/v2021-08-07/eng-tha/test.trg\n",
            "data/release/v2021-08-07/eng-tha/test.id\n",
            "data/release/v2021-08-07/eng-tha/dev.src\n",
            "data/release/v2021-08-07/eng-tha/dev.id\n",
            "data/release/v2021-08-07/eng-tha/README.md\n",
            "data/release/v2021-08-07/eng-tha/test.src\n",
            "data/release/v2021-08-07/eng-tha/train.trg.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip /content/data/release/v2021-08-07/eng-tha/train.id.gz"
      ],
      "metadata": {
        "id": "CsKwaTNxkFG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f34dfec-196b-4c62-b4b7-a3bd4975a465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gzip: /content/data/release/v2021-08-07/eng-tha/train.id already exists; do you wish to overwrite (y or n)? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail /content/data/release/v2021-08-07/eng-tha/train.id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMdUpsUokVIU",
        "outputId": "f4b7563b-d916-462b-fa5d-144609d0588f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CCAligned-v1\teng\ttha\n",
            "CCAligned-v1\teng\ttha\n",
            "CCAligned-v1\teng\ttha\n",
            "CCAligned-v1\teng\ttha\n",
            "CCAligned-v1\teng\ttha\n",
            "OpenSubtitles-v2018\teng\ttha\n",
            "CCAligned-v1\teng\ttha\n",
            "OpenSubtitles-v2018\teng\ttha\n",
            "OpenSubtitles-v2018\teng\ttha\n",
            "OpenSubtitles-v2018\teng\ttha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip /content/data/release/v2021-08-07/eng-tha/train.src.gz"
      ],
      "metadata": {
        "id": "fg62n-S_khcz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d382a06e-2388-4331-f3a5-810897ec84c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gzip: /content/data/release/v2021-08-07/eng-tha/train.src already exists; do you wish to overwrite (y or n)? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail /content/data/release/v2021-08-07/eng-tha/train.src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT5MP54ukqy5",
        "outputId": "36df2a16-7eb6-4995-dab5-057175abfeeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ShemaleMia \n",
            "Pro-environment Long Lifetime Flue Gas Cooler for Drying or Cooling usage for Various Equipments General Introduction of Product Flue gas coolers are special heat recovery units where sensible heat contained in ... Read More \n",
            "Model No.: AT-15W \n",
            "Nanpi Jiantong Hardware Manufacturing Co., Ltd is a designer and manufacturer for Custom Sheet Metal Stamping Partsand Custom deep drawn stamping.Laser Cutting Service. Whether you require metal stampings, metal forming and sheet metal fabrications, tooling and die programming or Custom Cnc Parts and other services we provide, the expert team will ensure first-class service and high-grade quality, backed by our ISO 9001:2008 and TS16949 Quality Assurance guarantee. Please send your Enquiries here and Contact us for considerate services. \n",
            "Are always used for 330 When we work with RPI, or it may vary? \n",
            "George's already here. Why didn't you come with him?\n",
            "Follow us on Twitter \n",
            "Glove? I don't own shorts.\n",
            "I need to ask you something. Get out of here.\n",
            "- I'm glad we've got that on the record.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip /content/data/release/v2021-08-07/eng-tha/train.trg.gz"
      ],
      "metadata": {
        "id": "p3uTa4Jtk6bE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca4202fa-4b70-476c-ee6a-e5e6711e7e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gzip: /content/data/release/v2021-08-07/eng-tha/train.trg already exists; do you wish to overwrite (y or n)? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail /content/data/release/v2021-08-07/eng-tha/train.trg"
      ],
      "metadata": {
        "id": "XY0xlfrhk-Nv",
        "outputId": "281ad305-3912-4534-aaef-d2b574c89ad3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "กระเทย\n",
            "เครื่องทำความเย็นแก๊สไอเสียสำหรับใช้งานในสภาพแวดล้อมที่ยาวนานสำหรับการทำให้แห้งหรือทำความเย็นสำหรับอุปกรณ์ต่าง ๆ บทนำทั่วไปของผลิตภัณฑ์ เครื่องทำความเย็นก๊าซปล่องเป็นหน่วยกู้คืนความร้อนพิเศษที่ความร้อนที่เหมาะส... Read More\n",
            "หมายเลขรุ่น: AT-15W\n",
            "Nanpi Jiantong Hardware Manufacturing Co. , Ltd เป็นผู้ออกแบบและผู้ผลิต ชิ้นส่วนปั๊มโลหะแผ่นแบบกำหนดเองและปั๊มขึ้นรูป ลึกแบบกำหนดเอง บริการตัดด้วยเลเซอร์ ไม่ว่าคุณจะต้องการการประทับตราโลหะการขึ้นรูปโลหะและการประดิษฐ์แผ่นโลหะเครื่องมือและแม่พิมพ์หรือ ชิ้นส่วน CNC แบบกำหนดเอง และบริการอื่น ๆ ที่เราให้บริการทีมผู้เชี่ยวชาญจะรับประกันบริการชั้นหนึ่งและคุณภาพสูงซึ่งได้รับการสนับสนุนจาก ISO 9001: 2008 TS16949 รับประกันคุณภาพรับประกัน กรุณาส่งคำถามของคุณที่นี่และ ติดต่อเรา สำหรับบริการที่นึกถึง\n",
            "จะใช้สำหรับ 330 เมื่อเราทำงานกับ RPI, หรืออาจแตกต่างกัน?\n",
            "จอร์จมานี่ก่อนแล้ว ทำไมเธอไม่มาพร้อมเขาล่ะ\n",
            "ติดตามเราบน อินสตาแกรม\n",
            "ถุงมือเหรอ ผมไม่ได้เตรียมมาเล่นนะ\n",
            "ฉันมีเรื่องจะถามคุณ\n",
            "-ดีที่เราบันทึกไว้\n"
          ]
        }
      ]
    }
  ]
}